{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Копия блокнота \"farich_read_root_example.ipynb\"",
   "provenance": [
    {
     "file_id": "11NebRxpDewALrvN8Un_jA6atrZ3L4HlN",
     "timestamp": 1652210152468
    },
    {
     "file_id": "1VFgar3L6EujFLgBfbXNjISVZZ2F2k15t",
     "timestamp": 1631255116354
    },
    {
     "file_id": "19drm9hSuUtYHZlxN3xIVb7R-UoJ0EpDJ",
     "timestamp": 1619687086093
    },
    {
     "file_id": "1AWtfk-SUO5iUQL6SPYK5X3VzsIWD7j4Q",
     "timestamp": 1618441852195
    },
    {
     "file_id": "1yEW57kkrxMiquNsmuG7Z13pyi9YkIGag",
     "timestamp": 1617528150642
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0dQArAzUdno",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898444844,
     "user_tz": -180,
     "elapsed": 404,
     "user": {
      "displayName": "Платон Дмитриевич Рогожин",
      "userId": "06374754299160062301"
     }
    },
    "outputId": "05d97e3b-58af-45c6-c325-bba6a4b5f0d4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Подключение пакетов\n",
    "import os, sys, time\n",
    "import uproot3 as uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "from mpl_toolkits import mplot3d\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from numbers import Integral\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm, truncnorm, foldnorm\n",
    "from itertools import compress\n",
    "from pynverse import inversefunc\n",
    "import warnings\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "print('Uproot version:',uproot.version.version)\n",
    "print('Numpy version:', np.version.version)\n",
    "print('Pandas version:', pd.__version__)\n",
    "plt.ioff()\n",
    "\n",
    "# инициализация генератора псевдослучайных чисел\n",
    "# pandas version was 1.5.1\n",
    "\n",
    "rng = np.random.default_rng(42069) # сделать другой был 12345"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uproot version: 3.14.4\n",
      "Numpy version: 1.23.4\n",
      "Pandas version: 2.0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "datadir = 'data'\n",
    "picsdir = 'pics'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LwzFMaFOPreX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898469884,
     "user_tz": -180,
     "elapsed": 263,
     "user": {
      "displayName": "Платон Дмитриевич Рогожин",
      "userId": "06374754299160062301"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# отображение ключей в файле uproot в виде иерархии\n",
    "def show_uproot_tree(obj, maxkeylen=12, sep='/', indent=0) -> None:\n",
    "  width = maxkeylen+len(sep)\n",
    "  startline = False\n",
    "  if isinstance(obj, uproot.rootio.ROOTDirectory):\n",
    "    print('TFile: '+obj.name.decode('utf-8'))\n",
    "    startline = True\n",
    "    indent = 2\n",
    "  elif issubclass(type(obj), uproot.tree.TTreeMethods):\n",
    "    print('TTree: '+obj.name.decode('utf-8'))\n",
    "    startline = True\n",
    "    indent = 4\n",
    "  else:\n",
    "    if len(obj.keys()) > 0:\n",
    "      indent += width\n",
    "      s = obj.name.decode('utf-8')[:maxkeylen]\n",
    "      print(s + ' '*(maxkeylen-len(s)) + sep, end='')\n",
    "    else:\n",
    "      print(obj.name.decode('utf-8'))\n",
    "\n",
    "  if len(obj.keys()) > 0:\n",
    "    for i, key in enumerate(obj.keys()):\n",
    "      if i>0 or startline:\n",
    "        print(' '*indent, end='')\n",
    "      show_uproot_tree(obj[key], indent=indent)\n",
    "    indent -= width"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lg70kDuWKx1d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898474427,
     "user_tz": -180,
     "elapsed": 2763,
     "user": {
      "displayName": "Платон Дмитриевич Рогожин",
      "userId": "06374754299160062301"
     }
    },
    "outputId": "d3b922b3-ad42-4ec9-e62e-f8fc027d0904",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "filepath = os.path.join(datadir, 'farichsim_1200kevt.root')\n",
    "show_uproot_tree(uproot.open(filepath))"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFile: ./farichsim_pi-pi-_45-360deg_1200.0k_ideal_2020-12-24_rndm.root\n",
      "  TTree: info_sim\n",
      "    info_gen    /m_num_events\n",
      "                 m_z_dis\n",
      "    info_rad    /m_layers    /m_layers.first\n",
      "                              m_layers.second\n",
      "    info_pmt    /m_name\n",
      "                 m_num_side_x\n",
      "                 m_num_side_y\n",
      "                 m_gap\n",
      "                 m_size\n",
      "                 m_chip_num_size\n",
      "                 m_chip_pitch\n",
      "                 m_chip_size\n",
      "                 m_chip_offset\n",
      "                 m_focal_length\n",
      "                 m_trg_window\n",
      "                 m_origin_pos/m_origin_pos._2\n",
      "                              m_origin_pos._1\n",
      "                              m_origin_pos._0\n",
      "  TTree: raw_data\n",
      "    event       /m_id_event\n",
      "                 m_id_primary\n",
      "                 m_pos_primar/m_pos_primary._2\n",
      "                              m_pos_primary._1\n",
      "                              m_pos_primary._0\n",
      "                 m_dir_primar/m_dir_primary._2\n",
      "                              m_dir_primary._1\n",
      "                              m_dir_primary._0\n",
      "                 m_theta_primary\n",
      "                 m_phi_primary\n",
      "                 m_momentum_primary\n",
      "                 m_beta_primary\n",
      "                 m_hits      /m_hits.m_photon_id_pmt\n",
      "                              m_hits.m_photon_id_chip\n",
      "                              m_hits.m_photon_id_layer\n",
      "                              m_hits.m_photon_id_track\n",
      "                              m_hits.m_photon_id_track_parent\n",
      "                              m_hits.m_photon_id_hit\n",
      "                              m_hits.m_photon_wl\n",
      "                              m_hits.m_photon_time\n",
      "                              m_hits.m_photon_pos_exact._2\n",
      "                              m_hits.m_photon_pos_exact._1\n",
      "                              m_hits.m_photon_pos_exact._0\n",
      "                              m_hits.m_photon_pos_chip._2\n",
      "                              m_hits.m_photon_pos_chip._1\n",
      "                              m_hits.m_photon_pos_chip._0\n",
      "                              m_hits.m_photon_pos_vertex._2\n",
      "                              m_hits.m_photon_pos_vertex._1\n",
      "                              m_hits.m_photon_pos_vertex._0\n",
      "                              m_hits.m_photon_dir_vertex._2\n",
      "                              m_hits.m_photon_dir_vertex._1\n",
      "                              m_hits.m_photon_dir_vertex._0\n",
      "                              m_hits.m_hit_is_fittable\n",
      "                              m_hits.m_photon_theta.first\n",
      "                              m_hits.m_photon_theta.second\n",
      "                              m_hits.m_photon_phi.first\n",
      "                              m_hits.m_photon_phi.second\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X1oKpqDKUfrD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898477207,
     "user_tz": -180,
     "elapsed": 332,
     "user": {
      "displayName": "Платон Дмитриевич Рогожин",
      "userId": "06374754299160062301"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def readInfoFromRoot(filepath, verbose: bool = False) -> pd.DataFrame:\n",
    "  '''\n",
    "  Получение информации о моделировании из ROOT-файла в виде датафрейм формой (1, N), где N - число параметров.\n",
    "  '''\n",
    "  # Названия используемых колонок данных для переименования и сохранения в data frame\n",
    "  idf_rename_map = {'m_num_events': 'nevents',  # число событий моделирования\n",
    "                    'm_z_dis': 'zdis',  # расстояние от места рождения частицы до входа в радиатор в мм\n",
    "                    'm_layers': 'nlayers',  # число слоев радиатора\n",
    "                    'm_size': 'array_size',  # размер матрицы КФУ в мм\n",
    "                    'm_gap': 'array_gap',  # зазор между матрицами КФУ в мм\n",
    "                    'm_chip_size': 'pixel_size',  # размер пикселя КФУ в мм\n",
    "                    'm_chip_pitch': 'pixel_gap',  # зазор между пикселями КФУ в мм\n",
    "                    'm_chip_num_size': 'pixel_numx',  # размер матрицы КФУ в пикселях\n",
    "                    'm_num_side_x': 'nxarrays', 'm_num_side_y': 'nyarrays',  # размер фотодетектора в матрицах КФУ по X и Y\n",
    "                    'm_focal_length': 'distance',  # расстояние от входа в радиатор до входа в фотодетектор\n",
    "                    'm_trg_window': 'trg_window_ns',  # размер временного окна в нс\n",
    "                    'W': 'W',  # толщина радиатора в мм (вычисляемая)\n",
    "                    'n_mean': 'n_mean',  # средний показатель преломления радиатора (вычисляемый)\n",
    "                    'n_max': 'n_max',  # максимальный показатель преломления радиатора (вычисляемый)\n",
    "                   }\n",
    "\n",
    "  # Открытие ROOT-файла с данными используя Uproot https://github.com/scikit-hep/uproot3\n",
    "  with uproot.open(filepath) as file:\n",
    "    idf = file[b'info_sim'].pandas.df('*', flatten=False)\n",
    "\n",
    "  # Переименование параметров\n",
    "  idf.rename(columns=idf_rename_map, inplace=True, errors='ignore')\n",
    "\n",
    "  # Получение параметров (многослойного) радиатора одинаковых для всех файлов\n",
    "  n_l = idf.at[0,'m_layers.first']  # показатели преломления слоёв\n",
    "  w_l = idf.at[0,'m_layers.second']  # толщины слоёв радиатора\n",
    "\n",
    "  W = w_l.sum()  # суммарная толщина всех слоёв\n",
    "  n_mean = n_l.mean()  # средний показатель преломления\n",
    "  n_max = n_l.max()  # максимальный показатель преломления\n",
    "\n",
    "  # Добавление вычисляемых параметров в idf\n",
    "  idf['W'] = W\n",
    "  idf['n_mean'] = n_mean\n",
    "  idf['n_max'] = n_max\n",
    "\n",
    "  # Сохранение нужных параметров\n",
    "  idf = idf[idf_rename_map.values()]\n",
    "\n",
    "  if verbose:\n",
    "    for name in idf.columns:\n",
    "      print(f'{name}: {idf.at[0, name]}')\n",
    "\n",
    "  return idf"
   ],
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y8Ku3fKp8Vxl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898480118,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Платон Дмитриевич Рогожин",
      "userId": "06374754299160062301"
     }
    },
    "outputId": "3541df8f-bc75-45f9-e0a7-6d1ff9183be1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "idf = readInfoFromRoot(filepath)"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "       nevents  zdis  nlayers  array_size  array_gap  pixel_size  pixel_gap   \nentry                                                                         \n0      1200000   1.0        4       26.68        1.0        3.16        0.2  \\\n\n       pixel_numx  nxarrays  nyarrays  distance  trg_window_ns     W  n_mean   \nentry                                                                          \n0               8        30        30     200.0           20.0  35.0  1.0454  \\\n\n       n_max  \nentry         \n0       1.05  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nevents</th>\n      <th>zdis</th>\n      <th>nlayers</th>\n      <th>array_size</th>\n      <th>array_gap</th>\n      <th>pixel_size</th>\n      <th>pixel_gap</th>\n      <th>pixel_numx</th>\n      <th>nxarrays</th>\n      <th>nyarrays</th>\n      <th>distance</th>\n      <th>trg_window_ns</th>\n      <th>W</th>\n      <th>n_mean</th>\n      <th>n_max</th>\n    </tr>\n    <tr>\n      <th>entry</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1200000</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>26.68</td>\n      <td>1.0</td>\n      <td>3.16</td>\n      <td>0.2</td>\n      <td>8</td>\n      <td>30</td>\n      <td>30</td>\n      <td>200.0</td>\n      <td>20.0</td>\n      <td>35.0</td>\n      <td>1.0454</td>\n      <td>1.05</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sCexVXIHFivc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898482259,
     "user_tz": -180,
     "elapsed": 318,
     "user": {
      "displayName": "Платон Дмитриевич Рогожин",
      "userId": "06374754299160062301"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def genChunkFromRoot(filepath, eventchunksize=2000, noisefreqpersqmm: float = 2e6, noiseTimeRange: float = (0, 7), shiftSignalTimes: bool = True,\n",
    "                     edfstore: pd.HDFStore = None, verbose: bool = True, to_skip : int = 0) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "    Генератор событий из ROOT-файла в виде датафрейма. Число событий eventchunksize, читаемых генератором за один раз, должен выбираться так,\n",
    "    чтобы все данные с учетом добавляемых шумовых срабатываний умещались в размер ОЗУ.\n",
    "\n",
    "    Параметры:\n",
    "    filepath - путь к ROOT-файлу для чтения.\n",
    "    eventchunksize - число событий, загружаемых из ROOT-файла за один вызов.\n",
    "    noisefreqpersqmm - частота темновых срабатываний на единицу активной площади фотодетектора в с^{-1}*мм^{-2}, подмешиваемых к событиям;\n",
    "                       максимальное значение параметра, которое имеет смысл рассматривать, 2e6.\n",
    "    noiseTimeRange - (start, stop) - tuple, задающий временной интервал генерации шума в наносекундах.\n",
    "    edfstore - HDF-хранилище для записи датафрейма \"edf\"; данные добавляются к уже записанным в хранилище.\n",
    "    verbose - флаг отладочной печати.\n",
    "\n",
    "    Описание условий моделирования:\n",
    "    Ось Z направлена по нормали к плоскости радиатора от радиатора к фотодетектору.\n",
    "    Оси X и Y паралельны осям симметрии матрицы фотодетектора.\n",
    "    Первичная частица (отрицательный пион) вылетает на расстоянии zdis=1 мм перед радиатором в его сторону\n",
    "    Начальное положение частицы случайно разбрасывается по X и Y в квадрате со стороной (pixel_size+pixel_gap).\n",
    "    Направление частицы случайно разбрасывается в телесном угле в пределах theta_p=[0, π/4], phi_p=[0, 2π].\n",
    "    Скорость частицы случайно и равномерно разбрасывается от 0.957 до 0.999 скорости света.\n",
    "  \"\"\"\n",
    "  global rng\n",
    "\n",
    "  # Данные о частице (для переименования и сохранения)\n",
    "  part_rename_map = {'m_hits': 'nhits',                # число срабатываний в событии\n",
    "                     'm_pos_primary._0': 'x_p',        # X-координата вылета частицы в мм\n",
    "                     'm_pos_primary._1': 'y_p',        # Y-координата вылета частицы в мм\n",
    "                     'm_pos_primary._2': 'z_p',        # Z-координата вылета частицы в мм\n",
    "                     'm_dir_primary._0': 'nx_p',       # X-компонента единичного вектора направления частицы\n",
    "                     'm_dir_primary._1': 'ny_p',       # Y-компонента единичного вектора направления частицы\n",
    "                     'm_dir_primary._2': 'nz_p',       # Z-компонента единичного вектора направления частицы\n",
    "                     'm_beta_primary': 'beta',         # скорость частицы в единицах скорости света\n",
    "                     'm_theta_primary': 'theta_p',     # полярный угол направления частицы в радианах\n",
    "                     'm_phi_primary': 'phi_p',         # азимутальный угол направления частицы в радианах\n",
    "                     'm_momentum_primary': 'momentum'  # импульс частицы в МэВ/c\n",
    "                    }\n",
    "  \n",
    "  # Наблюдаемые данные о срабатываниях (для переименования и сохранения)\n",
    "  hit_rename_map = {'m_hits.m_photon_pos_chip._0': 'x_c',  # X-координата срабатывания в мм\n",
    "                    'm_hits.m_photon_pos_chip._1': 'y_c',  # Y-координата срабатывания в мм\n",
    "                    'm_hits.m_photon_pos_chip._2': 'z_c',  # Z-координата срабатывания в мм\n",
    "                    'm_hits.m_photon_time': 't_c'          # время срабатывания в нс\n",
    "                   }\n",
    "\n",
    "\n",
    "\n",
    "  # Наименования колонок для сохранения в датафрейм\n",
    "  edfcolstosave = list(part_rename_map.values()) + list(hit_rename_map.values())\n",
    "\n",
    "  # Чтение параметров моделирования\n",
    "  idf = readInfoFromRoot(filepath)\n",
    "\n",
    "  # Определения параметров фотодетектора для генерации темнового шума\n",
    "  pixel_size, pixel_gap = idf.at[0, 'pixel_size'], idf.at[0, 'pixel_gap']\n",
    "  array_size, array_gap = idf.at[0, 'array_size'], idf.at[0, 'array_gap']\n",
    "  nxpixels_arr = idf.at[0, 'pixel_numx']\n",
    "  nxpixels_tot = idf.at[0, 'nxarrays']*nxpixels_arr\n",
    "  igrid = np.arange(nxpixels_tot//2)\n",
    "  xpnts = array_gap/2 + (igrid//nxpixels_arr)*(array_size+array_gap) + (igrid%nxpixels_arr)*(pixel_size+pixel_gap) + pixel_size/2\n",
    "  xpnts = np.sort(np.append(-xpnts, xpnts)).astype('float32')\n",
    "  xgrid, ygrid = np.meshgrid(xpnts, xpnts)\n",
    "  xgrid = xgrid.reshape(xgrid.size)\n",
    "  ygrid = ygrid.reshape(ygrid.size)\n",
    " \n",
    "  def addNoise(partdf: pd.DataFrame, hitdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' \n",
    "    Генерация темновых срабатываний темнового шума и добавление в датафрейм (без учета \"мёртвого\" времени пикселя).\n",
    "    partdf - датафрейм для частиц\n",
    "    hitdf - датафрейм для срабатываний\n",
    "    '''\n",
    "    assert(np.isclose(pixel_size*nxpixels_arr+pixel_gap*(nxpixels_arr-1), array_size))\n",
    "    nevents = partdf.shape[0]  # число событий\n",
    "    \n",
    "    # среднее число шумовых срабатываний на событие\n",
    "    munoise = (noiseTimeRange[1]-noiseTimeRange[0])*1e-9*noisefreqpersqmm*(pixel_size**2)*(nxpixels_tot**2)\n",
    "\n",
    "    print(f'    Generate noise with DCR per mm^2 {noisefreqpersqmm}, mean number of hits per event: {munoise:.2f}.', end='')\n",
    "\n",
    "    noisehits = rng.poisson(munoise, nevents)   # генерация массива числа шумовых срабатываний в событиях по пуассоновскому распределению\n",
    "    Ndc = int(noisehits.sum())                  # общее число шумовых срабатываний (скаляр)\n",
    "    signalhits = partdf['nhits'].to_numpy()     # массив числа сигнальных срабатываний по событиям\n",
    "\n",
    "    # случайное смещение сигнальных срабатываний в пределах временного окна генерации шума\n",
    "    if shiftSignalTimes:\n",
    "      hitdf['t_c'] += np.repeat(rng.uniform(0, noiseTimeRange[1]-2, nevents), partdf['nhits'])\n",
    "\n",
    "    hitdf['signal'] = np.ones(signalhits.sum(), bool)  # разметка сигнальных срабатываний значением 'signal' True\n",
    "    if Ndc == 0:    # если нет шумовых срабатываний\n",
    "      return hitdf  # возвращаем исходный датафрейм с добавлением колонки 'signal'\n",
    "\n",
    "    ich = rng.choice(xgrid.size, Ndc)           # генерация случайных номеров сработавших каналов с возможным повтором\n",
    "    xh = xgrid[ich]                             # x-координата сработавших каналов\n",
    "    yh = ygrid[ich]                             # y-координата сработавших каналов\n",
    "    # zh = hitdf.at[(0, 0), 'z_c']                # z-координата срабатываний (скаляр)\n",
    "    zh = 201.050003\n",
    "    th = rng.uniform(noiseTimeRange[0], noiseTimeRange[1], size=Ndc) # генерация времён срабатываний по однородному распределению\n",
    "   \n",
    "    # нумерация шумовых срабатываний по событиям\n",
    "    ievent = np.repeat(partdf.index, noisehits) # массив номеров событий для записи в датафрейм\n",
    "    ihit = np.zeros(Ndc, 'int64')               # инициализация массива номеров срабатываний для записи в датафрейм\n",
    "    index = 0\n",
    "    for i in range(nevents):\n",
    "      ihit[index:index+noisehits[i]] = signalhits[i] + np.arange(noisehits[i])\n",
    "      index += noisehits[i]\n",
    "    \n",
    "    # создание датафрейма с шумовыми срабатываниями того же формата, что hitdf\n",
    "    noisedf = pd.DataFrame({'x_c': xh, 'y_c': yh, 'z_c': zh, 't_c': th, 'signal': np.zeros(Ndc, bool)},\n",
    "                           index=pd.MultiIndex.from_arrays((ievent, ihit), names=('entry', 'subentry')))\n",
    "\n",
    "    # TO DO: случайное смещение кольца в фотодетекторе (сдвиг координат сигнальных хитов).\n",
    "    # Сложность с реализацией для неравномерной сетки пикселей, т.к. зазоры между матрицами больше зазоров между пикселями в матрице.\n",
    "    # Проще сделать в моделировании.\n",
    "\n",
    "    # сливаем сигнальный и шумовой датафрейм и сортируем указатель событий и срабатываний\n",
    "    hitdf2 = pd.concat((hitdf, noisedf), copy=False).sort_index(level=('entry', 'subentry'))\n",
    "\n",
    "    # обновляем количества срабатываний в partdf, добавляя количества шумовых срабатываний по событиям\n",
    "    partdf['nhits'] += noisehits\n",
    "\n",
    "    return hitdf2\n",
    "\n",
    "\n",
    "  nFileEvents = idf.at[0, 'nevents']\n",
    "  # print(f'Processing ROOT file {filepath} with {nFileEvents} simulated events...', flush=True)\n",
    "  skip_iterator = 0\n",
    "  # Цикл чтения кусков ROOT-файла\n",
    "  for partdf, hitdf in zip(uproot.pandas.iterate(filepath, \"raw_data\", part_rename_map.keys(), entrysteps=eventchunksize),\n",
    "                           uproot.pandas.iterate(filepath, \"raw_data\", hit_rename_map.keys(), entrysteps=eventchunksize, flatten=True)):\n",
    "    # print('\\n  Processing next chunk...')\n",
    "    if to_skip > skip_iterator:\n",
    "      skip_iterator += 1\n",
    "      yield 0\n",
    "    else:\n",
    "      # Переименование колонок\n",
    "      partdf.rename(columns=part_rename_map, inplace=True, errors='raise')\n",
    "      hitdf.rename(columns=hit_rename_map, inplace=True, errors='raise')\n",
    "\n",
    "      partdf = partdf.astype('float32', copy=False)\n",
    "      partdf['nhits'] = partdf['nhits'].astype('int32', copy=False)\n",
    "      hitdf = hitdf.astype('float32', copy=False)\n",
    "\n",
    "      # Генерация и добавление шумовых срабатываний\n",
    "      hitdf = addNoise(partdf, hitdf)\n",
    "\n",
    "      # print(f'    {hitdf.index.levels[0].size} entries with {hitdf.shape[0]} hits to process')\n",
    "\n",
    "      # Слияние данных событий и срабатываний\n",
    "      edf = hitdf.join(partdf, on='entry')\n",
    "      #edf = hitdf.join(partdf, on='entry')\n",
    "      #edf = edf.join(otherdf, on='entry')\n",
    "      if verbose:\n",
    "        pass\n",
    "        # print(edf)\n",
    "\n",
    "      if edfstore is not None:\n",
    "        # print(f'    Saving edf chunk...')\n",
    "        edfstore.put('edf', edf, format='table', append=True)\n",
    "\n",
    "      yield edf"
   ],
   "execution_count": 135,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cCcplDgkbT1Y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898487147,
     "user_tz": -180,
     "elapsed": 645,
     "user": {
      "displayName": "Платон Дмитриевич Рогожин",
      "userId": "06374754299160062301"
     }
    },
    "outputId": "f6651bf4-214c-43f8-94e6-9a9bd43c5468",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Чтение и домоделирование одного \"куска\" данных\n",
    "#edf = next(genChunkFromRoot(filepath, 1450, noisefreqpersqmm=1000000))\n",
    "edf = next(genChunkFromRoot(filepath, 10000, noisefreqpersqmm=0))"
   ],
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Generate noise with DCR per mm^2 0, mean number of hits per event: 0.00.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def edf_to_bdf(edf_col: pd.Series, bdf: pd.DataFrame):\n",
    "  to_bdf = [sub.iloc[0] for _, sub in edf_col.groupby(level=0)]\n",
    "  bdf[edf_col.name] = pd.Series(to_bdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "                       x_c         y_c         z_c       t_c  signal  nhits   \nentry subentry                                                                \n0     0         -70.879997 -226.880005  201.050003  5.791411    True     18  \\\n      1         -53.279999 -309.920013  201.050003  5.999227    True     18   \n      2         -36.480000 -306.559998  201.050003  5.985067    True     18   \n      3         -49.919998 -184.960007  201.050003  5.676237    True     18   \n      4         -12.160000 -288.959991  201.050003  5.929748    True     18   \n...                    ...         ...         ...       ...     ...    ...   \n9999  40        178.240005  -80.959999  201.050003  4.232174    True     45   \n      41        178.240005  -74.239998  201.050003  4.224118    True     45   \n      42        226.880005  -53.279999  201.050003  4.429142    True     45   \n      43        274.720001 -209.279999  201.050003  4.639789    True     45   \n      44        251.199997  -18.879999  201.050003  4.377775    True     45   \n\n                     x_p       y_p  z_p      nx_p      ny_p      nz_p   \nentry subentry                                                          \n0     0         1.275724  1.576625  0.0 -0.073019 -0.695325  0.714977  \\\n      1         1.275724  1.576625  0.0 -0.073019 -0.695325  0.714977   \n      2         1.275724  1.576625  0.0 -0.073019 -0.695325  0.714977   \n      3         1.275724  1.576625  0.0 -0.073019 -0.695325  0.714977   \n      4         1.275724  1.576625  0.0 -0.073019 -0.695325  0.714977   \n...                  ...       ...  ...       ...       ...       ...   \n9999  40        1.499871 -1.121928  0.0  0.419547 -0.313757  0.851784   \n      41        1.499871 -1.121928  0.0  0.419547 -0.313757  0.851784   \n      42        1.499871 -1.121928  0.0  0.419547 -0.313757  0.851784   \n      43        1.499871 -1.121928  0.0  0.419547 -0.313757  0.851784   \n      44        1.499871 -1.121928  0.0  0.419547 -0.313757  0.851784   \n\n                    beta   theta_p     phi_p    momentum  \nentry subentry                                            \n0     0         0.966818  0.774205  4.607758  528.209290  \n      1         0.966818  0.774205  4.607758  528.209290  \n      2         0.966818  0.774205  4.607758  528.209290  \n      3         0.966818  0.774205  4.607758  528.209290  \n      4         0.966818  0.774205  4.607758  528.209290  \n...                  ...       ...       ...         ...  \n9999  40        0.987837  0.551415  5.641063  886.668091  \n      41        0.987837  0.551415  5.641063  886.668091  \n      42        0.987837  0.551415  5.641063  886.668091  \n      43        0.987837  0.551415  5.641063  886.668091  \n      44        0.987837  0.551415  5.641063  886.668091  \n\n[314038 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>x_c</th>\n      <th>y_c</th>\n      <th>z_c</th>\n      <th>t_c</th>\n      <th>signal</th>\n      <th>nhits</th>\n      <th>x_p</th>\n      <th>y_p</th>\n      <th>z_p</th>\n      <th>nx_p</th>\n      <th>ny_p</th>\n      <th>nz_p</th>\n      <th>beta</th>\n      <th>theta_p</th>\n      <th>phi_p</th>\n      <th>momentum</th>\n    </tr>\n    <tr>\n      <th>entry</th>\n      <th>subentry</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th>0</th>\n      <td>-70.879997</td>\n      <td>-226.880005</td>\n      <td>201.050003</td>\n      <td>5.791411</td>\n      <td>True</td>\n      <td>18</td>\n      <td>1.275724</td>\n      <td>1.576625</td>\n      <td>0.0</td>\n      <td>-0.073019</td>\n      <td>-0.695325</td>\n      <td>0.714977</td>\n      <td>0.966818</td>\n      <td>0.774205</td>\n      <td>4.607758</td>\n      <td>528.209290</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-53.279999</td>\n      <td>-309.920013</td>\n      <td>201.050003</td>\n      <td>5.999227</td>\n      <td>True</td>\n      <td>18</td>\n      <td>1.275724</td>\n      <td>1.576625</td>\n      <td>0.0</td>\n      <td>-0.073019</td>\n      <td>-0.695325</td>\n      <td>0.714977</td>\n      <td>0.966818</td>\n      <td>0.774205</td>\n      <td>4.607758</td>\n      <td>528.209290</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-36.480000</td>\n      <td>-306.559998</td>\n      <td>201.050003</td>\n      <td>5.985067</td>\n      <td>True</td>\n      <td>18</td>\n      <td>1.275724</td>\n      <td>1.576625</td>\n      <td>0.0</td>\n      <td>-0.073019</td>\n      <td>-0.695325</td>\n      <td>0.714977</td>\n      <td>0.966818</td>\n      <td>0.774205</td>\n      <td>4.607758</td>\n      <td>528.209290</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-49.919998</td>\n      <td>-184.960007</td>\n      <td>201.050003</td>\n      <td>5.676237</td>\n      <td>True</td>\n      <td>18</td>\n      <td>1.275724</td>\n      <td>1.576625</td>\n      <td>0.0</td>\n      <td>-0.073019</td>\n      <td>-0.695325</td>\n      <td>0.714977</td>\n      <td>0.966818</td>\n      <td>0.774205</td>\n      <td>4.607758</td>\n      <td>528.209290</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-12.160000</td>\n      <td>-288.959991</td>\n      <td>201.050003</td>\n      <td>5.929748</td>\n      <td>True</td>\n      <td>18</td>\n      <td>1.275724</td>\n      <td>1.576625</td>\n      <td>0.0</td>\n      <td>-0.073019</td>\n      <td>-0.695325</td>\n      <td>0.714977</td>\n      <td>0.966818</td>\n      <td>0.774205</td>\n      <td>4.607758</td>\n      <td>528.209290</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">9999</th>\n      <th>40</th>\n      <td>178.240005</td>\n      <td>-80.959999</td>\n      <td>201.050003</td>\n      <td>4.232174</td>\n      <td>True</td>\n      <td>45</td>\n      <td>1.499871</td>\n      <td>-1.121928</td>\n      <td>0.0</td>\n      <td>0.419547</td>\n      <td>-0.313757</td>\n      <td>0.851784</td>\n      <td>0.987837</td>\n      <td>0.551415</td>\n      <td>5.641063</td>\n      <td>886.668091</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>178.240005</td>\n      <td>-74.239998</td>\n      <td>201.050003</td>\n      <td>4.224118</td>\n      <td>True</td>\n      <td>45</td>\n      <td>1.499871</td>\n      <td>-1.121928</td>\n      <td>0.0</td>\n      <td>0.419547</td>\n      <td>-0.313757</td>\n      <td>0.851784</td>\n      <td>0.987837</td>\n      <td>0.551415</td>\n      <td>5.641063</td>\n      <td>886.668091</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>226.880005</td>\n      <td>-53.279999</td>\n      <td>201.050003</td>\n      <td>4.429142</td>\n      <td>True</td>\n      <td>45</td>\n      <td>1.499871</td>\n      <td>-1.121928</td>\n      <td>0.0</td>\n      <td>0.419547</td>\n      <td>-0.313757</td>\n      <td>0.851784</td>\n      <td>0.987837</td>\n      <td>0.551415</td>\n      <td>5.641063</td>\n      <td>886.668091</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>274.720001</td>\n      <td>-209.279999</td>\n      <td>201.050003</td>\n      <td>4.639789</td>\n      <td>True</td>\n      <td>45</td>\n      <td>1.499871</td>\n      <td>-1.121928</td>\n      <td>0.0</td>\n      <td>0.419547</td>\n      <td>-0.313757</td>\n      <td>0.851784</td>\n      <td>0.987837</td>\n      <td>0.551415</td>\n      <td>5.641063</td>\n      <td>886.668091</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>251.199997</td>\n      <td>-18.879999</td>\n      <td>201.050003</td>\n      <td>4.377775</td>\n      <td>True</td>\n      <td>45</td>\n      <td>1.499871</td>\n      <td>-1.121928</td>\n      <td>0.0</td>\n      <td>0.419547</td>\n      <td>-0.313757</td>\n      <td>0.851784</td>\n      <td>0.987837</td>\n      <td>0.551415</td>\n      <td>5.641063</td>\n      <td>886.668091</td>\n    </tr>\n  </tbody>\n</table>\n<p>314038 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RnR-4_yXtH5v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898489590,
     "user_tz": -180,
     "elapsed": 277,
     "user": {
      "displayName": "Платон Дмитриевич Рогожин",
      "userId": "06374754299160062301"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def recoAngles(edf: pd.DataFrame, idf: pd.DataFrame, rotation_mode = False):\n",
    "  '''\n",
    "  Геометрическая реконструкция углов фотонов относительно направления частицы.\n",
    "  Из координат срабатываний и частиц вычисляются углы theta_c, phi_c и время вылета фотонов t_c_orig и добавляются к edf.\n",
    "  '''\n",
    "  r0 = edf.loc[:, ('x_p', 'y_p', 'z_p')].to_numpy()\n",
    "  if rotation_mode:\n",
    "    r = edf.loc[:, ('rotated_x', 'rotated_y', 'rotated_z')].to_numpy()\n",
    "    # n0 = edf.loc[:, ('rotated_nx_p', 'rotated_ny_p', 'rotated_nz_p')].to_numpy()\n",
    "    n0 = edf.loc[:, ('recalculated_nx_p', 'recalculated_ny_p', 'recalculated_nz_p')].to_numpy()\n",
    "  else:\n",
    "    r  = edf.loc[:, ('x_c', 'y_c', 'z_c')].to_numpy()\n",
    "    n0 = edf.loc[:, ('nx_p', 'ny_p', 'nz_p')].to_numpy()\n",
    "\n",
    "  speedOfLight_mmperns = 299.792458 # мм/нс\n",
    "\n",
    "  # расстояние от радиатора до детектора\n",
    "  dist = float(idf['distance'])\n",
    "\n",
    "  # толщина радиатора\n",
    "  W = float(idf['W'])\n",
    "\n",
    "  # расстояние от точки вылета частицы до входной плоскости радиатора\n",
    "  rad_pos = float(idf['zdis'])\n",
    "\n",
    "  # полное число срабатываний\n",
    "  N = edf.shape[0]\n",
    "\n",
    "  # координаты точки пересечения трека с ФД\n",
    "  if not rotation_mode:\n",
    "    y_i = r0[:,1] + (dist + rad_pos) * n0[:,1] / n0[:,2] # r0[:,1] + (dist + W + rad_pos) * n0[:,1] / n0[:,2]   #   r0[:,1] + (dist + rad_pos) * n0[:,1] / n0[:,2]\n",
    "    x_i = r0[:,0] + (y_i - r0[:,1]) * n0[:,0] / n0[:,1] # r0[:,0] + (y_i - r0[:,1]) * n0[:,0] / n0[:,1]    #     r0[:,0] + (dist + rad_pos) * n0[:,0] / n0[:,2]\n",
    "    edf['x_i'] = x_i\n",
    "    edf['y_i'] = y_i\n",
    "    edf['r_p_c'] = np.sqrt((r0[:,0] - x_i) ** 2 + (r0[:,1] - y_i) ** 2 + (r0[:,2] - r[:,2]) ** 2)\n",
    "    edf['r_c'] = np.sqrt((x_i - edf['x_c']) ** 2 + (y_i - edf['y_c']) ** 2)\n",
    "\n",
    "  if rotation_mode:\n",
    "    n_mean = float(idf['n_mean'])\n",
    "\n",
    "    edf['rotated_r_c'] = np.sqrt((edf['rotated_x_i'] - edf['rotated_x']) ** 2 + (edf['rotated_y_i'] - edf['rotated_y']) ** 2)\n",
    "\n",
    "    rotated_r_c = edf['rotated_r_c'].to_numpy()\n",
    "    # r_p_c = edf['r_p_c'].to_numpy()\n",
    "    beta = edf['beta'].to_numpy()\n",
    "    r_p_c = dist # or + W/2 ???\n",
    "\n",
    "    edf['beta_from_true_r'] = np.sqrt(rotated_r_c ** 2 + r_p_c ** 2) / (n_mean * r_p_c)\n",
    "    edf['true_r_from_beta'] = r_p_c * np.sqrt((n_mean * beta) ** 2 - 1)\n",
    "\n",
    "    avg_betas = []\n",
    "    for _, subentry in edf['beta_from_true_r'].groupby(level=0):\n",
    "      avg_beta = subentry.mean()\n",
    "      for __ in subentry:\n",
    "        avg_betas.append(avg_beta)\n",
    "    edf['beta_from_true_r_mean'] = avg_betas\n",
    "  # косинусы и синусы сферических углов направления частицы\n",
    "  costheta, sintheta = n0[:,2], np.sqrt(n0[:,0]**2+n0[:,1]**2)\n",
    "  phi = np.arctan2(n0[:,1], n0[:,0])\n",
    "  cosphi, sinphi = np.cos(phi), np.sin(phi)\n",
    "\n",
    "  # номинальная точка вылета фотонов\n",
    "  ro = r0 + (W/2+rad_pos)/n0[:,2].reshape(N,1)*n0\n",
    "\n",
    "  \"\"\"\n",
    "  Преобразование в СК частицы\n",
    "  𝑢𝑥 = cos 𝜃(𝑣𝑥 cos 𝜙 + 𝑣𝑦 sin 𝜙) − 𝑣𝑧 sin 𝜃,\n",
    "  𝑢𝑦 = −𝑣𝑥 sin 𝜙 + 𝑣𝑦 cos 𝜙,\n",
    "  𝑢𝑧 = sin 𝜃(𝑣𝑥 cos 𝜙 + 𝑣𝑦 sin 𝜙) + 𝑣𝑧 cos 𝜃.\n",
    "  \"\"\"\n",
    "\n",
    "  # вектор направления фотона в лабораторной СК\n",
    "  s = (r-ro)\n",
    "  snorm = np.linalg.norm(s, axis=1, keepdims=True)\n",
    "  v = s / snorm\n",
    "  if not rotation_mode:\n",
    "    edf['t_c_orig'] = edf['t_c'] - (snorm / speedOfLight_mmperns).reshape(N)\n",
    "\n",
    "  # освобождение памяти при необходимости\n",
    "  #del r0, n0, ro, r, s\n",
    "\n",
    "  U = np.stack((np.stack((costheta*cosphi, costheta*sinphi, -sintheta)),\n",
    "                np.stack((-sinphi,         cosphi,          np.full(N, 0.))),\n",
    "                np.stack((sintheta*cosphi, sintheta*sinphi, costheta)))).transpose(2,0,1)\n",
    "\n",
    "  # единичный вектор направления фотона в СК частицы\n",
    "  u = (U @ v.reshape(N,3,1)).reshape(N,3)\n",
    "\n",
    "  # сферические углы фотона в СК частицы\n",
    "  if rotation_mode:\n",
    "    edf['rotated_theta_c'] = np.arccos(u[:,2])\n",
    "    edf['rotated_phi_c'] = np.arctan2(-u[:,1], -u[:,0])\n",
    "  else:\n",
    "    edf['theta_c'] = np.arccos(u[:,2])\n",
    "    edf['phi_c'] = np.arctan2(-u[:,1], -u[:,0])\n",
    "    avg_thetas = []\n",
    "    for _, subentry in edf['theta_c'].groupby(level=0):\n",
    "      avg_theta = subentry.mean()\n",
    "      for __ in subentry:\n",
    "        avg_thetas.append(avg_theta)\n",
    "    edf['theta_c_mean'] = avg_thetas"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def applySpaceCut(edf: pd.DataFrame) -> pd.DataFrame:\n",
    "  return edf[(abs(edf['x_c'] - edf['x_i']) <= 220) & (abs(edf['y_c'] - edf['y_i']) <= 220)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def signalLength(edf: pd.DataFrame):\n",
    "  t_signal = edf[edf['signal'] ==  True]['t_c']\n",
    "  t = []\n",
    "  for _, subentry in t_signal.groupby(level=0):\n",
    "    t_min = np.min(subentry)\n",
    "    t_max = np.max(subentry)\n",
    "    t.extend(t_max - t_min for __ in subentry)\n",
    "  t = np.array(t)\n",
    "  edf['signal_length'] = t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def planeRecalculation(edf: pd.DataFrame, idf: pd.DataFrame):\n",
    "    R_p = edf[['x_p', 'y_p', 'z_p']].to_numpy()\n",
    "    R = edf[['x_c', 'y_c', 'z_c']].to_numpy()\n",
    "    R_i = edf[['x_i', 'y_i', 'z_c']].to_numpy()\n",
    "    N = edf[['nx_p', 'ny_p', 'nz_p']].to_numpy()\n",
    "    dist = idf.W / 2 + idf.zdis\n",
    "    alpha = (float(dist) - R_p[:,2]) / N[:,2]\n",
    "    r_d = R_p + N * alpha[:, np.newaxis]\n",
    "\n",
    "    u = R - r_d\n",
    "    dot = np.sum(N * u, axis=1)\n",
    "    w = r_d - R_i\n",
    "    fac = -np.sum(N * w, axis=1) / dot\n",
    "    u *= fac[:, np.newaxis]\n",
    "\n",
    "    R_new = r_d + u\n",
    "\n",
    "    speedOfLight_mmperns = 299.792458\n",
    "    t_dif = np.sqrt(np.sum((R_new - R) ** 2, axis=1)) / speedOfLight_mmperns\n",
    "    edf['t_c'] = edf['t_c'] + np.sign(R_new[:,2] - R[:,2]) * t_dif\n",
    "\n",
    "    edf['recalculated_x'] = R_new[:,0]\n",
    "    edf['recalculated_y'] = R_new[:,1]\n",
    "    edf['recalculated_z'] = R_new[:,2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def primaryDirectionRecalculation(edf: pd.DataFrame):\n",
    "  N = edf.loc[:, ('nx_p', 'ny_p', 'nz_p')].to_numpy()\n",
    "  M = []\n",
    "  for n in N:\n",
    "    # C = np.stack((np.array([-(n[1] ** 2 + n[2] ** 2) / n[0], 0 , n[0]]),\n",
    "    #               np.array([n[1], - n[2], n[1]]),\n",
    "    #               np.array([n[2], n[1], n[2]])))\n",
    "\n",
    "    # C_inv = np.array([np.array([- n[0] / (n[0] ** 2 + n[1] ** 2 + n[2] ** 2), n[0] ** 2 * n[1] / (n[1] ** 4 + n[0] ** 2 * n[1] ** 2 + n[2] ** 4 + n[0] ** 2 * n[2] ** 2 + 2 * n[1] ** 2 * n[2] ** 2) , n[0] ** 2 * n[2] / (n[1] ** 4 + n[0] ** 2 * n[1] ** 2 + n[2] ** 4 + n[0] ** 2 * n[2] ** 2 + 2 * n[1] ** 2 * n[2] ** 2)]),\n",
    "    #               np.array([0, - n[2] / (n[1] ** 2 + n[2] ** 2), n[1] / (n[1] ** 2 + n[2] ** 2)]),\n",
    "    #               np.array([n[0] / (n[0] ** 2 + n[1] ** 2 + n[2] ** 2), n[1] / (n[0] ** 2 + n[1] ** 2 + n[2] ** 2), n[2] / (n[0] ** 2 + n[1] ** 2 + n[2] ** 2)])])\n",
    "    M.append([0, 0, 1])\n",
    "    # print(n)\n",
    "    # print(C_inv)\n",
    "    # print(C_inv @ n)\n",
    "    # break\n",
    "  M = np.array(M)\n",
    "  edf['recalculated_nx_p'] = M[:,0]\n",
    "  edf['recalculated_ny_p'] = M[:,1]\n",
    "  edf['recalculated_nz_p'] = M[:,2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def planeRotation(edf: pd.DataFrame):\n",
    "  R = edf[['recalculated_x', 'recalculated_y', 'recalculated_z']].to_numpy()\n",
    "  R_i = edf[['x_i', 'y_i', 'z_c']].to_numpy()\n",
    "  N = edf[['nx_p', 'ny_p', 'nz_p']].to_numpy() # N\n",
    "  M = np.array([0, 0, 1])                           # M\n",
    "  c = np.dot(N, M) / (np.linalg.norm(M) * np.linalg.norm(N, axis=1))\n",
    "  axis = np.cross(N, np.broadcast_to(M, (N.shape[0], 3))) / np.linalg.norm(np.cross(N, np.broadcast_to(M, (N.shape[0], 3))), axis=1, keepdims=True)\n",
    "  x, y, z = axis.T\n",
    "  s = np.sqrt(1-c*c)\n",
    "  C = 1-c\n",
    "  rmat = np.array([\n",
    "      [x*x*C+c, x*y*C-z*s, x*z*C+y*s],\n",
    "      [y*x*C+z*s, y*y*C+c, y*z*C-x*s],\n",
    "      [z*x*C-y*s, z*y*C+x*s, z*z*C+c]])\n",
    "  # print(rmat.shape)\n",
    "  # print(R.shape)\n",
    "  # print(rmat[:, :, 0])\n",
    "  # print(R[0])\n",
    "  # print(rmat[:, :, 0] @ R[0])\n",
    "  rotated_R = np.matmul(rmat.transpose((2, 0, 1)), R[:, :, np.newaxis])\n",
    "  rotated_R = np.squeeze(rotated_R, axis=-1).transpose().T\n",
    "  rotated_R_i = np.matmul(rmat.transpose((2, 0, 1)), R_i[:, :, np.newaxis])\n",
    "  rotated_R_i = np.squeeze(rotated_R_i, axis=-1).transpose().T\n",
    "  # print(rotated_R[0])\n",
    "  maskR = np.logical_or(abs(rotated_R[:, 0]) >= 500, abs(rotated_R[:, 1]) >= 500)\n",
    "  maskR_i = np.logical_or(abs(rotated_R_i[:, 0]) >= 500, abs(rotated_R_i[:, 1]) >= 500)\n",
    "  rotated_R[maskR] = [5000, 5000, 0]\n",
    "  rotated_R_i[maskR_i] = [5000, 5000, 0]\n",
    "  rotated_n = (rotated_R_i - edf[['x_p', 'y_p', 'z_p']].to_numpy()) / np.linalg.norm(rotated_R_i - edf[['x_p', 'y_p', 'z_p']].to_numpy(), axis=1, keepdims=True)\n",
    "  edf['rotated_x'] = rotated_R[:,0]\n",
    "  edf['rotated_y'] = rotated_R[:,1]\n",
    "  edf['rotated_z'] = rotated_R[:,2]\n",
    "  edf['rotated_x_i'] = rotated_R_i[:,0]\n",
    "  edf['rotated_y_i'] = rotated_R_i[:,1]\n",
    "  edf['rotated_z_i'] = rotated_R_i[:,2]\n",
    "  edf['rotated_nx_p'] = rotated_n[:,0]\n",
    "  edf['rotated_ny_p'] = rotated_n[:,1]\n",
    "  edf['rotated_nz_p'] = rotated_n[:,2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def applySecondSpaceCut(edf: pd.DataFrame) -> pd.DataFrame:\n",
    "  return edf[(abs(edf['rotated_x'] - edf['rotated_x_i']) <= 220) & (abs(edf['rotated_y'] - edf['rotated_y_i']) <= 220)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def local_sum_2d(event, r_slices, t_slices, square_counts, max_index, n, m, timestep, t_window_width, method='N/r'):\n",
    "  # cut_event = event[(event.t_c <= t_slices[np.clip(max_index[1] + m, a_min=0, a_max=10)]) & (event.t_c >= t_slices[np.clip(max_index[1] - m, a_min=0, a_max=10)]) &\n",
    "  #                   (event.rotated_r_c <= r_slices[max_index[0] + n]) & (event.rotated_r_c >= r_slices[max_index[0] - n])]\n",
    "  cut_event = event[(event.t_c <= np.clip(t_slices[max_index[1]] + t_window_width + timestep * m, 0, 10)) & (event.t_c >= np.clip(t_slices[max_index[1]] - timestep * m, 0, 10)) &\n",
    "                    (event.rotated_r_c <= r_slices[max_index[0] + n]) & (event.rotated_r_c >= r_slices[max_index[0] - n])]\n",
    "  return np.mean(cut_event.rotated_r_c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def local_weighed_sum_2d(r_slices, t_slices, square_counts, max_index, n, m, method='N/r'):\n",
    "  arr = np.mean(square_counts[max_index[0] - n:max_index[0] + n + 1, np.clip(max_index[1] - m, 0, 50):np.clip(max_index[1] + m + 1, 0, 50)], axis=1)\n",
    "  if method == 'N/r':\n",
    "    sum_arr = r_slices[max_index[0] - n:max_index[0] + n + 1] ** 2 * arr\n",
    "    den_arr = r_slices[max_index[0] - n:max_index[0] + n + 1] * arr\n",
    "  else:\n",
    "    sum_arr = r_slices[max_index[0] - n:max_index[0] + n + 1] * arr\n",
    "    den_arr = arr\n",
    "\n",
    "  weighted_sum = np.sum(sum_arr)\n",
    "  weighted_den = np.sum(den_arr)\n",
    "\n",
    "  return weighted_sum / weighted_den"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def local_weighed_sum(r_slices, counts, max_index, n, method='N/r'):\n",
    "  if method == 'N/r':\n",
    "    sum_arr = r_slices[max_index - n:max_index + n + 1] ** 2 * counts[max_index - n:max_index + n + 1]\n",
    "    den_arr = r_slices[max_index - n:max_index + n + 1] * counts[max_index - n:max_index + n + 1]\n",
    "  else:\n",
    "    sum_arr = r_slices[max_index - n:max_index + n + 1] * counts[max_index - n:max_index + n + 1]\n",
    "    den_arr = counts[max_index - n:max_index + n + 1]\n",
    "\n",
    "  weighted_sum = np.sum(sum_arr)\n",
    "  weighted_den = np.sum(den_arr)\n",
    "\n",
    "  return weighted_sum / weighted_den"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def pol(x, a, b, c):\n",
    "  return a * np.exp((x - b) ** 2 / c ** 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def rSlidingWindowIntro(edf: pd.DataFrame, idf: pd.DataFrame, bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, step=float(idf.pixel_size), method='N/r', cal_arr=False, t_window_width=2,\n",
    "                        r_width_factor=2, t_width_factor=8, full_width_t_hist = False, num_of_groups=5):\n",
    "  r_r_c = edf['rotated_r_c']\n",
    "  time_step = float(t_window_width) / t_width_factor\n",
    "  all_avgs = np.array(r_r_c.groupby(level=0).transform('mean').to_list()).ravel()\n",
    "  all_dists = np.abs(r_r_c - all_avgs)\n",
    "  all_sigms = np.array(r_r_c.groupby(level=0).transform('std').to_list()).ravel()\n",
    "\n",
    "  edf['mean_rotated_r_c'] = all_avgs\n",
    "  edf['dist_from_mean_rotated_r_c'] = all_dists\n",
    "  edf['rotated_r_c_sigm'] = all_sigms\n",
    "\n",
    "  # Compute beta_step and r_step using NumPy functions\n",
    "  beta_step = np.ptp(edf['beta'].values) # не факт что нужно values\n",
    "  r_step = np.ptp(edf['true_r_from_beta'].values)\n",
    "\n",
    "  # Compute beta_intervals using NumPy linspace function\n",
    "  num_of_groups = num_of_groups\n",
    "  beta_intervals = np.linspace(edf['beta'].min(), edf['beta'].max(), num=num_of_groups)\n",
    "\n",
    "  # Compute beta_group_to_bdf and true_r_group using NumPy operations\n",
    "  beta_group = np.floor((num_of_groups * edf['beta'] + max(edf['beta']) - (num_of_groups + 1) * min(edf['beta'])) / beta_step).values\n",
    "  true_r_group = np.floor((num_of_groups * edf['true_r_from_beta'] + max(edf['true_r_from_beta']) - (num_of_groups + 1) * min(edf['true_r_from_beta'])) / r_step).values\n",
    "\n",
    "  edf['beta_group'] = beta_group\n",
    "  edf['true_r_group'] = true_r_group\n",
    "\n",
    "  edf_to_bdf(edf.beta_group, bdf)\n",
    "  edf_to_bdf(edf.true_r_group, bdf)\n",
    "\n",
    "  edf_to_bdf(edf.theta_p, bdf)\n",
    "  bdf['cos_theta_p'] = np.cos(bdf['theta_p'])\n",
    "  # edf_to_bdf(edf.signal_counts, bdf)\n",
    "  edf_to_bdf(edf.beta, bdf)\n",
    "  edf_to_bdf(edf.true_r_from_beta, bdf)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def calculateSignalCounts(edf: pd.DataFrame, bdf: pd.DataFrame):\n",
    "  signal_counts = edf['signal'].groupby(level=0).sum()\n",
    "  bdf['signal_counts'] = signal_counts.values\n",
    "  edf['signal_counts'] = edf.signal.groupby(level=0).transform('sum').values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def rSlidingWindowLoop1(edf: pd.DataFrame, idf: pd.DataFrame, bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, step=float(idf.pixel_size), method='N/r', cal_arr=False, t_window_width=2,\n",
    "                        r_width_factor=2, t_width_factor=8, full_width_t_hist = True, weighed = True):\n",
    "  step = step / r_width_factor\n",
    "  time_step = float(t_window_width) / t_width_factor\n",
    "\n",
    "  r_slices = np.arange(0, 800, step=step)\n",
    "  t_slices = np.arange(0, 15, step=time_step)\n",
    "  phi_slices = np.array([-np.pi, -2.013, -0.671, 0, 0.671, 2.013, np.pi])\n",
    "\n",
    "  n_sigmas = np.ptp(avg_sigmas)\n",
    "  t_sigmas = np.ptp(avg_t_sigmas)\n",
    "  # all_counts_to_edf = np.zeros((n_sigmas, len(edf)))\n",
    "  all_counts_to_edf = np.zeros((n_sigmas, len(edf)))\n",
    "  all_calculated_r = np.zeros((n_sigmas, len(edf)))\n",
    "  all_calculated_r_from_2d = np.zeros((t_sigmas, n_sigmas, len(edf)))\n",
    "  cur_ind = 0\n",
    "  for i, (entry, subentry) in enumerate(edf[['rotated_r_c', 't_c', 'rotated_phi_c']].groupby(level=0)):\n",
    "    counts = np.zeros(r_slices.shape)\n",
    "    square_counts = np.zeros(shape=(r_slices.shape[0], t_slices.shape[0]))\n",
    "\n",
    "    mask = np.logical_and(subentry.rotated_r_c >= 16, subentry.rotated_r_c <= 80)\n",
    "    rotated_r_c = subentry.rotated_r_c[mask]\n",
    "    t_c = subentry.t_c[mask]\n",
    "    rotated_phi_c = subentry.rotated_phi_c[mask]\n",
    "\n",
    "    counts, _ = np.histogram(rotated_r_c, bins=r_slices)\n",
    "    square_counts, _, __ = np.histogram2d(rotated_r_c, t_c, bins=(r_slices, t_slices))\n",
    "\n",
    "    if method == 'N/r':\n",
    "      counts = np.divide(np.add(counts[:-1], counts[1:]), r_slices[1:-1])\n",
    "      shift = 0\n",
    "      square_counts[:-1, :] = np.divide(np.add(square_counts[:-1, :], square_counts[1:, :]), r_slices[1:-1-shift*2, np.newaxis])\n",
    "\n",
    "    if full_width_t_hist:\n",
    "      square_counts_but_last = sum([square_counts[:, it : -t_width_factor + 1 + it] for it in range(t_width_factor - 1)])\n",
    "      square_counts = np.add(square_counts_but_last, square_counts[:, t_width_factor - 1:])\n",
    "\n",
    "    max_index = np.argmax(counts)\n",
    "\n",
    "    max_index_2d = np.unravel_index(np.argmax(square_counts), square_counts.shape)\n",
    "\n",
    "    for j in range(n_sigmas):\n",
    "      all_counts_to_edf[j][cur_ind:subentry.shape[0] + cur_ind] = counts[np.floor_divide(subentry.rotated_r_c, step).astype(int)] # fixed\n",
    "      # avg_r_from_slices = local_weighed_sum(r_slices, counts, max_index, j + avg_sigmas[0], method)\n",
    "      # all_calculated_r[j, cur_ind:subentry.shape[0] + cur_ind] = np.repeat(avg_r_from_slices, subentry.shape[0])\n",
    "      for t in range(t_sigmas):\n",
    "        if weighed:\n",
    "          avg_r_from_2d_slices = local_weighed_sum_2d(r_slices, t_slices, square_counts, max_index_2d, j + avg_sigmas[0], t + avg_t_sigmas[0])\n",
    "        else:\n",
    "          avg_r_from_2d_slices = local_sum_2d(subentry, r_slices, t_slices, square_counts, max_index_2d, j + avg_sigmas[0], t + avg_t_sigmas[0], t_window_width=t_window_width, timestep=time_step)\n",
    "\n",
    "        # if np.isnan(avg_r_from_2d_slices):\n",
    "        #   print(max_index_2d)\n",
    "        #   print(square_counts[max_index_2d[0] - 1:max_index_2d[0] + 2, max_index_2d[1] - 1: max_index_2d[1] + 2])\n",
    "        #   raise ValueError\n",
    "        all_calculated_r_from_2d[t, j, cur_ind:subentry.shape[0] + cur_ind] = np.repeat(avg_r_from_2d_slices, subentry.shape[0])\n",
    "\n",
    "    cur_ind += subentry.shape[0]\n",
    "  for j in range(n_sigmas):\n",
    "    edf[f'slice_counts_{j + avg_sigmas[0]}_sigms'] = all_counts_to_edf[j]\n",
    "    # edf[f'unfixed_calculated_r_{j + avg_sigmas[0]}_sigms'] = all_calculated_r[j, :]\n",
    "    for t in range(t_sigmas):\n",
    "      edf[f'unfixed_calculated_r_2d_{j + avg_sigmas[0]}_rsigms_{t + avg_t_sigmas[0]}_tsigms'] = all_calculated_r_from_2d[t, j, :]\n",
    "      edf_to_bdf(edf[f'unfixed_calculated_r_2d_{j + avg_sigmas[0]}_rsigms_{t + avg_t_sigmas[0]}_tsigms'], bdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "def rSlidingWindowLoop2(edf: pd.DataFrame, idf: pd.DataFrame, bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, step=float(idf.pixel_size), method='N/r', cal_arr=False, t_window_width=2,\n",
    "                        r_width_factor=2, t_width_factor=8, full_width_t_hist = False, param_fit=False):\n",
    "\n",
    "  # cal_arr = np.array([np.array([np.array(y) for y in x]) for x in cal_arr])\n",
    "\n",
    "  edf_to_bdf(edf.theta_p, bdf)\n",
    "  bdf['cos_theta_p'] = np.cos(bdf['theta_p'])\n",
    "  edf['cos_theta_p'] = np.cos(edf['theta_p'])\n",
    "  theta_interval = np.ptp(bdf.cos_theta_p) / 10\n",
    "  theta_min = min(bdf.cos_theta_p)\n",
    "  theta_max = max(bdf.cos_theta_p)\n",
    "  edf_to_bdf(edf.beta, bdf)\n",
    "  edf_to_bdf(edf.true_r_from_beta, bdf)\n",
    "\n",
    "  for n_sigms in range(*avg_sigmas):\n",
    "    for t_sigms in range(*avg_t_sigmas):\n",
    "      meas_betas = np.zeros(edf.shape[0])\n",
    "      cur_ind = 0\n",
    "      # meas_betas = []\n",
    "      for entry, subentry in edf[f'unfixed_calculated_r_2d_{n_sigms}_rsigms_{t_sigms}_tsigms'].groupby(level=0):\n",
    "        if param_fit:\n",
    "          cos_theta_p = edf.cos_theta_p[entry].iloc[0]\n",
    "          meas_beta = pol(subentry.iloc[0], pol2(cos_theta_p, *cal_arr[n_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][0]),\n",
    "                          pol2(cos_theta_p, *cal_arr[n_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][1]),\n",
    "                          pol2(cos_theta_p, *cal_arr[n_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][2]))\n",
    "        else:\n",
    "          if edf.cos_theta_p[entry].iloc[0] != theta_max:\n",
    "            meas_beta = pol(subentry.iloc[0], *(cal_arr[n_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][(np.floor(((edf.cos_theta_p[entry].iloc[0]) - theta_min) / theta_interval)).astype(int)]))\n",
    "          else:\n",
    "            meas_beta = pol(subentry.iloc[0], *(cal_arr[n_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][9]))\n",
    "        meas_betas[cur_ind: subentry.shape[0] + cur_ind] = np.repeat(meas_beta, subentry.shape[0])\n",
    "        cur_ind += subentry.shape[0]\n",
    "        # for subsub in subentry:\n",
    "        #   meas_betas.append(meas_beta)  # FIXME\n",
    "      edf[f'beta_from_calc_r_{n_sigms}_rsigms_{t_sigms}_tsigms'] = meas_betas\n",
    "      edf[f'delta_beta_{n_sigms}_rsigms_{t_sigms}_tsigms'] = edf[f'beta_from_calc_r_{n_sigms}_rsigms_{t_sigms}_tsigms'] - edf['beta']\n",
    "      edf[f'eps_beta_{n_sigms}_rsigms_{t_sigms}_tsigms'] = edf[f'delta_beta_{n_sigms}_rsigms_{t_sigms}_tsigms'] / edf['beta'] * 100\n",
    "\n",
    "\n",
    "      edf_to_bdf(edf[f'beta_from_calc_r_{n_sigms}_rsigms_{t_sigms}_tsigms'], bdf)\n",
    "      edf_to_bdf(edf[f'delta_beta_{n_sigms}_rsigms_{t_sigms}_tsigms'], bdf)\n",
    "      edf_to_bdf(edf[f'eps_beta_{n_sigms}_rsigms_{t_sigms}_tsigms'], bdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def rSlidingWindow(edf: pd.DataFrame, idf: pd.DataFrame, bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, step=float(idf.pixel_size), method='N/r', cal_arr=False, t_window_width=2,\n",
    "                        r_width_factor=2, t_width_factor=8, full_width_t_hist = True, num_of_groups=5, weighed=True, deg_lim=False, param_fit=False):\n",
    "  rSlidingWindowIntro(edf, idf, bdf, avg_sigmas, avg_t_sigmas, step=step, method=method, cal_arr=cal_arr, t_window_width=t_window_width,\n",
    "                      r_width_factor=r_width_factor, t_width_factor=t_width_factor, num_of_groups=num_of_groups)\n",
    "  calculateSignalCounts(edf, bdf)\n",
    "  rSlidingWindowLoop1(edf, idf, bdf, avg_sigmas, avg_t_sigmas, step=step, method=method, cal_arr=cal_arr, t_window_width=t_window_width,\n",
    "                      r_width_factor=r_width_factor, t_width_factor=t_width_factor, full_width_t_hist=full_width_t_hist, weighed=weighed)\n",
    "  if cal_arr is False:\n",
    "    cal_arr = np.array(calibration(edf, bdf, avg_sigmas=avg_sigmas, avg_t_sigmas=avg_t_sigmas, step=step, t_window_width=t_window_width,\n",
    "                                   r_width_factor=r_width_factor, t_width_factor=t_width_factor, weighed=weighed, deg_lim=deg_lim, param_fit=param_fit)) # add r and t calibr - done\n",
    "  rSlidingWindowLoop2(edf, idf, bdf, avg_sigmas, avg_t_sigmas, step=step, method=method, cal_arr=cal_arr, t_window_width=t_window_width,\n",
    "                      r_width_factor=r_width_factor, t_width_factor=t_width_factor, param_fit=param_fit)\n",
    "  return cal_arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def rms90(arr):\n",
    "    # Calculate the mean and standard deviation of the array\n",
    "    arr = arr.dropna()\n",
    "    arr_mean = np.mean(arr)\n",
    "    arr_std = np.std(arr)\n",
    "\n",
    "    # Define the upper and lower limits for the 90% range\n",
    "    lower_limit = np.percentile(arr, 5)\n",
    "    upper_limit = np.percentile(arr, 95)\n",
    "    # print(lower_limit, upper_limit)\n",
    "    # print(arr)\n",
    "    # Select the values within the 90% range\n",
    "    arr_filtered = arr[(arr >= lower_limit) & (arr <= upper_limit)]\n",
    "    # print(arr_filtered)\n",
    "    assert arr_filtered.shape\n",
    "    # Calculate the root mean square of the filtered values\n",
    "    rms = np.std(arr_filtered)\n",
    "\n",
    "    return rms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def betaGroupsRMS90(bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, n = 5):\n",
    "  beta_sigms = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), n), 0.)\n",
    "  beta_epss = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), n), 0.)\n",
    "  beta_sigms_sigms = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), n), 0.)\n",
    "\n",
    "  for group in range(1, n + 1):\n",
    "    data = bdf[bdf['beta_group'] == group]\n",
    "    for i in range(np.ptp(avg_sigmas)):\n",
    "      for j in range(np.ptp(avg_t_sigmas)):\n",
    "        population_fourth_moment = np.mean(bdf[f'delta_beta_{i + avg_sigmas[0]}_rsigms_{j + avg_t_sigmas[0]}_tsigms'] ** 4)\n",
    "        sample_fourth_moment = np.mean(data[f'delta_beta_{i + avg_sigmas[0]}_rsigms_{j + avg_t_sigmas[0]}_tsigms'] ** 4)\n",
    "        # print(np.std(data[f'delta_beta_{i + avg_sigmas[0]}_rsigms_{j + avg_t_sigmas[0]}_tsigms']))\n",
    "        beta_sigms[i, j, group - 1] = rms90(data[f'delta_beta_{i + avg_sigmas[0]}_rsigms_{j + avg_t_sigmas[0]}_tsigms'])\n",
    "        # assert not np.isnan(beta_sigms[i, j, group - 1])\n",
    "        beta_epss[i, j, group - 1] = rms90(data[f'eps_beta_{i + avg_sigmas[0]}_rsigms_{j + avg_t_sigmas[0]}_tsigms'])\n",
    "        beta_sigms_sigms[i, j, group - 1] = np.sqrt(2 * np.abs(sample_fourth_moment - population_fourth_moment) / (data.shape[0]))\n",
    "\n",
    "  return beta_sigms, beta_epss, beta_sigms_sigms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def plot_final_graph(beta_sigms, beta_sigms_yerr, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, to_save=True, deg_lim=False, num_of_groups=10, iteration=0):\n",
    "  labels = ['0', '1e3', '1e4', '1e5', '1e6']\n",
    "  labels = ['DCR = ' + i + ' $Hz/mm^2$' for i in labels]\n",
    "  colors = ['c', 'y', 'g', 'r', 'm']\n",
    "  weight = 'weighed' if weighed else 'unweighed'\n",
    "  y = np.arange(1, num_of_groups + 1)\n",
    "  x = (y * (max(edf['beta']) - min(edf['beta'])) - max(edf['beta']) + (num_of_groups + 1) * min(edf['beta'])) / num_of_groups\n",
    "\n",
    "  fig, axs = plt.subplots(np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), figsize=(10 * np.ptp(avg_t_sigmas), 10 * np.ptp(avg_sigmas)))\n",
    "  title = f'Method: N(r) / r; {weight} Avg\\nR Width = {r_width}mm, T Width = {t_width}ns\\nR step factor = {r_factor}, T step factor = {t_factor}'\n",
    "  if deg_lim:\n",
    "    title += '\\n' + r'$\\theta_p < 10\\deg$'\n",
    "  # fig.suptitle(title)\n",
    "\n",
    "  if np.ptp(avg_sigmas) > 1:\n",
    "    for i in range(np.ptp(avg_sigmas)):\n",
    "      for j in range(np.ptp(avg_t_sigmas)):\n",
    "        for k in range(beta_sigms.shape[0]):\n",
    "          axs[i, j].plot(x, beta_sigms[k, i, j], label=labels[k], c=colors[k])\n",
    "          axs[i, j].errorbar(x, beta_sigms[k, i, j], xerr=[np.diff(x)[0]/4 for _ in x], linestyle='', c=colors[k])\n",
    "          axs[i, j].errorbar(x, beta_sigms[k, i, j], yerr=beta_sigms_yerr[k, i, j], linestyle='', c=colors[k])\n",
    "        axs[i, j].legend(loc='upper right')\n",
    "        axs[i, j].set_xlabel('Beta Group')\n",
    "        axs[i, j].set_ylabel(r'RMS90($\\Delta\\beta$)')\n",
    "        if deg_lim:\n",
    "          axs[i, j].set_ylim((0, 0.004))\n",
    "        axs[i, j].set_title(f'Velocity resoultion for\\nr window width = {avg_sigmas[0] + i}$\\sigma$\\nt window width = {avg_t_sigmas[0] + j}$\\sigma$')\n",
    "        axs[i, j].grid()\n",
    "  elif np.ptp(avg_t_sigmas) > 1:\n",
    "    for j in range(np.ptp(avg_t_sigmas)):\n",
    "      for k in range(beta_sigms.shape[0]):\n",
    "        axs[j].plot(x, beta_sigms[k, 0, j], label=labels[k], c=colors[k])\n",
    "        axs[j].errorbar(x, beta_sigms[k, 0, j], xerr=[np.diff(x)[0]/4 for _ in x], linestyle='', c=colors[k])\n",
    "        axs[j].errorbar(x, beta_sigms[k, 0, j], yerr=beta_sigms_yerr[k, 0, j], linestyle='', c=colors[k])\n",
    "      axs[j].legend(loc='upper right')\n",
    "      axs[j].set_xlabel('Beta Group')\n",
    "      axs[j].set_ylabel(r'RMS90($\\Delta\\beta)$')\n",
    "      if deg_lim:\n",
    "        axs[j].set_ylim((0, 0.004))\n",
    "      axs[j].set_title(f'Velocity resoultion for\\nr window width = {avg_sigmas[0]}$\\sigma$\\nt window width = {avg_t_sigmas[0] + j}$\\sigma$')\n",
    "      axs[j].grid()\n",
    "  else:\n",
    "    for k in range(beta_sigms.shape[0]):\n",
    "      axs.plot(x, beta_sigms[k, 0, 0], label=labels[k], c=colors[k])\n",
    "      axs.errorbar(x, beta_sigms[k, 0, 0], xerr=[np.diff(x)[0]/4 for _ in x], linestyle='', c=colors[k])\n",
    "      axs.errorbar(x, beta_sigms[k, 0, 0], yerr=beta_sigms_yerr[k, 0, 0], linestyle='', c=colors[k])\n",
    "    axs.legend(loc='upper right')\n",
    "    axs.set_xlabel('Beta Group')\n",
    "    axs.set_ylabel(r'RMS90($\\Delta\\beta$)')\n",
    "    if deg_lim:\n",
    "      axs.set_ylim((0, 0.002))\n",
    "    axs.set_title(f'Velocity resoultion for\\nr window width = {avg_sigmas[0]}$\\sigma$\\nt window width = {avg_t_sigmas[0]}$\\sigma$')\n",
    "    axs.grid()\n",
    "\n",
    "  if to_save:\n",
    "    filename = f'{weight}_avg_rw={r_width}_tw={t_width}_rs={r_factor}_ts={t_factor}_rsigms={avg_sigmas[0]}-{avg_sigmas[-1]-1}_tsigms={avg_t_sigmas[0]}-{avg_t_sigmas[-1]-1}'\n",
    "    if deg_lim:\n",
    "      filename += '_10deg'\n",
    "    filename += f'_{iteration}'\n",
    "    filename += '.png'\n",
    "    fig.savefig(os.path.join('results', f'{filename}'))\n",
    "    plt.close(fig)\n",
    "  else:\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def plot_groupped_distributions(bdf, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, background, to_save=True, deg_lim=False, num_of_groups=10):\n",
    "  labels = ['0', '1e3', '1e4', '1e5', '1e6']\n",
    "  labels = ['DCR = ' + i + ' cps' for i in labels]\n",
    "  colors = ['c', 'y', 'g', 'r', 'm']\n",
    "  weight = 'weighed' if weighed else 'unweighed'\n",
    "  left_lim = min(bdf[f'delta_beta_{avg_sigmas[0]}_rsigms_{avg_t_sigmas[0]}_tsigms'])\n",
    "  right_lim = max(bdf[f'delta_beta_{avg_sigmas[0]}_rsigms_{avg_t_sigmas[0]}_tsigms'])\n",
    "  y = np.arange(1, num_of_groups + 1)\n",
    "  x = (y * (max(edf['beta']) - min(edf['beta'])) - max(edf['beta']) + (num_of_groups + 1) * min(edf['beta'])) / num_of_groups\n",
    "  x_interval_over_2 = (x[1] - x[0]) / 2\n",
    "  fig, axs = plt.subplots(num_of_groups, 1, figsize=(16, 9 * num_of_groups), sharex=True)\n",
    "  title = f'Method: N(r) / r; {weight} Avg\\nR Width = {r_width}mm, T Width = {t_width}ns\\nR step factor = {r_factor}, T step factor = {t_factor}, DCR={background}'\n",
    "  if deg_lim:\n",
    "    title += '\\n' + r'$\\theta_p < 10\\deg$'\n",
    "  # fig.suptitle(title)\n",
    "  fig.tight_layout()\n",
    "  if np.ptp(avg_sigmas) > 1:\n",
    "    pass\n",
    "  elif np.ptp(avg_t_sigmas) > 1:\n",
    "    pass\n",
    "  else:\n",
    "    for group in range(1, num_of_groups + 1):\n",
    "      data = bdf[bdf['beta_group'] == group]\n",
    "      # data = data.dropna()\n",
    "      # print(data.shape)\n",
    "      # bin_heights, bin_borders = np.histogram(data[f'delta_beta_{avg_sigmas[0]}_rsigms_{avg_t_sigmas[0]}_tsigms'], bins='auto', normed=True)\n",
    "      # bin_width = np.diff(bin_borders)\n",
    "      axs[group - 1].hist(data[f'delta_beta_{avg_sigmas[0]}_rsigms_{avg_t_sigmas[0]}_tsigms'], bins='auto')\n",
    "      # axs[group - 1].set_xlabel(r'$\\Delta\\beta$')\n",
    "      axs[group - 1].set_ylabel(r'Events')\n",
    "      axs[group - 1].set_title(r'$\\beta$ in ' + f'[{round(x[group - 1] - x_interval_over_2, 3)}, {round(x[group -1 ] + x_interval_over_2, 3)}]')\n",
    "      axs[group - 1].set_xlim((-0.05, 0.08))\n",
    "\n",
    "  if to_save:\n",
    "    filename = f'Hist_{weight}_avg_rw={r_width}_tw={t_width}_rs={r_factor}_ts={t_factor}_rsigms={avg_sigmas[0]}-{avg_sigmas[-1]-1}_tsigms={avg_t_sigmas[0]}-{avg_t_sigmas[-1]-1}_background={background}'\n",
    "    if deg_lim:\n",
    "      filename += '_10deg'\n",
    "    filename += '.png'\n",
    "    fig.savefig(os.path.join('results', f'{filename}'))\n",
    "    plt.close(fig)\n",
    "  else:\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# print([[[]]* 5] * 5)\n",
    "# print(cal_arr.shape) # r_sigms -> t_sigms -> thetq_groups -> 3 params\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def pol2old(x, b, c, d):\n",
    "  return b * x ** 2 + c * x + d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def pol2(x, p0, p1, p2):\n",
    "  return p0 + p1 * x + p2 * x ** 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "def d3pol2(X, p0, p1, p2, q0, q1, q2, k0, k1, k2):\n",
    "  r, theta = X\n",
    "  # return pol(r, pol2(theta, p0, p1, p2), pol2(theta, q0, q1, q2), pol2(theta, k0, k1, k2))\n",
    "  return pol(r, p0 + p1 * theta + p2 * theta ** 2, q0 + q1 * theta + q2 * theta ** 2, k0 + k1 * theta + k2 * theta ** 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calibration(edf: pd.DataFrame, bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, step=float(idf.pixel_size), method='N/r', t_window_width=2,\n",
    "                        r_width_factor=2, t_width_factor=8, full_width_t_hist = False, weighed=True, deg_lim=False, param_fit=False):\n",
    "  def gaussian(x, mean, sigma):\n",
    "    return norm.pdf(x, loc=mean, scale=sigma)\n",
    "  # to_return_unbinned = [[], [], [], []]\n",
    "  bdf['cos_theta_p'] = np.cos(bdf['theta_p'])\n",
    "  theta_p_max = max(bdf.cos_theta_p)\n",
    "  theta_p_min = min(bdf.cos_theta_p)\n",
    "  num_of_theta_intervals = 11\n",
    "  theta_intervals = np.linspace(theta_p_min, theta_p_max, num=num_of_theta_intervals)\n",
    "  theta_dif = (theta_intervals[1:] + theta_intervals[:-1]) / 2\n",
    "  to_return_unbinned = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), num_of_theta_intervals - 1, 3), 0.)\n",
    "\n",
    "  errs_tmp = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), num_of_theta_intervals - 1, 3), 0.)\n",
    "  fit_params = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), 3, 3), 0.)\n",
    "\n",
    "  weight = 'weighed' if weighed else 'unweighed'\n",
    "  beta_min = min(bdf.beta)\n",
    "  num_of_beta_intervals = 10 # was 20\n",
    "  beta_delim = (max(bdf.beta) - min(bdf.beta)) / num_of_beta_intervals\n",
    "  beta_intervals = np.linspace(min(bdf.beta), max(bdf.beta), num=num_of_beta_intervals + 1)\n",
    "  dir_to_save = f'{weight}_rw={step}_tw={t_window_width}_rs={r_width_factor}_ts={t_width_factor}'\n",
    "  if not os.path.exists(os.path.join('calibrations', dir_to_save)):\n",
    "    os.mkdir(os.path.join('calibrations', dir_to_save))\n",
    "  for r_sigms in range(*avg_sigmas):\n",
    "    fig, axs = plt.subplots(num_of_theta_intervals - 1, np.ptp(avg_t_sigmas), figsize=(16 * np.ptp(avg_t_sigmas), 90))\n",
    "    for t_sigms in range(*avg_t_sigmas):\n",
    "      chosen_column = f'unfixed_calculated_r_2d_{r_sigms}_rsigms_{t_sigms}_tsigms'\n",
    "\n",
    "      meas_r_min = min(bdf[chosen_column])\n",
    "      meas_r_max = max(bdf[chosen_column])\n",
    "      num_of_meas_r_intervals = num_of_beta_intervals\n",
    "      meas_r_delim = (meas_r_max - meas_r_min) / num_of_meas_r_intervals\n",
    "      meas_r_intervals = np.linspace(meas_r_min, meas_r_max, num=num_of_meas_r_intervals + 1)\n",
    "\n",
    "\n",
    "      # fig2, axs2 = plt.subplots(10* num_of_theta_intervals - 10, 10, figsize=(16, 90))\n",
    "\n",
    "      for theta_interval_index in range(num_of_theta_intervals - 1):\n",
    "        xerrs = []\n",
    "        yerrs = []\n",
    "        gauss_beta = []\n",
    "        gauss_r = []\n",
    "        t_bdf = bdf.copy()\n",
    "        t_bdf = t_bdf[np.isfinite(t_bdf[chosen_column])]\n",
    "        t_bdf = t_bdf[t_bdf.signal_counts >= 15]\n",
    "        t_bdf = t_bdf[t_bdf.cos_theta_p <= theta_intervals[theta_interval_index + 1]]\n",
    "        t_bdf = t_bdf[t_bdf.cos_theta_p >= theta_intervals[theta_interval_index]]\n",
    "        if t_sigms - avg_t_sigmas[0] != 0:\n",
    "          for_colorbar = axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].hist2d(t_bdf[chosen_column], t_bdf.beta, bins=70, range=((0, 80), (beta_min,1)))\n",
    "          fig.colorbar(for_colorbar[3], ax=axs[theta_interval_index, t_sigms - avg_t_sigmas[0]])\n",
    "        else:\n",
    "          for_colorbar = axs[theta_interval_index].hist2d(t_bdf[chosen_column], t_bdf.beta, bins=70, range=((0, 80), (beta_min,1)))\n",
    "          fig.colorbar(for_colorbar[3], ax=axs[theta_interval_index])\n",
    "        t_bdf = t_bdf[t_bdf[chosen_column] <= 65]\n",
    "        t_bdf = t_bdf[t_bdf[chosen_column] >= 25]\n",
    "\n",
    "        pol_param, cov = curve_fit(pol, t_bdf[chosen_column], t_bdf.beta, maxfev=50000, p0=(1, 80, 30))\n",
    "        to_return_unbinned[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][theta_interval_index] = pol_param\n",
    "        pol_param_errs = np.sqrt(np.diag(cov))\n",
    "        errs_tmp[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][theta_interval_index] = pol_param_errs\n",
    "        rs = np.linspace(10, 80, num=50)\n",
    "        chi2 = np.sum((t_bdf.beta - pol(t_bdf[chosen_column], *pol_param)) ** 2)\n",
    "\n",
    "        if t_sigms - avg_t_sigmas[0] != 0:\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].plot(rs, pol(rs, *pol_param), label=r'$\\chi^2$ = '+ str(chi2), c='r')\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].set_xlim((0, 90))\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].set_ylim((0.955, 1))\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].set_ylim((beta_min, 1))\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].set_xlabel(r'$R_{reco}$, mm')\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].set_ylabel(r'$\\beta_{true}$')\n",
    "        else:\n",
    "          axs[theta_interval_index].plot(rs, pol(rs, *pol_param), label=r'$\\chi^2$ = '+ str(chi2), c='r')\n",
    "          axs[theta_interval_index].set_xlim((0, 90))\n",
    "          axs[theta_interval_index].set_ylim((0.955, 1))\n",
    "          axs[theta_interval_index].set_ylim((beta_min, 1))\n",
    "          axs[theta_interval_index].set_xlabel(r'$R_{reco}$, mm')\n",
    "          axs[theta_interval_index].set_ylabel(r'$\\beta_{true}$')\n",
    "      if param_fit:\n",
    "        t_bdf = bdf.copy()\n",
    "        t_bdf = t_bdf[np.isfinite(t_bdf[chosen_column])]\n",
    "        t_bdf = t_bdf[t_bdf.signal_counts >= 5]\n",
    "        X = (np.array(t_bdf[chosen_column]), np.array(t_bdf.cos_theta_p))\n",
    "        fit, errs = curve_fit(d3pol2, X, t_bdf.beta, p0=(1.219, -0.5588, 0.2946, 864.4, -1922, 1055, -2535, 6572, -3751))\n",
    "        errs = np.sqrt(np.diag(errs))\n",
    "        for param in range(3):\n",
    "          fit_params[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][param] = fit[param * 3: param * 3 + 3]\n",
    "        # print(fit)\n",
    "        # print(errs)\n",
    "        chi2 = np.sum((t_bdf.beta - d3pol2(X, *fit)) ** 2)\n",
    "        # print(chi2)\n",
    "      # if param_fit:\n",
    "      #   for param in range(3):\n",
    "      #     fit, _ = curve_fit(pol2, theta_dif, to_return_unbinned[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][:, param], sigma=errs_tmp[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][:, param])\n",
    "      #     fit_params[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][param] = fit\n",
    "    filename = f'rsigm={r_sigms}_t_sigms={avg_t_sigmas[0]}-{avg_t_sigmas[-1] - 1}'\n",
    "    if deg_lim:\n",
    "      filename += '_10deg'\n",
    "    if dir_to_save != '':\n",
    "      fig.savefig(os.path.join('calibrations', dir_to_save, f'{filename}'))\n",
    "      plt.close(fig)\n",
    "\n",
    "\n",
    "  if param_fit:\n",
    "    return fit_params\n",
    "  return to_return_unbinned\n",
    "# cal_arr = np.array(calibration(edf, bdf, avg_sigmas=(1, 5), avg_t_sigmas=(1, 5))) # add r and t calibr - done"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ы' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [92], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mы\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'ы' is not defined"
     ]
    }
   ],
   "source": [
    "ы"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "  print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# With DCR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f4VM3-a7N3wA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652899028826,
     "user_tz": -180,
     "elapsed": 22573,
     "user": {
      "displayName": "Платон Дмитриевич Рогожин",
      "userId": "06374754299160062301"
     }
    },
    "outputId": "9c993c1f-f0b0-40cf-c4f8-0190fe507ae2",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "event = 1444\n",
    "#momentum = edf.at[(event, 0), 'momentum']\n",
    "#theta_p = edf.at[(event, 0), 'theta_p']*180/np.pi\n",
    "avg_sigmas=(4, 5)\n",
    "avg_t_sigmas=(4, 5)\n",
    "num_of_groups = 10\n",
    "r_width = float(idf.pixel_size)\n",
    "t_width = 0.25\n",
    "t_step = 0.25\n",
    "r_factor = 2 # not to change\n",
    "t_factor = int(t_width / t_step)\n",
    "weighed = False\n",
    "deg_lim = False\n",
    "param_fit = True # WORKS\n",
    "sample_size = 1\n",
    "overall_timer_start = perf_counter()\n",
    "for t_width in [0.25]: # [0.25, 0.5, 0.75, 1]\n",
    "  for t_step in [0.25]: # [0.25, 0.5]\n",
    "    for r_width in [2 * float(idf.pixel_size)]: # [float(idf.pixel_size), 2 * float(idf.pixel_size)]\n",
    "      for weighed in [True]: # [False, True]\n",
    "        for iteration in range(10):\n",
    "          cal_arr_for_dcr = False\n",
    "          beta_sigms = []\n",
    "          beta_sigms_yerr = []\n",
    "          beta_sigms_deglim = []\n",
    "          beta_sigms_yerr_deglim = []\n",
    "          print(f'Generating Iteration {iteration}\\n')\n",
    "          for dcr in ['0', '1e3', '1e4', '1e5', '1e6']  : # ['0', '1e3', '1e4', '1e5', '1e6']\n",
    "            timer_start = perf_counter()\n",
    "            gen = genChunkFromRoot(filepath, 10000, noisefreqpersqmm=float(dcr), shiftSignalTimes=True, to_skip=12*iteration)\n",
    "            c_bdf_d = pd.DataFrame()\n",
    "            print(f'Skipping {12*iteration}...')\n",
    "            for i in range(12 * iteration):\n",
    "              edf_d = next(gen)\n",
    "            print(f'Skipped {12*iteration}')\n",
    "            for i in range(sample_size):\n",
    "              edf_d = next(gen)\n",
    "              print(f' {i+1}/{sample_size}')\n",
    "              # edf_d = next(genChunkFromRoot(filepath, 10000, noisefreqpersqmm=float(dcr), shiftSignalTimes=True))\n",
    "\n",
    "              bdf_d = pd.DataFrame()\n",
    "              # signalLength(edf_d)\n",
    "              recoAngles(edf_d, idf)\n",
    "              edf_d = applySpaceCut(edf_d)\n",
    "              planeRecalculation(edf_d, idf)\n",
    "              planeRotation(edf_d)\n",
    "              edf_d = applySecondSpaceCut(edf_d)\n",
    "              primaryDirectionRecalculation(edf_d)\n",
    "\n",
    "              recoAngles(edf_d, idf, rotation_mode=True)\n",
    "              cal_arr_for_dcr = rSlidingWindow(edf_d, idf, bdf_d, avg_sigmas=avg_sigmas, avg_t_sigmas=avg_t_sigmas, cal_arr=cal_arr_for_dcr, num_of_groups=num_of_groups,\n",
    "                                               step=r_width, t_window_width=t_width, r_width_factor=r_factor, t_width_factor=t_factor, weighed=weighed, deg_lim=deg_lim, param_fit=param_fit)\n",
    "\n",
    "              if deg_lim:\n",
    "                edf_d = edf_d[edf_d.theta_p <= 10. * np.pi / 180]\n",
    "                edf_d = edf_d[edf_d.signal_counts >= 5]\n",
    "                bdf_d = bdf_d[bdf_d.theta_p <= 10. * np.pi / 180]\n",
    "                bdf_d = bdf_d[bdf_d.signal_counts >= 5]\n",
    "              if i == 0:\n",
    "                c_bdf_d = bdf_d\n",
    "              else:\n",
    "                c_bdf_d = pd.concat([c_bdf_d, bdf_d], ignore_index=True)\n",
    "            # plot_groupped_distributions(c_bdf_d, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, background=dcr, deg_lim=False, num_of_groups=num_of_groups, to_save=True)\n",
    "            bg = betaGroupsRMS90(c_bdf_d, avg_sigmas=avg_sigmas, avg_t_sigmas=avg_t_sigmas, n=num_of_groups)\n",
    "            beta_sigms.append(bg[0])\n",
    "            beta_sigms_yerr.append(bg[2])\n",
    "\n",
    "            c_bdf_d = c_bdf_d[c_bdf_d.theta_p <= 10. * np.pi / 180]\n",
    "            c_bdf_d = c_bdf_d[c_bdf_d.signal_counts >= 5]\n",
    "\n",
    "            # plot_groupped_distributions(c_bdf_d, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, background=dcr, deg_lim=True, num_of_groups=num_of_groups, to_save=True)\n",
    "            bg_deglim = betaGroupsRMS90(c_bdf_d, avg_sigmas=avg_sigmas, avg_t_sigmas=avg_t_sigmas, n=num_of_groups)\n",
    "            beta_sigms_deglim.append(bg_deglim[0])\n",
    "            beta_sigms_yerr_deglim.append(bg_deglim[2])\n",
    "            print('Time elapsed on current DCR: ', perf_counter() - timer_start)\n",
    "            print('Total Time elapsed: ', perf_counter() - overall_timer_start)\n",
    "\n",
    "            # plothits(edf_d, 1, event, dir_to_save=f'event_{event}_{dcr}_noise')\n",
    "\n",
    "            #figxy.savefig(os.path.join(picsdir, f'labeled_ring_pi_p{momentum:.0f}mev_theta{theta_p:.0f}deg_dcr{dcr:.3g}.png'))\n",
    "            #figtime.savefig(os.path.join(picsdir, f'labeled_time_pi_p{momentum:.0f}mev_theta{theta_p:.0f}deg_dcr{dcr:.3g}.png'))\n",
    "          beta_sigms = np.array(beta_sigms)\n",
    "          beta_sigms_yerr = np.array(beta_sigms_yerr)\n",
    "          beta_sigms_deglim = np.array(beta_sigms_deglim)\n",
    "          beta_sigms_yerr_deglim = np.array(beta_sigms_yerr_deglim)\n",
    "          betas_df = pd.DataFrame()\n",
    "          for it, dcr in enumerate(['0', '1e3', '1e4', '1e5', '1e6']):\n",
    "            betas_df[f'RMS90_{dcr}_cps'] = beta_sigms[it][0][0]\n",
    "            betas_df[f'yerr_{dcr}_cps'] = beta_sigms_yerr[it][0][0]\n",
    "            betas_df[f'deglim_RMS90_{dcr}_cps'] = beta_sigms_deglim[it][0][0]\n",
    "            betas_df[f'deglim_yerr_{dcr}_cps'] = beta_sigms_yerr_deglim[it][0][0]\n",
    "          betas_df.to_csv(f'Results_{iteration}.csv', header=True, index=False)\n",
    "\n",
    "          plot_final_graph(beta_sigms, beta_sigms_yerr, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, deg_lim=False, num_of_groups=num_of_groups, iteration=iteration)\n",
    "\n",
    "          plot_final_graph(beta_sigms_deglim, beta_sigms_yerr_deglim, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, deg_lim=True, num_of_groups=num_of_groups, iteration=iteration)\n",
    "\n",
    "print(perf_counter() - overall_timer_start)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Iteration 0\n",
      "\n",
      "Skipping 0...\n",
      "Skipped 0\n",
      "    Generate noise with DCR per mm^2 0.0, mean number of hits per event: 0.00. 1/1\n",
      "[ 7.32314156e-01  6.13332477e-01 -4.19087064e-01 -3.84580119e+02\n",
      "  1.07585654e+03 -7.55051918e+02  1.12994026e+03 -2.09370474e+03\n",
      "  1.39600554e+03]\n",
      "[2.47453718e-02 6.06337294e-02 3.73193133e-02 5.34904198e+01\n",
      " 1.26942891e+02 7.56488337e+01 1.68458190e+02 3.84236095e+02\n",
      " 2.17469981e+02]\n",
      "0.039539050848318234\n",
      "Time elapsed on current DCR:  25.171756799998548\n",
      "Total Time elapsed:  25.172266300000047\n",
      "Skipping 0...\n",
      "Skipped 0\n",
      "    Generate noise with DCR per mm^2 1000.0, mean number of hits per event: 4.03. 1/1\n",
      "Time elapsed on current DCR:  24.396380899997894\n",
      "Total Time elapsed:  49.568881899998814\n",
      "Skipping 0...\n",
      "Skipped 0\n",
      "    Generate noise with DCR per mm^2 10000.0, mean number of hits per event: 40.26. 1/1\n",
      "Time elapsed on current DCR:  25.707965099998546\n",
      "Total Time elapsed:  75.27692190000016\n",
      "Skipping 0...\n",
      "Skipped 0\n",
      "    Generate noise with DCR per mm^2 100000.0, mean number of hits per event: 402.62. 1/1\n",
      "Time elapsed on current DCR:  28.314630599998054\n",
      "Total Time elapsed:  103.59163320000152\n",
      "Skipping 0...\n",
      "Skipped 0\n",
      "    Generate noise with DCR per mm^2 1000000.0, mean number of hits per event: 4026.19. 1/1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Skipping 1/108\n",
      " Skipping 2/108\n",
      " Skipping 3/108\n",
      " Skipping 4/108\n",
      " Skipping 5/108\n",
      " Skipping 6/108\n",
      " Skipping 7/108\n",
      " Skipping 8/108\n",
      " Skipping 9/108\n",
      " Skipping 10/108\n",
      " Skipping 11/108\n",
      " Skipping 12/108\n",
      " Skipping 13/108\n",
      " Skipping 14/108\n",
      " Skipping 15/108\n",
      " Skipping 16/108\n",
      " Skipping 17/108\n",
      " Skipping 18/108\n",
      " Skipping 19/108\n",
      " Skipping 20/108\n",
      " Skipping 21/108\n",
      " Skipping 22/108\n",
      " Skipping 23/108\n",
      " Skipping 24/108\n",
      " Skipping 25/108\n",
      " Skipping 26/108\n",
      " Skipping 27/108\n",
      " Skipping 28/108\n",
      " Skipping 29/108\n",
      " Skipping 30/108\n",
      " Skipping 31/108\n",
      " Skipping 32/108\n",
      " Skipping 33/108\n",
      " Skipping 34/108\n",
      " Skipping 35/108\n",
      " Skipping 36/108\n",
      " Skipping 37/108\n",
      " Skipping 38/108\n",
      " Skipping 39/108\n",
      " Skipping 40/108\n",
      " Skipping 41/108\n",
      " Skipping 42/108\n",
      " Skipping 43/108\n",
      " Skipping 44/108\n",
      " Skipping 45/108\n",
      " Skipping 46/108\n",
      " Skipping 47/108\n",
      " Skipping 48/108\n",
      " Skipping 49/108\n",
      " Skipping 50/108\n",
      " Skipping 51/108\n",
      " Skipping 52/108\n",
      " Skipping 53/108\n",
      " Skipping 54/108\n",
      " Skipping 55/108\n",
      " Skipping 56/108\n",
      " Skipping 57/108\n",
      " Skipping 58/108\n",
      " Skipping 59/108\n",
      " Skipping 60/108\n",
      " Skipping 61/108\n",
      " Skipping 62/108\n",
      " Skipping 63/108\n",
      " Skipping 64/108\n",
      " Skipping 65/108\n",
      " Skipping 66/108\n",
      " Skipping 67/108\n",
      " Skipping 68/108\n",
      " Skipping 69/108\n",
      " Skipping 70/108\n",
      " Skipping 71/108\n",
      " Skipping 72/108\n",
      " Skipping 73/108\n",
      " Skipping 74/108\n",
      " Skipping 75/108\n",
      " Skipping 76/108\n",
      " Skipping 77/108\n",
      " Skipping 78/108\n",
      " Skipping 79/108\n",
      " Skipping 80/108\n",
      " Skipping 81/108\n",
      " Skipping 82/108\n",
      " Skipping 83/108\n",
      " Skipping 84/108\n",
      " Skipping 85/108\n",
      " Skipping 86/108\n",
      " Skipping 87/108\n",
      " Skipping 88/108\n",
      " Skipping 89/108\n",
      " Skipping 90/108\n",
      " Skipping 91/108\n",
      " Skipping 92/108\n",
      " Skipping 93/108\n",
      " Skipping 94/108\n",
      " Skipping 95/108\n",
      " Skipping 96/108\n",
      " Skipping 97/108\n",
      " Skipping 98/108\n",
      " Skipping 99/108\n",
      " Skipping 100/108\n",
      " Skipping 101/108\n",
      " Skipping 102/108\n",
      " Skipping 103/108\n",
      " Skipping 104/108\n",
      " Skipping 105/108\n",
      " Skipping 106/108\n",
      " Skipping 107/108\n",
      " Skipping 108/108\n"
     ]
    }
   ],
   "source": [
    "gen = genChunkFromRoot(filepath, 10000, noisefreqpersqmm=float(dcr), shiftSignalTimes=True, to_skip=12*iteration)\n",
    "for i in range(12 * iteration):\n",
    "  t = next(gen)\n",
    "  print(f' Skipping {i+1}/{12*iteration}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Generate noise with DCR per mm^2 1000000.0, mean number of hits per event: 4026.19."
     ]
    },
    {
     "data": {
      "text/plain": "                         x_c         y_c         z_c       t_c  signal  nhits   \nentry   subentry                                                                \n1080000 0        -122.879997  105.279999  201.050003  1.753335    True   4126  \\\n        1         -39.840000 -105.279999  201.050003  1.900948    True   4126   \n        2          -5.440000  -60.799999  201.050003  1.492268    True   4126   \n        3          18.879999   29.760000  201.050003  1.463777    True   4126   \n        4           8.800000   53.279999  201.050003  1.477835    True   4126   \n...                      ...         ...         ...       ...     ...    ...   \n1089999 3983      351.040009   39.840000  201.050003  3.227188   False   3988   \n        3984     -351.040009  295.679993  201.050003  1.000412   False   3988   \n        3985     -309.920013  -36.480000  201.050003  5.732517   False   3988   \n        3986      351.040009  351.040009  201.050003  0.976915   False   3988   \n        3987     -409.760010 -164.000000  201.050003  5.585002   False   3988   \n\n                       x_p       y_p  z_p      nx_p      ny_p      nz_p   \nentry   subentry                                                          \n1080000 0         1.295658 -1.069564  0.0  0.195358  0.239113  0.951136  \\\n        1         1.295658 -1.069564  0.0  0.195358  0.239113  0.951136   \n        2         1.295658 -1.069564  0.0  0.195358  0.239113  0.951136   \n        3         1.295658 -1.069564  0.0  0.195358  0.239113  0.951136   \n        4         1.295658 -1.069564  0.0  0.195358  0.239113  0.951136   \n...                    ...       ...  ...       ...       ...       ...   \n1089999 3983     -1.345380 -1.618472  0.0  0.146940 -0.290678  0.945471   \n        3984     -1.345380 -1.618472  0.0  0.146940 -0.290678  0.945471   \n        3985     -1.345380 -1.618472  0.0  0.146940 -0.290678  0.945471   \n        3986     -1.345380 -1.618472  0.0  0.146940 -0.290678  0.945471   \n        3987     -1.345380 -1.618472  0.0  0.146940 -0.290678  0.945471   \n\n                      beta   theta_p     phi_p    momentum  \nentry   subentry                                            \n1080000 0         0.969949  0.313901  0.885769  556.397705  \n        1         0.969949  0.313901  0.885769  556.397705  \n        2         0.969949  0.313901  0.885769  556.397705  \n        3         0.969949  0.313901  0.885769  556.397705  \n        4         0.969949  0.313901  0.885769  556.397705  \n...                    ...       ...       ...         ...  \n1089999 3983      0.976841  0.331759  5.180434  637.191895  \n        3984      0.976841  0.331759  5.180434  637.191895  \n        3985      0.976841  0.331759  5.180434  637.191895  \n        3986      0.976841  0.331759  5.180434  637.191895  \n        3987      0.976841  0.331759  5.180434  637.191895  \n\n[40575725 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>x_c</th>\n      <th>y_c</th>\n      <th>z_c</th>\n      <th>t_c</th>\n      <th>signal</th>\n      <th>nhits</th>\n      <th>x_p</th>\n      <th>y_p</th>\n      <th>z_p</th>\n      <th>nx_p</th>\n      <th>ny_p</th>\n      <th>nz_p</th>\n      <th>beta</th>\n      <th>theta_p</th>\n      <th>phi_p</th>\n      <th>momentum</th>\n    </tr>\n    <tr>\n      <th>entry</th>\n      <th>subentry</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1080000</th>\n      <th>0</th>\n      <td>-122.879997</td>\n      <td>105.279999</td>\n      <td>201.050003</td>\n      <td>1.753335</td>\n      <td>True</td>\n      <td>4126</td>\n      <td>1.295658</td>\n      <td>-1.069564</td>\n      <td>0.0</td>\n      <td>0.195358</td>\n      <td>0.239113</td>\n      <td>0.951136</td>\n      <td>0.969949</td>\n      <td>0.313901</td>\n      <td>0.885769</td>\n      <td>556.397705</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-39.840000</td>\n      <td>-105.279999</td>\n      <td>201.050003</td>\n      <td>1.900948</td>\n      <td>True</td>\n      <td>4126</td>\n      <td>1.295658</td>\n      <td>-1.069564</td>\n      <td>0.0</td>\n      <td>0.195358</td>\n      <td>0.239113</td>\n      <td>0.951136</td>\n      <td>0.969949</td>\n      <td>0.313901</td>\n      <td>0.885769</td>\n      <td>556.397705</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-5.440000</td>\n      <td>-60.799999</td>\n      <td>201.050003</td>\n      <td>1.492268</td>\n      <td>True</td>\n      <td>4126</td>\n      <td>1.295658</td>\n      <td>-1.069564</td>\n      <td>0.0</td>\n      <td>0.195358</td>\n      <td>0.239113</td>\n      <td>0.951136</td>\n      <td>0.969949</td>\n      <td>0.313901</td>\n      <td>0.885769</td>\n      <td>556.397705</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18.879999</td>\n      <td>29.760000</td>\n      <td>201.050003</td>\n      <td>1.463777</td>\n      <td>True</td>\n      <td>4126</td>\n      <td>1.295658</td>\n      <td>-1.069564</td>\n      <td>0.0</td>\n      <td>0.195358</td>\n      <td>0.239113</td>\n      <td>0.951136</td>\n      <td>0.969949</td>\n      <td>0.313901</td>\n      <td>0.885769</td>\n      <td>556.397705</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8.800000</td>\n      <td>53.279999</td>\n      <td>201.050003</td>\n      <td>1.477835</td>\n      <td>True</td>\n      <td>4126</td>\n      <td>1.295658</td>\n      <td>-1.069564</td>\n      <td>0.0</td>\n      <td>0.195358</td>\n      <td>0.239113</td>\n      <td>0.951136</td>\n      <td>0.969949</td>\n      <td>0.313901</td>\n      <td>0.885769</td>\n      <td>556.397705</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1089999</th>\n      <th>3983</th>\n      <td>351.040009</td>\n      <td>39.840000</td>\n      <td>201.050003</td>\n      <td>3.227188</td>\n      <td>False</td>\n      <td>3988</td>\n      <td>-1.345380</td>\n      <td>-1.618472</td>\n      <td>0.0</td>\n      <td>0.146940</td>\n      <td>-0.290678</td>\n      <td>0.945471</td>\n      <td>0.976841</td>\n      <td>0.331759</td>\n      <td>5.180434</td>\n      <td>637.191895</td>\n    </tr>\n    <tr>\n      <th>3984</th>\n      <td>-351.040009</td>\n      <td>295.679993</td>\n      <td>201.050003</td>\n      <td>1.000412</td>\n      <td>False</td>\n      <td>3988</td>\n      <td>-1.345380</td>\n      <td>-1.618472</td>\n      <td>0.0</td>\n      <td>0.146940</td>\n      <td>-0.290678</td>\n      <td>0.945471</td>\n      <td>0.976841</td>\n      <td>0.331759</td>\n      <td>5.180434</td>\n      <td>637.191895</td>\n    </tr>\n    <tr>\n      <th>3985</th>\n      <td>-309.920013</td>\n      <td>-36.480000</td>\n      <td>201.050003</td>\n      <td>5.732517</td>\n      <td>False</td>\n      <td>3988</td>\n      <td>-1.345380</td>\n      <td>-1.618472</td>\n      <td>0.0</td>\n      <td>0.146940</td>\n      <td>-0.290678</td>\n      <td>0.945471</td>\n      <td>0.976841</td>\n      <td>0.331759</td>\n      <td>5.180434</td>\n      <td>637.191895</td>\n    </tr>\n    <tr>\n      <th>3986</th>\n      <td>351.040009</td>\n      <td>351.040009</td>\n      <td>201.050003</td>\n      <td>0.976915</td>\n      <td>False</td>\n      <td>3988</td>\n      <td>-1.345380</td>\n      <td>-1.618472</td>\n      <td>0.0</td>\n      <td>0.146940</td>\n      <td>-0.290678</td>\n      <td>0.945471</td>\n      <td>0.976841</td>\n      <td>0.331759</td>\n      <td>5.180434</td>\n      <td>637.191895</td>\n    </tr>\n    <tr>\n      <th>3987</th>\n      <td>-409.760010</td>\n      <td>-164.000000</td>\n      <td>201.050003</td>\n      <td>5.585002</td>\n      <td>False</td>\n      <td>3988</td>\n      <td>-1.345380</td>\n      <td>-1.618472</td>\n      <td>0.0</td>\n      <td>0.146940</td>\n      <td>-0.290678</td>\n      <td>0.945471</td>\n      <td>0.976841</td>\n      <td>0.331759</td>\n      <td>5.180434</td>\n      <td>637.191895</td>\n    </tr>\n  </tbody>\n</table>\n<p>40575725 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "beta_sigms.shape\n",
    "betas_df = pd.DataFrame()\n",
    "for it, dcr in enumerate(['0', '1e3', '1e4', '1e5', '1e6']):\n",
    "  betas_df[f'RMS90_{dcr}_cps'] = beta_sigms[it][0][0]\n",
    "  betas_df[f'yerr_{dcr}_cps'] = beta_sigms_yerr[it][0][0]\n",
    "  betas_df[f'deglim_RMS90_{dcr}_cps'] = beta_sigms_deglim[it][0][0]\n",
    "  betas_df[f'deglim_yerr_{dcr}_cps'] = beta_sigms_yerr_deglim[it][0][0]\n",
    "betas_df.to_csv('test.csv', header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "betas_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "read = pd.read_csv('test.csv')\n",
    "read"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ev = edf_d.loc[1444]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ev"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist3d, _ = np.histogramdd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "step = 2 * float(idf.pixel_size) / 2\n",
    "time_step = float(0.25) / 1\n",
    "\n",
    "r_slices = np.arange(0, 800, step=step)\n",
    "t_slices = np.arange(0, 15, step=time_step)\n",
    "phi_slices = np.array([-np.pi, -2.013, -0.671, 0, 0.671, 2.013, np.pi])\n",
    "\n",
    "mask = np.logical_and(ev.rotated_r_c >= 16, ev.rotated_r_c <= 80)\n",
    "rotated_r_c = ev.rotated_r_c[mask]\n",
    "t_c = ev.t_c[mask]\n",
    "rotated_phi_c = ev.rotated_phi_c[mask]\n",
    "\n",
    "counts, _ = np.histogram(rotated_r_c, bins=r_slices)\n",
    "square_counts, _, __ = np.histogram2d(rotated_r_c, t_c, bins=(r_slices, t_slices))\n",
    "cube_counts, _ = np.histogramdd((rotated_r_c, t_c, rotated_phi_c), bins=(r_slices, t_slices, phi_slices))\n",
    "\n",
    "counts = np.divide(np.add(counts[:-1], counts[1:]), r_slices[1:-1])\n",
    "shift=2\n",
    "square_counts = np.sum(cube_counts[:-2-shift,:,:] + cube_counts[1:-1-shift,:,:] + cube_counts[2:-shift,:,:], axis=2) + np.sum(cube_counts[3:-shift+1,:,:2] + cube_counts[3:-shift+1,:,-2:], axis=2) + np.sum(cube_counts[4:,:,:1] + cube_counts[4:,:,-1:], axis=2)\n",
    "square_counts[:-1, :] = np.divide(np.add(square_counts[:-1, :], square_counts[1:, :]), r_slices[1:-1-4, np.newaxis])\n",
    "\n",
    "square_counts_but_last = sum([square_counts[:, it : -1 + 1 + it] for it in range(1 - 1)])\n",
    "square_counts = np.add(square_counts_but_last, square_counts[:, 1 - 1:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cube_counts[:, :, -1:].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "square_counts2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}