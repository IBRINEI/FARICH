{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "–ö–æ–ø–∏—è –±–ª–æ–∫–Ω–æ—Ç–∞ \"farich_read_root_example.ipynb\"",
   "provenance": [
    {
     "file_id": "11NebRxpDewALrvN8Un_jA6atrZ3L4HlN",
     "timestamp": 1652210152468
    },
    {
     "file_id": "1VFgar3L6EujFLgBfbXNjISVZZ2F2k15t",
     "timestamp": 1631255116354
    },
    {
     "file_id": "19drm9hSuUtYHZlxN3xIVb7R-UoJ0EpDJ",
     "timestamp": 1619687086093
    },
    {
     "file_id": "1AWtfk-SUO5iUQL6SPYK5X3VzsIWD7j4Q",
     "timestamp": 1618441852195
    },
    {
     "file_id": "1yEW57kkrxMiquNsmuG7Z13pyi9YkIGag",
     "timestamp": 1617528150642
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0dQArAzUdno",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898444844,
     "user_tz": -180,
     "elapsed": 404,
     "user": {
      "displayName": "–ü–ª–∞—Ç–æ–Ω –î–º–∏—Ç—Ä–∏–µ–≤–∏—á –†–æ–≥–æ–∂–∏–Ω",
      "userId": "06374754299160062301"
     }
    },
    "outputId": "05d97e3b-58af-45c6-c325-bba6a4b5f0d4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –ø–∞–∫–µ—Ç–æ–≤\n",
    "import os, sys, time\n",
    "import uproot3 as uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "from mpl_toolkits import mplot3d\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from numbers import Integral\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm, truncnorm, foldnorm\n",
    "from itertools import compress\n",
    "from pynverse import inversefunc\n",
    "import warnings\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "print('Uproot version:',uproot.version.version)\n",
    "print('Numpy version:', np.version.version)\n",
    "print('Pandas version:', pd.__version__)\n",
    "plt.ioff()\n",
    "\n",
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –ø—Å–µ–≤–¥–æ—Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª\n",
    "# pandas version was 1.5.1\n",
    "\n",
    "rng = np.random.default_rng(12345)"
   ],
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uproot version: 3.14.4\n",
      "Numpy version: 1.23.4\n",
      "Pandas version: 2.0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "datadir = 'data'\n",
    "picsdir = 'pics'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LwzFMaFOPreX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898469884,
     "user_tz": -180,
     "elapsed": 263,
     "user": {
      "displayName": "–ü–ª–∞—Ç–æ–Ω –î–º–∏—Ç—Ä–∏–µ–≤–∏—á –†–æ–≥–æ–∂–∏–Ω",
      "userId": "06374754299160062301"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–ª—é—á–µ–π –≤ —Ñ–∞–π–ª–µ uproot –≤ –≤–∏–¥–µ –∏–µ—Ä–∞—Ä—Ö–∏–∏\n",
    "def show_uproot_tree(obj, maxkeylen=12, sep='/', indent=0) -> None:\n",
    "  width = maxkeylen+len(sep)\n",
    "  startline = False\n",
    "  if isinstance(obj, uproot.rootio.ROOTDirectory):\n",
    "    print('TFile: '+obj.name.decode('utf-8'))\n",
    "    startline = True\n",
    "    indent = 2\n",
    "  elif issubclass(type(obj), uproot.tree.TTreeMethods):\n",
    "    print('TTree: '+obj.name.decode('utf-8'))\n",
    "    startline = True\n",
    "    indent = 4\n",
    "  else:\n",
    "    if len(obj.keys()) > 0:\n",
    "      indent += width\n",
    "      s = obj.name.decode('utf-8')[:maxkeylen]\n",
    "      print(s + ' '*(maxkeylen-len(s)) + sep, end='')\n",
    "    else:\n",
    "      print(obj.name.decode('utf-8'))\n",
    "\n",
    "  if len(obj.keys()) > 0:\n",
    "    for i, key in enumerate(obj.keys()):\n",
    "      if i>0 or startline:\n",
    "        print(' '*indent, end='')\n",
    "      show_uproot_tree(obj[key], indent=indent)\n",
    "    indent -= width"
   ],
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lg70kDuWKx1d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898474427,
     "user_tz": -180,
     "elapsed": 2763,
     "user": {
      "displayName": "–ü–ª–∞—Ç–æ–Ω –î–º–∏—Ç—Ä–∏–µ–≤–∏—á –†–æ–≥–æ–∂–∏–Ω",
      "userId": "06374754299160062301"
     }
    },
    "outputId": "d3b922b3-ad42-4ec9-e62e-f8fc027d0904",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "filepath = os.path.join(datadir, 'farichsim_1200kevt.root')\n",
    "show_uproot_tree(uproot.open(filepath))"
   ],
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFile: ./farichsim_pi-pi-_45-360deg_1200.0k_ideal_2020-12-24_rndm.root\n",
      "  TTree: info_sim\n",
      "    info_gen    /m_num_events\n",
      "                 m_z_dis\n",
      "    info_rad    /m_layers    /m_layers.first\n",
      "                              m_layers.second\n",
      "    info_pmt    /m_name\n",
      "                 m_num_side_x\n",
      "                 m_num_side_y\n",
      "                 m_gap\n",
      "                 m_size\n",
      "                 m_chip_num_size\n",
      "                 m_chip_pitch\n",
      "                 m_chip_size\n",
      "                 m_chip_offset\n",
      "                 m_focal_length\n",
      "                 m_trg_window\n",
      "                 m_origin_pos/m_origin_pos._2\n",
      "                              m_origin_pos._1\n",
      "                              m_origin_pos._0\n",
      "  TTree: raw_data\n",
      "    event       /m_id_event\n",
      "                 m_id_primary\n",
      "                 m_pos_primar/m_pos_primary._2\n",
      "                              m_pos_primary._1\n",
      "                              m_pos_primary._0\n",
      "                 m_dir_primar/m_dir_primary._2\n",
      "                              m_dir_primary._1\n",
      "                              m_dir_primary._0\n",
      "                 m_theta_primary\n",
      "                 m_phi_primary\n",
      "                 m_momentum_primary\n",
      "                 m_beta_primary\n",
      "                 m_hits      /m_hits.m_photon_id_pmt\n",
      "                              m_hits.m_photon_id_chip\n",
      "                              m_hits.m_photon_id_layer\n",
      "                              m_hits.m_photon_id_track\n",
      "                              m_hits.m_photon_id_track_parent\n",
      "                              m_hits.m_photon_id_hit\n",
      "                              m_hits.m_photon_wl\n",
      "                              m_hits.m_photon_time\n",
      "                              m_hits.m_photon_pos_exact._2\n",
      "                              m_hits.m_photon_pos_exact._1\n",
      "                              m_hits.m_photon_pos_exact._0\n",
      "                              m_hits.m_photon_pos_chip._2\n",
      "                              m_hits.m_photon_pos_chip._1\n",
      "                              m_hits.m_photon_pos_chip._0\n",
      "                              m_hits.m_photon_pos_vertex._2\n",
      "                              m_hits.m_photon_pos_vertex._1\n",
      "                              m_hits.m_photon_pos_vertex._0\n",
      "                              m_hits.m_photon_dir_vertex._2\n",
      "                              m_hits.m_photon_dir_vertex._1\n",
      "                              m_hits.m_photon_dir_vertex._0\n",
      "                              m_hits.m_hit_is_fittable\n",
      "                              m_hits.m_photon_theta.first\n",
      "                              m_hits.m_photon_theta.second\n",
      "                              m_hits.m_photon_phi.first\n",
      "                              m_hits.m_photon_phi.second\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X1oKpqDKUfrD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898477207,
     "user_tz": -180,
     "elapsed": 332,
     "user": {
      "displayName": "–ü–ª–∞—Ç–æ–Ω –î–º–∏—Ç—Ä–∏–µ–≤–∏—á –†–æ–≥–æ–∂–∏–Ω",
      "userId": "06374754299160062301"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def readInfoFromRoot(filepath, verbose: bool = False) -> pd.DataFrame:\n",
    "  '''\n",
    "  –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑ ROOT-—Ñ–∞–π–ª–∞ –≤ –≤–∏–¥–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Ñ–æ—Ä–º–æ–π (1, N), –≥–¥–µ N - —á–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "  '''\n",
    "  # –ù–∞–∑–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ data frame\n",
    "  idf_rename_map = {'m_num_events': 'nevents',  # —á–∏—Å–ª–æ —Å–æ–±—ã—Ç–∏–π –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "                    'm_z_dis': 'zdis',  # —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç –º–µ—Å—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è —á–∞—Å—Ç–∏—Ü—ã –¥–æ –≤—Ö–æ–¥–∞ –≤ —Ä–∞–¥–∏–∞—Ç–æ—Ä –≤ –º–º\n",
    "                    'm_layers': 'nlayers',  # —á–∏—Å–ª–æ —Å–ª–æ–µ–≤ —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞\n",
    "                    'm_size': 'array_size',  # —Ä–∞–∑–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã –ö–§–£ –≤ –º–º\n",
    "                    'm_gap': 'array_gap',  # –∑–∞–∑–æ—Ä –º–µ–∂–¥—É –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –ö–§–£ –≤ –º–º\n",
    "                    'm_chip_size': 'pixel_size',  # —Ä–∞–∑–º–µ—Ä –ø–∏–∫—Å–µ–ª—è –ö–§–£ –≤ –º–º\n",
    "                    'm_chip_pitch': 'pixel_gap',  # –∑–∞–∑–æ—Ä –º–µ–∂–¥—É –ø–∏–∫—Å–µ–ª—è–º–∏ –ö–§–£ –≤ –º–º\n",
    "                    'm_chip_num_size': 'pixel_numx',  # —Ä–∞–∑–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã –ö–§–£ –≤ –ø–∏–∫—Å–µ–ª—è—Ö\n",
    "                    'm_num_side_x': 'nxarrays', 'm_num_side_y': 'nyarrays',  # —Ä–∞–∑–º–µ—Ä —Ñ–æ—Ç–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –≤ –º–∞—Ç—Ä–∏—Ü–∞—Ö –ö–§–£ –ø–æ X –∏ Y\n",
    "                    'm_focal_length': 'distance',  # —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç –≤—Ö–æ–¥–∞ –≤ —Ä–∞–¥–∏–∞—Ç–æ—Ä –¥–æ –≤—Ö–æ–¥–∞ –≤ —Ñ–æ—Ç–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä\n",
    "                    'm_trg_window': 'trg_window_ns',  # —Ä–∞–∑–º–µ—Ä –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ–∫–Ω–∞ –≤ –Ω—Å\n",
    "                    'W': 'W',  # —Ç–æ–ª—â–∏–Ω–∞ —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞ –≤ –º–º (–≤—ã—á–∏—Å–ª—è–µ–º–∞—è)\n",
    "                    'n_mean': 'n_mean',  # —Å—Ä–µ–¥–Ω–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –ø—Ä–µ–ª–æ–º–ª–µ–Ω–∏—è —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞ (–≤—ã—á–∏—Å–ª—è–µ–º—ã–π)\n",
    "                    'n_max': 'n_max',  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –ø—Ä–µ–ª–æ–º–ª–µ–Ω–∏—è —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞ (–≤—ã—á–∏—Å–ª—è–µ–º—ã–π)\n",
    "                   }\n",
    "\n",
    "  # –û—Ç–∫—Ä—ã—Ç–∏–µ ROOT-—Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –∏—Å–ø–æ–ª—å–∑—É—è Uproot https://github.com/scikit-hep/uproot3\n",
    "  with uproot.open(filepath) as file:\n",
    "    idf = file[b'info_sim'].pandas.df('*', flatten=False)\n",
    "\n",
    "  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "  idf.rename(columns=idf_rename_map, inplace=True, errors='ignore')\n",
    "\n",
    "  # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–æ–≥–æ) —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤\n",
    "  n_l = idf.at[0,'m_layers.first']  # –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø—Ä–µ–ª–æ–º–ª–µ–Ω–∏—è —Å–ª–æ—ë–≤\n",
    "  w_l = idf.at[0,'m_layers.second']  # —Ç–æ–ª—â–∏–Ω—ã —Å–ª–æ—ë–≤ —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞\n",
    "\n",
    "  W = w_l.sum()  # —Å—É–º–º–∞—Ä–Ω–∞—è —Ç–æ–ª—â–∏–Ω–∞ –≤—Å–µ—Ö —Å–ª–æ—ë–≤\n",
    "  n_mean = n_l.mean()  # —Å—Ä–µ–¥–Ω–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –ø—Ä–µ–ª–æ–º–ª–µ–Ω–∏—è\n",
    "  n_max = n_l.max()  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –ø—Ä–µ–ª–æ–º–ª–µ–Ω–∏—è\n",
    "\n",
    "  # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª—è–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ idf\n",
    "  idf['W'] = W\n",
    "  idf['n_mean'] = n_mean\n",
    "  idf['n_max'] = n_max\n",
    "\n",
    "  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω—É–∂–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "  idf = idf[idf_rename_map.values()]\n",
    "\n",
    "  if verbose:\n",
    "    for name in idf.columns:\n",
    "      print(f'{name}: {idf.at[0, name]}')\n",
    "\n",
    "  return idf"
   ],
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y8Ku3fKp8Vxl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898480118,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "–ü–ª–∞—Ç–æ–Ω –î–º–∏—Ç—Ä–∏–µ–≤–∏—á –†–æ–≥–æ–∂–∏–Ω",
      "userId": "06374754299160062301"
     }
    },
    "outputId": "3541df8f-bc75-45f9-e0a7-6d1ff9183be1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "idf = readInfoFromRoot(filepath)"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "       nevents  zdis  nlayers  array_size  array_gap  pixel_size  pixel_gap   \nentry                                                                         \n0      1200000   1.0        4       26.68        1.0        3.16        0.2  \\\n\n       pixel_numx  nxarrays  nyarrays  distance  trg_window_ns     W  n_mean   \nentry                                                                          \n0               8        30        30     200.0           20.0  35.0  1.0454  \\\n\n       n_max  \nentry         \n0       1.05  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nevents</th>\n      <th>zdis</th>\n      <th>nlayers</th>\n      <th>array_size</th>\n      <th>array_gap</th>\n      <th>pixel_size</th>\n      <th>pixel_gap</th>\n      <th>pixel_numx</th>\n      <th>nxarrays</th>\n      <th>nyarrays</th>\n      <th>distance</th>\n      <th>trg_window_ns</th>\n      <th>W</th>\n      <th>n_mean</th>\n      <th>n_max</th>\n    </tr>\n    <tr>\n      <th>entry</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1200000</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>26.68</td>\n      <td>1.0</td>\n      <td>3.16</td>\n      <td>0.2</td>\n      <td>8</td>\n      <td>30</td>\n      <td>30</td>\n      <td>200.0</td>\n      <td>20.0</td>\n      <td>35.0</td>\n      <td>1.0454</td>\n      <td>1.05</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sCexVXIHFivc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898482259,
     "user_tz": -180,
     "elapsed": 318,
     "user": {
      "displayName": "–ü–ª–∞—Ç–æ–Ω –î–º–∏—Ç—Ä–∏–µ–≤–∏—á –†–æ–≥–æ–∂–∏–Ω",
      "userId": "06374754299160062301"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def genChunkFromRoot(filepath, eventchunksize=2000, noisefreqpersqmm: float = 2e6, noiseTimeRange: float = (0, 7), shiftSignalTimes: bool = True,\n",
    "                     edfstore: pd.HDFStore = None, verbose: bool = True) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–æ–±—ã—Ç–∏–π –∏–∑ ROOT-—Ñ–∞–π–ª–∞ –≤ –≤–∏–¥–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞. –ß–∏—Å–ª–æ —Å–æ–±—ã—Ç–∏–π eventchunksize, —á–∏—Ç–∞–µ–º—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–º –∑–∞ –æ–¥–∏–Ω —Ä–∞–∑, –¥–æ–ª–∂–µ–Ω –≤—ã–±–∏—Ä–∞—Ç—å—Å—è —Ç–∞–∫,\n",
    "    —á—Ç–æ–±—ã –≤—Å–µ –¥–∞–Ω–Ω—ã–µ —Å —É—á–µ—Ç–æ–º –¥–æ–±–∞–≤–ª—è–µ–º—ã—Ö —à—É–º–æ–≤—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π —É–º–µ—â–∞–ª–∏—Å—å –≤ —Ä–∞–∑–º–µ—Ä –û–ó–£.\n",
    "\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    filepath - –ø—É—Ç—å –∫ ROOT-—Ñ–∞–π–ª—É –¥–ª—è —á—Ç–µ–Ω–∏—è.\n",
    "    eventchunksize - —á–∏—Å–ª–æ —Å–æ–±—ã—Ç–∏–π, –∑–∞–≥—Ä—É–∂–∞–µ–º—ã—Ö –∏–∑ ROOT-—Ñ–∞–π–ª–∞ –∑–∞ –æ–¥–∏–Ω –≤—ã–∑–æ–≤.\n",
    "    noisefreqpersqmm - —á–∞—Å—Ç–æ—Ç–∞ —Ç–µ–º–Ω–æ–≤—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –Ω–∞ –µ–¥–∏–Ω–∏—Ü—É –∞–∫—Ç–∏–≤–Ω–æ–π –ø–ª–æ—â–∞–¥–∏ —Ñ–æ—Ç–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –≤ —Å^{-1}*–º–º^{-2}, –ø–æ–¥–º–µ—à–∏–≤–∞–µ–º—ã—Ö –∫ —Å–æ–±—ã—Ç–∏—è–º;\n",
    "                       –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞, –∫–æ—Ç–æ—Ä–æ–µ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å, 2e6.\n",
    "    noiseTimeRange - (start, stop) - tuple, –∑–∞–¥–∞—é—â–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —à—É–º–∞ –≤ –Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥–∞—Ö.\n",
    "    edfstore - HDF-—Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ \"edf\"; –¥–∞–Ω–Ω—ã–µ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫ —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–º –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.\n",
    "    verbose - —Ñ–ª–∞–≥ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –ø–µ—á–∞—Ç–∏.\n",
    "\n",
    "    –û–ø–∏—Å–∞–Ω–∏–µ —É—Å–ª–æ–≤–∏–π –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
    "    –û—Å—å Z –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ –ø–æ –Ω–æ—Ä–º–∞–ª–∏ –∫ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞ –æ—Ç —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞ –∫ —Ñ–æ—Ç–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä—É.\n",
    "    –û—Å–∏ X –∏ Y –ø–∞—Ä–∞–ª–µ–ª—å–Ω—ã –æ—Å—è–º —Å–∏–º–º–µ—Ç—Ä–∏–∏ –º–∞—Ç—Ä–∏—Ü—ã —Ñ–æ—Ç–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.\n",
    "    –ü–µ—Ä–≤–∏—á–Ω–∞—è —á–∞—Å—Ç–∏—Ü–∞ (–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø–∏–æ–Ω) –≤—ã–ª–µ—Ç–∞–µ—Ç –Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏ zdis=1 –º–º –ø–µ—Ä–µ–¥ —Ä–∞–¥–∏–∞—Ç–æ—Ä–æ–º –≤ –µ–≥–æ —Å—Ç–æ—Ä–æ–Ω—É\n",
    "    –ù–∞—á–∞–ª—å–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ —á–∞—Å—Ç–∏—Ü—ã —Å–ª—É—á–∞–π–Ω–æ —Ä–∞–∑–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –ø–æ X –∏ Y –≤ –∫–≤–∞–¥—Ä–∞—Ç–µ —Å–æ —Å—Ç–æ—Ä–æ–Ω–æ–π (pixel_size+pixel_gap).\n",
    "    –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–∞—Å—Ç–∏—Ü—ã —Å–ª—É—á–∞–π–Ω–æ —Ä–∞–∑–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –≤ —Ç–µ–ª–µ—Å–Ω–æ–º —É–≥–ª–µ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö theta_p=[0, œÄ/4], phi_p=[0, 2œÄ].\n",
    "    –°–∫–æ—Ä–æ—Å—Ç—å —á–∞—Å—Ç–∏—Ü—ã —Å–ª—É—á–∞–π–Ω–æ –∏ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞–∑–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –æ—Ç 0.957 –¥–æ 0.999 —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å–≤–µ—Ç–∞.\n",
    "  \"\"\"\n",
    "  global rng\n",
    "\n",
    "  # –î–∞–Ω–Ω—ã–µ –æ —á–∞—Å—Ç–∏—Ü–µ (–¥–ª—è –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)\n",
    "  part_rename_map = {'m_hits': 'nhits',                # —á–∏—Å–ª–æ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –≤ —Å–æ–±—ã—Ç–∏–∏\n",
    "                     'm_pos_primary._0': 'x_p',        # X-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ –≤—ã–ª–µ—Ç–∞ —á–∞—Å—Ç–∏—Ü—ã –≤ –º–º\n",
    "                     'm_pos_primary._1': 'y_p',        # Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ –≤—ã–ª–µ—Ç–∞ —á–∞—Å—Ç–∏—Ü—ã –≤ –º–º\n",
    "                     'm_pos_primary._2': 'z_p',        # Z-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ –≤—ã–ª–µ—Ç–∞ —á–∞—Å—Ç–∏—Ü—ã –≤ –º–º\n",
    "                     'm_dir_primary._0': 'nx_p',       # X-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç–∏—Ü—ã\n",
    "                     'm_dir_primary._1': 'ny_p',       # Y-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç–∏—Ü—ã\n",
    "                     'm_dir_primary._2': 'nz_p',       # Z-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç–∏—Ü—ã\n",
    "                     'm_beta_primary': 'beta',         # —Å–∫–æ—Ä–æ—Å—Ç—å —á–∞—Å—Ç–∏—Ü—ã –≤ –µ–¥–∏–Ω–∏—Ü–∞—Ö —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å–≤–µ—Ç–∞\n",
    "                     'm_theta_primary': 'theta_p',     # –ø–æ–ª—è—Ä–Ω—ã–π —É–≥–æ–ª –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç–∏—Ü—ã –≤ —Ä–∞–¥–∏–∞–Ω–∞—Ö\n",
    "                     'm_phi_primary': 'phi_p',         # –∞–∑–∏–º—É—Ç–∞–ª—å–Ω—ã–π —É–≥–æ–ª –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç–∏—Ü—ã –≤ —Ä–∞–¥–∏–∞–Ω–∞—Ö\n",
    "                     'm_momentum_primary': 'momentum'  # –∏–º–ø—É–ª—å—Å —á–∞—Å—Ç–∏—Ü—ã –≤ –ú—ç–í/c\n",
    "                    }\n",
    "  \n",
    "  # –ù–∞–±–ª—é–¥–∞–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è—Ö (–¥–ª—è –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)\n",
    "  hit_rename_map = {'m_hits.m_photon_pos_chip._0': 'x_c',  # X-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è –≤ –º–º\n",
    "                    'm_hits.m_photon_pos_chip._1': 'y_c',  # Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è –≤ –º–º\n",
    "                    'm_hits.m_photon_pos_chip._2': 'z_c',  # Z-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è –≤ –º–º\n",
    "                    'm_hits.m_photon_time': 't_c'          # –≤—Ä–µ–º—è —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è –≤ –Ω—Å\n",
    "                   }\n",
    "\n",
    "  other_rename_map = {'m_id_event': '',                         #\n",
    "                      'm_id_primary': '',                       #\n",
    "                      'm_hits.m_photon_id_pmt': '',             #\n",
    "                      'm_hits.m_photon_id_chip': '',            #\n",
    "                      'm_hits.m_photon_id_layer': '',           #\n",
    "                      'm_hits.m_photon_id_track': '',           #\n",
    "                      'm_hits.m_photon_id_track_parent': '',    #\n",
    "                      'm_hits.m_photon_id_hit': '',             #\n",
    "                      'm_hits.m_photon_wl': '',                 #\n",
    "                      'm_hits.m_photon_pos_exact._0': '',       #\n",
    "                      'm_hits.m_photon_pos_exact._1': '',       #\n",
    "                      'm_hits.m_photon_pos_exact._2': '',       #\n",
    "                      'm_hits.m_photon_pos_vertex._0': '',      #\n",
    "                      'm_hits.m_photon_pos_vertex._1': '',      #\n",
    "                      'm_hits.m_photon_pos_vertex._2': '',      #\n",
    "                      'm_hits.m_photon_dir_vertex._0': '',      #\n",
    "                      'm_hits.m_photon_dir_vertex._1': '',      #\n",
    "                      'm_hits.m_photon_dir_vertex._2': '',      #\n",
    "                      'm_hits.m_hit_is_fittable': '',           #\n",
    "                      'm_hits.m_photon_theta.first': '',        #\n",
    "                      'm_hits.m_photon_theta.second': '',       #\n",
    "                      'm_hits.m_photon_phi.first': '',          #\n",
    "                      'm_hits.m_photon_phi.second': '',         #\n",
    "                      }\n",
    "\n",
    "  for key in other_rename_map:\n",
    "    other_rename_map.update({key: key})\n",
    "  # –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "  edfcolstosave = list(part_rename_map.values()) + list(hit_rename_map.values())\n",
    "\n",
    "  # –ß—Ç–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "  idf = readInfoFromRoot(filepath)\n",
    "\n",
    "  # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ñ–æ—Ç–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–º–Ω–æ–≤–æ–≥–æ —à—É–º–∞\n",
    "  pixel_size, pixel_gap = idf.at[0, 'pixel_size'], idf.at[0, 'pixel_gap']\n",
    "  array_size, array_gap = idf.at[0, 'array_size'], idf.at[0, 'array_gap']\n",
    "  nxpixels_arr = idf.at[0, 'pixel_numx']\n",
    "  nxpixels_tot = idf.at[0, 'nxarrays']*nxpixels_arr\n",
    "  igrid = np.arange(nxpixels_tot//2)\n",
    "  xpnts = array_gap/2 + (igrid//nxpixels_arr)*(array_size+array_gap) + (igrid%nxpixels_arr)*(pixel_size+pixel_gap) + pixel_size/2\n",
    "  xpnts = np.sort(np.append(-xpnts, xpnts)).astype('float32')\n",
    "  xgrid, ygrid = np.meshgrid(xpnts, xpnts)\n",
    "  xgrid = xgrid.reshape(xgrid.size)\n",
    "  ygrid = ygrid.reshape(ygrid.size)\n",
    " \n",
    "  def addNoise(partdf: pd.DataFrame, hitdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' \n",
    "    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–º–Ω–æ–≤—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π —Ç–µ–º–Ω–æ–≤–æ–≥–æ —à—É–º–∞ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º (–±–µ–∑ —É—á–µ—Ç–∞ \"–º—ë—Ä—Ç–≤–æ–≥–æ\" –≤—Ä–µ–º–µ–Ω–∏ –ø–∏–∫—Å–µ–ª—è).\n",
    "    partdf - –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è —á–∞—Å—Ç–∏—Ü\n",
    "    hitdf - –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π\n",
    "    '''\n",
    "    assert(np.isclose(pixel_size*nxpixels_arr+pixel_gap*(nxpixels_arr-1), array_size))\n",
    "    nevents = partdf.shape[0]  # —á–∏—Å–ª–æ —Å–æ–±—ã—Ç–∏–π\n",
    "    \n",
    "    # —Å—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ —à—É–º–æ–≤—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –Ω–∞ —Å–æ–±—ã—Ç–∏–µ\n",
    "    munoise = (noiseTimeRange[1]-noiseTimeRange[0])*1e-9*noisefreqpersqmm*(pixel_size**2)*(nxpixels_tot**2)\n",
    "\n",
    "    print(f'    Generate noise with DCR per mm^2 {noisefreqpersqmm}, mean number of hits per event: {munoise:.2f}.')\n",
    "\n",
    "    noisehits = rng.poisson(munoise, nevents)   # –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Å—Å–∏–≤–∞ —á–∏—Å–ª–∞ —à—É–º–æ–≤—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –≤ —Å–æ–±—ã—Ç–∏—è—Ö –ø–æ –ø—É–∞—Å—Å–æ–Ω–æ–≤—Å–∫–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é\n",
    "    Ndc = int(noisehits.sum())                  # –æ–±—â–µ–µ —á–∏—Å–ª–æ —à—É–º–æ–≤—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π (—Å–∫–∞–ª—è—Ä)\n",
    "    signalhits = partdf['nhits'].to_numpy()     # –º–∞—Å—Å–∏–≤ —á–∏—Å–ª–∞ —Å–∏–≥–Ω–∞–ª—å–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –ø–æ —Å–æ–±—ã—Ç–∏—è–º\n",
    "\n",
    "    # —Å–ª—É—á–∞–π–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª—å–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ–∫–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —à—É–º–∞\n",
    "    if shiftSignalTimes:\n",
    "      hitdf['t_c'] += np.repeat(rng.uniform(0, noiseTimeRange[1]-2, nevents), partdf['nhits'])\n",
    "\n",
    "    hitdf['signal'] = np.ones(signalhits.sum(), bool)  # —Ä–∞–∑–º–µ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª—å–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –∑–Ω–∞—á–µ–Ω–∏–µ–º 'signal' True\n",
    "    if Ndc == 0:    # –µ—Å–ª–∏ –Ω–µ—Ç —à—É–º–æ–≤—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π\n",
    "      return hitdf  # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –∫–æ–ª–æ–Ω–∫–∏ 'signal'\n",
    "\n",
    "    ich = rng.choice(xgrid.size, Ndc)           # –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤ —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏—Ö –∫–∞–Ω–∞–ª–æ–≤ —Å –≤–æ–∑–º–æ–∂–Ω—ã–º –ø–æ–≤—Ç–æ—Ä–æ–º\n",
    "    xh = xgrid[ich]                             # x-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏—Ö –∫–∞–Ω–∞–ª–æ–≤\n",
    "    yh = ygrid[ich]                             # y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏—Ö –∫–∞–Ω–∞–ª–æ–≤\n",
    "    # zh = hitdf.at[(0, 0), 'z_c']                # z-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π (—Å–∫–∞–ª—è—Ä)\n",
    "    zh = 201.050003\n",
    "    th = rng.uniform(noiseTimeRange[0], noiseTimeRange[1], size=Ndc) # –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Ä–µ–º—ë–Ω —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –ø–æ –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é\n",
    "   \n",
    "    # –Ω—É–º–µ—Ä–∞—Ü–∏—è —à—É–º–æ–≤—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –ø–æ —Å–æ–±—ã—Ç–∏—è–º\n",
    "    ievent = np.repeat(partdf.index, noisehits) # –º–∞—Å—Å–∏–≤ –Ω–æ–º–µ—Ä–æ–≤ —Å–æ–±—ã—Ç–∏–π –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "    ihit = np.zeros(Ndc, 'int64')               # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Å—Å–∏–≤–∞ –Ω–æ–º–µ—Ä–æ–≤ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "    index = 0\n",
    "    for i in range(nevents):\n",
    "      ihit[index:index+noisehits[i]] = signalhits[i] + np.arange(noisehits[i])\n",
    "      index += noisehits[i]\n",
    "    \n",
    "    # —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ —Å —à—É–º–æ–≤—ã–º–∏ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è–º–∏ —Ç–æ–≥–æ –∂–µ —Ñ–æ—Ä–º–∞—Ç–∞, —á—Ç–æ hitdf\n",
    "    noisedf = pd.DataFrame({'x_c': xh, 'y_c': yh, 'z_c': zh, 't_c': th, 'signal': np.zeros(Ndc, bool)},\n",
    "                           index=pd.MultiIndex.from_arrays((ievent, ihit), names=('entry', 'subentry')))\n",
    "\n",
    "    # TO DO: —Å–ª—É—á–∞–π–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ –∫–æ–ª—å—Ü–∞ –≤ —Ñ–æ—Ç–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä–µ (—Å–¥–≤–∏–≥ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç —Å–∏–≥–Ω–∞–ª—å–Ω—ã—Ö —Ö–∏—Ç–æ–≤).\n",
    "    # –°–ª–æ–∂–Ω–æ—Å—Ç—å —Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–π —Å–µ—Ç–∫–∏ –ø–∏–∫—Å–µ–ª–µ–π, —Ç.–∫. –∑–∞–∑–æ—Ä—ã –º–µ–∂–¥—É –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –±–æ–ª—å—à–µ –∑–∞–∑–æ—Ä–æ–≤ –º–µ–∂–¥—É –ø–∏–∫—Å–µ–ª—è–º–∏ –≤ –º–∞—Ç—Ä–∏—Ü–µ.\n",
    "    # –ü—Ä–æ—â–µ —Å–¥–µ–ª–∞—Ç—å –≤ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏.\n",
    "\n",
    "    # —Å–ª–∏–≤–∞–µ–º —Å–∏–≥–Ω–∞–ª—å–Ω—ã–π –∏ —à—É–º–æ–≤–æ–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º —É–∫–∞–∑–∞—Ç–µ–ª—å —Å–æ–±—ã—Ç–∏–π –∏ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π\n",
    "    hitdf2 = pd.concat((hitdf, noisedf), copy=False).sort_index(level=('entry', 'subentry'))\n",
    "\n",
    "    # –æ–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –≤ partdf, –¥–æ–±–∞–≤–ª—è—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —à—É–º–æ–≤—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –ø–æ —Å–æ–±—ã—Ç–∏—è–º\n",
    "    partdf['nhits'] += noisehits\n",
    "\n",
    "    return hitdf2\n",
    "\n",
    "\n",
    "  nFileEvents = idf.at[0, 'nevents']\n",
    "  # print(f'Processing ROOT file {filepath} with {nFileEvents} simulated events...', flush=True)\n",
    "  \n",
    "  # –¶–∏–∫–ª —á—Ç–µ–Ω–∏—è –∫—É—Å–∫–æ–≤ ROOT-—Ñ–∞–π–ª–∞\n",
    "  for partdf, hitdf, otherdf in zip(uproot.pandas.iterate(filepath, \"raw_data\", part_rename_map.keys(), entrysteps=eventchunksize),\n",
    "                           uproot.pandas.iterate(filepath, \"raw_data\", hit_rename_map.keys(), entrysteps=eventchunksize, flatten=True),\n",
    "                           uproot.pandas.iterate(filepath, \"raw_data\", other_rename_map.keys(), entrysteps=eventchunksize, flatten=True)):\n",
    "    # print('\\n  Processing next chunk...')\n",
    "\n",
    "    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫\n",
    "    partdf.rename(columns=part_rename_map, inplace=True, errors='raise')\n",
    "    hitdf.rename(columns=hit_rename_map, inplace=True, errors='raise')\n",
    "    otherdf.rename(columns=other_rename_map, inplace=True, errors='raise')\n",
    "\n",
    "    partdf = partdf.astype('float32', copy=False)\n",
    "    partdf['nhits'] = partdf['nhits'].astype('int32', copy=False)\n",
    "    hitdf = hitdf.astype('float32', copy=False)\n",
    "    otherdf = otherdf.astype('float32', copy=False)\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–æ–≤—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π\n",
    "    hitdf = addNoise(partdf, hitdf)\n",
    "\n",
    "    # print(f'    {hitdf.index.levels[0].size} entries with {hitdf.shape[0]} hits to process')\n",
    "\n",
    "    # –°–ª–∏—è–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –∏ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π\n",
    "    edf = hitdf.join(otherdf)\n",
    "    edf = edf.join(partdf, on='entry')\n",
    "    #edf = hitdf.join(partdf, on='entry')\n",
    "    #edf = edf.join(otherdf, on='entry')\n",
    "    if verbose:\n",
    "      pass\n",
    "      # print(edf)\n",
    "\n",
    "    if edfstore is not None:\n",
    "      # print(f'    Saving edf chunk...')\n",
    "      edfstore.put('edf', edf, format='table', append=True)\n",
    "\n",
    "    yield edf"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cCcplDgkbT1Y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898487147,
     "user_tz": -180,
     "elapsed": 645,
     "user": {
      "displayName": "–ü–ª–∞—Ç–æ–Ω –î–º–∏—Ç—Ä–∏–µ–≤–∏—á –†–æ–≥–æ–∂–∏–Ω",
      "userId": "06374754299160062301"
     }
    },
    "outputId": "f6651bf4-214c-43f8-94e6-9a9bd43c5468",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# –ß—Ç–µ–Ω–∏–µ –∏ –¥–æ–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ \"–∫—É—Å–∫–∞\" –¥–∞–Ω–Ω—ã—Ö\n",
    "#edf = next(genChunkFromRoot(filepath, 1450, noisefreqpersqmm=1000000))\n",
    "edf = next(genChunkFromRoot(filepath, 10000, noisefreqpersqmm=0))"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Generate noise with DCR per mm^2 0, mean number of hits per event: 0.00.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def edf_to_bdf(edf_col: pd.Series, bdf: pd.DataFrame):\n",
    "  to_bdf = [sub.iloc[0] for _, sub in edf_col.groupby(level=0)]\n",
    "  bdf[edf_col.name] = pd.Series(to_bdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "                       x_c         y_c         z_c       t_c  signal   \nentry subentry                                                         \n0     0         -70.879997 -226.880005  201.050003  2.188593    True  \\\n      1         -53.279999 -309.920013  201.050003  2.396409    True   \n      2         -36.480000 -306.559998  201.050003  2.382249    True   \n      3         -49.919998 -184.960007  201.050003  2.073419    True   \n      4         -12.160000 -288.959991  201.050003  2.326930    True   \n...                    ...         ...         ...       ...     ...   \n9999  40        178.240005  -80.959999  201.050003  3.695349    True   \n      41        178.240005  -74.239998  201.050003  3.687293    True   \n      42        226.880005  -53.279999  201.050003  3.892318    True   \n      43        274.720001 -209.279999  201.050003  4.102964    True   \n      44        251.199997  -18.879999  201.050003  3.840951    True   \n\n                m_id_event  m_id_primary  m_hits.m_photon_id_pmt   \nentry subentry                                                     \n0     0                1.0        -211.0                   367.0  \\\n      1                1.0        -211.0                   394.0   \n      2                1.0        -211.0                   394.0   \n      3                1.0        -211.0                   399.0   \n      4                1.0        -211.0                   425.0   \n...                    ...           ...                     ...   \n9999  40           10000.0        -211.0                   643.0   \n      41           10000.0        -211.0                   643.0   \n      42           10000.0        -211.0                   704.0   \n      43           10000.0        -211.0                   728.0   \n      44           10000.0        -211.0                   735.0   \n\n                m_hits.m_photon_id_chip  m_hits.m_photon_id_layer  ...   \nentry subentry                                                     ...   \n0     0                            31.0                       4.0  ...  \\\n      1                             7.0                       4.0  ...   \n      2                            48.0                       4.0  ...   \n      3                            11.0                       2.0  ...   \n      4                            37.0                       3.0  ...   \n...                                 ...                       ...  ...   \n9999  40                           25.0                       1.0  ...   \n      41                           27.0                       3.0  ...   \n      42                            9.0                       4.0  ...   \n      43                           60.0                       4.0  ...   \n      44                            3.0                       4.0  ...   \n\n                     x_p       y_p  z_p      nx_p      ny_p      nz_p   \nentry subentry                                                          \n0     0         1.275724  1.576625  0.0 -0.073019 -0.695325  0.714977  \\\n      1         1.275724  1.576625  0.0 -0.073019 -0.695325  0.714977   \n      2         1.275724  1.576625  0.0 -0.073019 -0.695325  0.714977   \n      3         1.275724  1.576625  0.0 -0.073019 -0.695325  0.714977   \n      4         1.275724  1.576625  0.0 -0.073019 -0.695325  0.714977   \n...                  ...       ...  ...       ...       ...       ...   \n9999  40        1.499871 -1.121928  0.0  0.419547 -0.313757  0.851784   \n      41        1.499871 -1.121928  0.0  0.419547 -0.313757  0.851784   \n      42        1.499871 -1.121928  0.0  0.419547 -0.313757  0.851784   \n      43        1.499871 -1.121928  0.0  0.419547 -0.313757  0.851784   \n      44        1.499871 -1.121928  0.0  0.419547 -0.313757  0.851784   \n\n                    beta   theta_p     phi_p    momentum  \nentry subentry                                            \n0     0         0.966818  0.774205  4.607758  528.209290  \n      1         0.966818  0.774205  4.607758  528.209290  \n      2         0.966818  0.774205  4.607758  528.209290  \n      3         0.966818  0.774205  4.607758  528.209290  \n      4         0.966818  0.774205  4.607758  528.209290  \n...                  ...       ...       ...         ...  \n9999  40        0.987837  0.551415  5.641063  886.668091  \n      41        0.987837  0.551415  5.641063  886.668091  \n      42        0.987837  0.551415  5.641063  886.668091  \n      43        0.987837  0.551415  5.641063  886.668091  \n      44        0.987837  0.551415  5.641063  886.668091  \n\n[314038 rows x 39 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>x_c</th>\n      <th>y_c</th>\n      <th>z_c</th>\n      <th>t_c</th>\n      <th>signal</th>\n      <th>m_id_event</th>\n      <th>m_id_primary</th>\n      <th>m_hits.m_photon_id_pmt</th>\n      <th>m_hits.m_photon_id_chip</th>\n      <th>m_hits.m_photon_id_layer</th>\n      <th>...</th>\n      <th>x_p</th>\n      <th>y_p</th>\n      <th>z_p</th>\n      <th>nx_p</th>\n      <th>ny_p</th>\n      <th>nz_p</th>\n      <th>beta</th>\n      <th>theta_p</th>\n      <th>phi_p</th>\n      <th>momentum</th>\n    </tr>\n    <tr>\n      <th>entry</th>\n      <th>subentry</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th>0</th>\n      <td>-70.879997</td>\n      <td>-226.880005</td>\n      <td>201.050003</td>\n      <td>2.188593</td>\n      <td>True</td>\n      <td>1.0</td>\n      <td>-211.0</td>\n      <td>367.0</td>\n      <td>31.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>1.275724</td>\n      <td>1.576625</td>\n      <td>0.0</td>\n      <td>-0.073019</td>\n      <td>-0.695325</td>\n      <td>0.714977</td>\n      <td>0.966818</td>\n      <td>0.774205</td>\n      <td>4.607758</td>\n      <td>528.209290</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-53.279999</td>\n      <td>-309.920013</td>\n      <td>201.050003</td>\n      <td>2.396409</td>\n      <td>True</td>\n      <td>1.0</td>\n      <td>-211.0</td>\n      <td>394.0</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>1.275724</td>\n      <td>1.576625</td>\n      <td>0.0</td>\n      <td>-0.073019</td>\n      <td>-0.695325</td>\n      <td>0.714977</td>\n      <td>0.966818</td>\n      <td>0.774205</td>\n      <td>4.607758</td>\n      <td>528.209290</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-36.480000</td>\n      <td>-306.559998</td>\n      <td>201.050003</td>\n      <td>2.382249</td>\n      <td>True</td>\n      <td>1.0</td>\n      <td>-211.0</td>\n      <td>394.0</td>\n      <td>48.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>1.275724</td>\n      <td>1.576625</td>\n      <td>0.0</td>\n      <td>-0.073019</td>\n      <td>-0.695325</td>\n      <td>0.714977</td>\n      <td>0.966818</td>\n      <td>0.774205</td>\n      <td>4.607758</td>\n      <td>528.209290</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-49.919998</td>\n      <td>-184.960007</td>\n      <td>201.050003</td>\n      <td>2.073419</td>\n      <td>True</td>\n      <td>1.0</td>\n      <td>-211.0</td>\n      <td>399.0</td>\n      <td>11.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>1.275724</td>\n      <td>1.576625</td>\n      <td>0.0</td>\n      <td>-0.073019</td>\n      <td>-0.695325</td>\n      <td>0.714977</td>\n      <td>0.966818</td>\n      <td>0.774205</td>\n      <td>4.607758</td>\n      <td>528.209290</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-12.160000</td>\n      <td>-288.959991</td>\n      <td>201.050003</td>\n      <td>2.326930</td>\n      <td>True</td>\n      <td>1.0</td>\n      <td>-211.0</td>\n      <td>425.0</td>\n      <td>37.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>1.275724</td>\n      <td>1.576625</td>\n      <td>0.0</td>\n      <td>-0.073019</td>\n      <td>-0.695325</td>\n      <td>0.714977</td>\n      <td>0.966818</td>\n      <td>0.774205</td>\n      <td>4.607758</td>\n      <td>528.209290</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">9999</th>\n      <th>40</th>\n      <td>178.240005</td>\n      <td>-80.959999</td>\n      <td>201.050003</td>\n      <td>3.695349</td>\n      <td>True</td>\n      <td>10000.0</td>\n      <td>-211.0</td>\n      <td>643.0</td>\n      <td>25.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.499871</td>\n      <td>-1.121928</td>\n      <td>0.0</td>\n      <td>0.419547</td>\n      <td>-0.313757</td>\n      <td>0.851784</td>\n      <td>0.987837</td>\n      <td>0.551415</td>\n      <td>5.641063</td>\n      <td>886.668091</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>178.240005</td>\n      <td>-74.239998</td>\n      <td>201.050003</td>\n      <td>3.687293</td>\n      <td>True</td>\n      <td>10000.0</td>\n      <td>-211.0</td>\n      <td>643.0</td>\n      <td>27.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>1.499871</td>\n      <td>-1.121928</td>\n      <td>0.0</td>\n      <td>0.419547</td>\n      <td>-0.313757</td>\n      <td>0.851784</td>\n      <td>0.987837</td>\n      <td>0.551415</td>\n      <td>5.641063</td>\n      <td>886.668091</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>226.880005</td>\n      <td>-53.279999</td>\n      <td>201.050003</td>\n      <td>3.892318</td>\n      <td>True</td>\n      <td>10000.0</td>\n      <td>-211.0</td>\n      <td>704.0</td>\n      <td>9.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>1.499871</td>\n      <td>-1.121928</td>\n      <td>0.0</td>\n      <td>0.419547</td>\n      <td>-0.313757</td>\n      <td>0.851784</td>\n      <td>0.987837</td>\n      <td>0.551415</td>\n      <td>5.641063</td>\n      <td>886.668091</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>274.720001</td>\n      <td>-209.279999</td>\n      <td>201.050003</td>\n      <td>4.102964</td>\n      <td>True</td>\n      <td>10000.0</td>\n      <td>-211.0</td>\n      <td>728.0</td>\n      <td>60.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>1.499871</td>\n      <td>-1.121928</td>\n      <td>0.0</td>\n      <td>0.419547</td>\n      <td>-0.313757</td>\n      <td>0.851784</td>\n      <td>0.987837</td>\n      <td>0.551415</td>\n      <td>5.641063</td>\n      <td>886.668091</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>251.199997</td>\n      <td>-18.879999</td>\n      <td>201.050003</td>\n      <td>3.840951</td>\n      <td>True</td>\n      <td>10000.0</td>\n      <td>-211.0</td>\n      <td>735.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>1.499871</td>\n      <td>-1.121928</td>\n      <td>0.0</td>\n      <td>0.419547</td>\n      <td>-0.313757</td>\n      <td>0.851784</td>\n      <td>0.987837</td>\n      <td>0.551415</td>\n      <td>5.641063</td>\n      <td>886.668091</td>\n    </tr>\n  </tbody>\n</table>\n<p>314038 rows √ó 39 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RnR-4_yXtH5v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652898489590,
     "user_tz": -180,
     "elapsed": 277,
     "user": {
      "displayName": "–ü–ª–∞—Ç–æ–Ω –î–º–∏—Ç—Ä–∏–µ–≤–∏—á –†–æ–≥–æ–∂–∏–Ω",
      "userId": "06374754299160062301"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def recoAngles(edf: pd.DataFrame, idf: pd.DataFrame, rotation_mode = False):\n",
    "  '''\n",
    "  –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —É–≥–ª–æ–≤ —Ñ–æ—Ç–æ–Ω–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç–∏—Ü—ã.\n",
    "  –ò–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –∏ —á–∞—Å—Ç–∏—Ü –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è —É–≥–ª—ã theta_c, phi_c –∏ –≤—Ä–µ–º—è –≤—ã–ª–µ—Ç–∞ —Ñ–æ—Ç–æ–Ω–æ–≤ t_c_orig –∏ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫ edf.\n",
    "  '''\n",
    "  r0 = edf.loc[:, ('x_p', 'y_p', 'z_p')].to_numpy()\n",
    "  if rotation_mode:\n",
    "    r = edf.loc[:, ('rotated_x', 'rotated_y', 'rotated_z')].to_numpy()\n",
    "    # n0 = edf.loc[:, ('rotated_nx_p', 'rotated_ny_p', 'rotated_nz_p')].to_numpy()\n",
    "    n0 = edf.loc[:, ('recalculated_nx_p', 'recalculated_ny_p', 'recalculated_nz_p')].to_numpy()\n",
    "  else:\n",
    "    r  = edf.loc[:, ('x_c', 'y_c', 'z_c')].to_numpy()\n",
    "    n0 = edf.loc[:, ('nx_p', 'ny_p', 'nz_p')].to_numpy()\n",
    "\n",
    "  speedOfLight_mmperns = 299.792458 # –º–º/–Ω—Å\n",
    "\n",
    "  # —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞ –¥–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞\n",
    "  dist = float(idf['distance'])\n",
    "\n",
    "  # —Ç–æ–ª—â–∏–Ω–∞ —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞\n",
    "  W = float(idf['W'])\n",
    "\n",
    "  # —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç —Ç–æ—á–∫–∏ –≤—ã–ª–µ—Ç–∞ —á–∞—Å—Ç–∏—Ü—ã –¥–æ –≤—Ö–æ–¥–Ω–æ–π –ø–ª–æ—Å–∫–æ—Å—Ç–∏ —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞\n",
    "  rad_pos = float(idf['zdis'])\n",
    "\n",
    "  # –ø–æ–ª–Ω–æ–µ —á–∏—Å–ª–æ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π\n",
    "  N = edf.shape[0]\n",
    "\n",
    "  # –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ—á–∫–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Ç—Ä–µ–∫–∞ —Å –§–î\n",
    "  if not rotation_mode:\n",
    "    y_i = r0[:,1] + (dist + rad_pos) * n0[:,1] / n0[:,2] # r0[:,1] + (dist + W + rad_pos) * n0[:,1] / n0[:,2]   #   r0[:,1] + (dist + rad_pos) * n0[:,1] / n0[:,2]\n",
    "    x_i = r0[:,0] + (y_i - r0[:,1]) * n0[:,0] / n0[:,1] # r0[:,0] + (y_i - r0[:,1]) * n0[:,0] / n0[:,1]    #     r0[:,0] + (dist + rad_pos) * n0[:,0] / n0[:,2]\n",
    "    edf['x_i'] = x_i\n",
    "    edf['y_i'] = y_i\n",
    "    edf['r_p_c'] = np.sqrt((r0[:,0] - x_i) ** 2 + (r0[:,1] - y_i) ** 2 + (r0[:,2] - r[:,2]) ** 2)\n",
    "    edf['r_c'] = np.sqrt((x_i - edf['x_c']) ** 2 + (y_i - edf['y_c']) ** 2)\n",
    "\n",
    "  if rotation_mode:\n",
    "    n_mean = float(idf['n_mean'])\n",
    "\n",
    "    edf['rotated_r_c'] = np.sqrt((edf['rotated_x_i'] - edf['rotated_x']) ** 2 + (edf['rotated_y_i'] - edf['rotated_y']) ** 2)\n",
    "\n",
    "    rotated_r_c = edf['rotated_r_c'].to_numpy()\n",
    "    # r_p_c = edf['r_p_c'].to_numpy()\n",
    "    beta = edf['beta'].to_numpy()\n",
    "    r_p_c = dist # or + W/2 ???\n",
    "\n",
    "    edf['beta_from_true_r'] = np.sqrt(rotated_r_c ** 2 + r_p_c ** 2) / (n_mean * r_p_c)\n",
    "    edf['true_r_from_beta'] = r_p_c * np.sqrt((n_mean * beta) ** 2 - 1)\n",
    "\n",
    "    avg_betas = []\n",
    "    for _, subentry in edf['beta_from_true_r'].groupby(level=0):\n",
    "      avg_beta = subentry.mean()\n",
    "      for __ in subentry:\n",
    "        avg_betas.append(avg_beta)\n",
    "    edf['beta_from_true_r_mean'] = avg_betas\n",
    "  # –∫–æ—Å–∏–Ω—É—Å—ã –∏ —Å–∏–Ω—É—Å—ã —Å—Ñ–µ—Ä–∏—á–µ—Å–∫–∏—Ö —É–≥–ª–æ–≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç–∏—Ü—ã\n",
    "  costheta, sintheta = n0[:,2], np.sqrt(n0[:,0]**2+n0[:,1]**2)\n",
    "  phi = np.arctan2(n0[:,1], n0[:,0])\n",
    "  cosphi, sinphi = np.cos(phi), np.sin(phi)\n",
    "\n",
    "  # –Ω–æ–º–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞ –≤—ã–ª–µ—Ç–∞ —Ñ–æ—Ç–æ–Ω–æ–≤\n",
    "  ro = r0 + (W/2+rad_pos)/n0[:,2].reshape(N,1)*n0\n",
    "\n",
    "  \"\"\"\n",
    "  –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –°–ö —á–∞—Å—Ç–∏—Ü—ã\n",
    "  ùë¢ùë• = cos ùúÉ(ùë£ùë• cos ùúô + ùë£ùë¶ sin ùúô) ‚àí ùë£ùëß sin ùúÉ,\n",
    "  ùë¢ùë¶ = ‚àíùë£ùë• sin ùúô + ùë£ùë¶ cos ùúô,\n",
    "  ùë¢ùëß = sin ùúÉ(ùë£ùë• cos ùúô + ùë£ùë¶ sin ùúô) + ùë£ùëß cos ùúÉ.\n",
    "  \"\"\"\n",
    "\n",
    "  # –≤–µ–∫—Ç–æ—Ä –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ñ–æ—Ç–æ–Ω–∞ –≤ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π –°–ö\n",
    "  s = (r-ro)\n",
    "  snorm = np.linalg.norm(s, axis=1, keepdims=True)\n",
    "  v = s / snorm\n",
    "  if not rotation_mode:\n",
    "    edf['t_c_orig'] = edf['t_c'] - (snorm / speedOfLight_mmperns).reshape(N)\n",
    "\n",
    "  # –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "  #del r0, n0, ro, r, s\n",
    "\n",
    "  U = np.stack((np.stack((costheta*cosphi, costheta*sinphi, -sintheta)),\n",
    "                np.stack((-sinphi,         cosphi,          np.full(N, 0.))),\n",
    "                np.stack((sintheta*cosphi, sintheta*sinphi, costheta)))).transpose(2,0,1)\n",
    "\n",
    "  # –µ–¥–∏–Ω–∏—á–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ñ–æ—Ç–æ–Ω–∞ –≤ –°–ö —á–∞—Å—Ç–∏—Ü—ã\n",
    "  u = (U @ v.reshape(N,3,1)).reshape(N,3)\n",
    "\n",
    "  # —Å—Ñ–µ—Ä–∏—á–µ—Å–∫–∏–µ —É–≥–ª—ã —Ñ–æ—Ç–æ–Ω–∞ –≤ –°–ö —á–∞—Å—Ç–∏—Ü—ã\n",
    "  if rotation_mode:\n",
    "    edf['rotated_theta_c'] = np.arccos(u[:,2])\n",
    "    edf['rotated_phi_c'] = np.arctan2(-u[:,1], -u[:,0])\n",
    "  else:\n",
    "    edf['theta_c'] = np.arccos(u[:,2])\n",
    "    edf['phi_c'] = np.arctan2(-u[:,1], -u[:,0])\n",
    "    avg_thetas = []\n",
    "    for _, subentry in edf['theta_c'].groupby(level=0):\n",
    "      avg_theta = subentry.mean()\n",
    "      for __ in subentry:\n",
    "        avg_thetas.append(avg_theta)\n",
    "    edf['theta_c_mean'] = avg_thetas"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def applySpaceCut(edf: pd.DataFrame) -> pd.DataFrame:\n",
    "  return edf[(abs(edf['x_c'] - edf['x_i']) <= 220) & (abs(edf['y_c'] - edf['y_i']) <= 220)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def signalLength(edf: pd.DataFrame):\n",
    "  t_signal = edf[edf['signal'] ==  True]['t_c']\n",
    "  t = []\n",
    "  for _, subentry in t_signal.groupby(level=0):\n",
    "    t_min = np.min(subentry)\n",
    "    t_max = np.max(subentry)\n",
    "    t.extend(t_max - t_min for __ in subentry)\n",
    "  t = np.array(t)\n",
    "  edf['signal_length'] = t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def planeRecalculation(edf: pd.DataFrame, idf: pd.DataFrame):\n",
    "    R_p = edf[['x_p', 'y_p', 'z_p']].to_numpy()\n",
    "    R = edf[['x_c', 'y_c', 'z_c']].to_numpy()\n",
    "    R_i = edf[['x_i', 'y_i', 'z_c']].to_numpy()\n",
    "    N = edf[['nx_p', 'ny_p', 'nz_p']].to_numpy()\n",
    "    dist = idf.W / 2 + idf.zdis\n",
    "    alpha = (float(dist) - R_p[:,2]) / N[:,2]\n",
    "    r_d = R_p + N * alpha[:, np.newaxis]\n",
    "\n",
    "    u = R - r_d\n",
    "    dot = np.sum(N * u, axis=1)\n",
    "    w = r_d - R_i\n",
    "    fac = -np.sum(N * w, axis=1) / dot\n",
    "    u *= fac[:, np.newaxis]\n",
    "\n",
    "    R_new = r_d + u\n",
    "\n",
    "\n",
    "\n",
    "    edf['recalculated_x'] = R_new[:,0]\n",
    "    edf['recalculated_y'] = R_new[:,1]\n",
    "    edf['recalculated_z'] = R_new[:,2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def primaryDirectionRecalculation(edf: pd.DataFrame):\n",
    "  N = edf.loc[:, ('nx_p', 'ny_p', 'nz_p')].to_numpy()\n",
    "  M = []\n",
    "  for n in N:\n",
    "    # C = np.stack((np.array([-(n[1] ** 2 + n[2] ** 2) / n[0], 0 , n[0]]),\n",
    "    #               np.array([n[1], - n[2], n[1]]),\n",
    "    #               np.array([n[2], n[1], n[2]])))\n",
    "\n",
    "    # C_inv = np.array([np.array([- n[0] / (n[0] ** 2 + n[1] ** 2 + n[2] ** 2), n[0] ** 2 * n[1] / (n[1] ** 4 + n[0] ** 2 * n[1] ** 2 + n[2] ** 4 + n[0] ** 2 * n[2] ** 2 + 2 * n[1] ** 2 * n[2] ** 2) , n[0] ** 2 * n[2] / (n[1] ** 4 + n[0] ** 2 * n[1] ** 2 + n[2] ** 4 + n[0] ** 2 * n[2] ** 2 + 2 * n[1] ** 2 * n[2] ** 2)]),\n",
    "    #               np.array([0, - n[2] / (n[1] ** 2 + n[2] ** 2), n[1] / (n[1] ** 2 + n[2] ** 2)]),\n",
    "    #               np.array([n[0] / (n[0] ** 2 + n[1] ** 2 + n[2] ** 2), n[1] / (n[0] ** 2 + n[1] ** 2 + n[2] ** 2), n[2] / (n[0] ** 2 + n[1] ** 2 + n[2] ** 2)])])\n",
    "    M.append([0, 0, 1])\n",
    "    # print(n)\n",
    "    # print(C_inv)\n",
    "    # print(C_inv @ n)\n",
    "    # break\n",
    "  M = np.array(M)\n",
    "  edf['recalculated_nx_p'] = M[:,0]\n",
    "  edf['recalculated_ny_p'] = M[:,1]\n",
    "  edf['recalculated_nz_p'] = M[:,2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def planeRotation(edf: pd.DataFrame):\n",
    "  R = edf[['recalculated_x', 'recalculated_y', 'recalculated_z']].to_numpy()\n",
    "  R_i = edf[['x_i', 'y_i', 'z_c']].to_numpy()\n",
    "  N = edf[['nx_p', 'ny_p', 'nz_p']].to_numpy() # N\n",
    "  M = np.array([0, 0, 1])                           # M\n",
    "  c = np.dot(N, M) / (np.linalg.norm(M) * np.linalg.norm(N, axis=1))\n",
    "  axis = np.cross(N, np.broadcast_to(M, (N.shape[0], 3))) / np.linalg.norm(np.cross(N, np.broadcast_to(M, (N.shape[0], 3))), axis=1, keepdims=True)\n",
    "  x, y, z = axis.T\n",
    "  s = np.sqrt(1-c*c)\n",
    "  C = 1-c\n",
    "  rmat = np.array([\n",
    "      [x*x*C+c, x*y*C-z*s, x*z*C+y*s],\n",
    "      [y*x*C+z*s, y*y*C+c, y*z*C-x*s],\n",
    "      [z*x*C-y*s, z*y*C+x*s, z*z*C+c]])\n",
    "  # print(rmat.shape)\n",
    "  # print(R.shape)\n",
    "  # print(rmat[:, :, 0])\n",
    "  # print(R[0])\n",
    "  # print(rmat[:, :, 0] @ R[0])\n",
    "  rotated_R = np.matmul(rmat.transpose((2, 0, 1)), R[:, :, np.newaxis])\n",
    "  rotated_R = np.squeeze(rotated_R, axis=-1).transpose().T\n",
    "  rotated_R_i = np.matmul(rmat.transpose((2, 0, 1)), R_i[:, :, np.newaxis])\n",
    "  rotated_R_i = np.squeeze(rotated_R_i, axis=-1).transpose().T\n",
    "  # print(rotated_R[0])\n",
    "  maskR = np.logical_or(abs(rotated_R[:, 0]) >= 500, abs(rotated_R[:, 1]) >= 500)\n",
    "  maskR_i = np.logical_or(abs(rotated_R_i[:, 0]) >= 500, abs(rotated_R_i[:, 1]) >= 500)\n",
    "  rotated_R[maskR] = [5000, 5000, 0]\n",
    "  rotated_R_i[maskR_i] = [5000, 5000, 0]\n",
    "  rotated_n = (rotated_R_i - edf[['x_p', 'y_p', 'z_p']].to_numpy()) / np.linalg.norm(rotated_R_i - edf[['x_p', 'y_p', 'z_p']].to_numpy(), axis=1, keepdims=True)\n",
    "  edf['rotated_x'] = rotated_R[:,0]\n",
    "  edf['rotated_y'] = rotated_R[:,1]\n",
    "  edf['rotated_z'] = rotated_R[:,2]\n",
    "  edf['rotated_x_i'] = rotated_R_i[:,0]\n",
    "  edf['rotated_y_i'] = rotated_R_i[:,1]\n",
    "  edf['rotated_z_i'] = rotated_R_i[:,2]\n",
    "  edf['rotated_nx_p'] = rotated_n[:,0]\n",
    "  edf['rotated_ny_p'] = rotated_n[:,1]\n",
    "  edf['rotated_nz_p'] = rotated_n[:,2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def applySecondSpaceCut(edf: pd.DataFrame) -> pd.DataFrame:\n",
    "  return edf[(abs(edf['rotated_x'] - edf['rotated_x_i']) <= 220) & (abs(edf['rotated_y'] - edf['rotated_y_i']) <= 220)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def local_sum_2d(event, r_slices, t_slices, square_counts, max_index, n, m, timestep, t_window_width, method='N/r'):\n",
    "  # cut_event = event[(event.t_c <= t_slices[np.clip(max_index[1] + m, a_min=0, a_max=10)]) & (event.t_c >= t_slices[np.clip(max_index[1] - m, a_min=0, a_max=10)]) &\n",
    "  #                   (event.rotated_r_c <= r_slices[max_index[0] + n]) & (event.rotated_r_c >= r_slices[max_index[0] - n])]\n",
    "  cut_event = event[(event.t_c <= np.clip(t_slices[max_index[1]] + t_window_width + timestep * m, 0, 10)) & (event.t_c >= np.clip(t_slices[max_index[1]] - timestep * m, 0, 10)) &\n",
    "                    (event.rotated_r_c <= r_slices[max_index[0] + n]) & (event.rotated_r_c >= r_slices[max_index[0] - n])]\n",
    "  return np.mean(cut_event.rotated_r_c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def local_weighed_sum_2d(r_slices, t_slices, square_counts, max_index, n, m, method='N/r'):\n",
    "  arr = np.mean(square_counts[max_index[0] - n:max_index[0] + n + 1, np.clip(max_index[1] - m, 0, 50):np.clip(max_index[1] + m + 1, 0, 50)], axis=1)\n",
    "  if method == 'N/r':\n",
    "    sum_arr = r_slices[max_index[0] - n:max_index[0] + n + 1] ** 2 * arr\n",
    "    den_arr = r_slices[max_index[0] - n:max_index[0] + n + 1] * arr\n",
    "  else:\n",
    "    sum_arr = r_slices[max_index[0] - n:max_index[0] + n + 1] * arr\n",
    "    den_arr = arr\n",
    "\n",
    "  weighted_sum = np.sum(sum_arr)\n",
    "  weighted_den = np.sum(den_arr)\n",
    "\n",
    "  return weighted_sum / weighted_den"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def local_weighed_sum(r_slices, counts, max_index, n, method='N/r'):\n",
    "  if method == 'N/r':\n",
    "    sum_arr = r_slices[max_index - n:max_index + n + 1] ** 2 * counts[max_index - n:max_index + n + 1]\n",
    "    den_arr = r_slices[max_index - n:max_index + n + 1] * counts[max_index - n:max_index + n + 1]\n",
    "  else:\n",
    "    sum_arr = r_slices[max_index - n:max_index + n + 1] * counts[max_index - n:max_index + n + 1]\n",
    "    den_arr = counts[max_index - n:max_index + n + 1]\n",
    "\n",
    "  weighted_sum = np.sum(sum_arr)\n",
    "  weighted_den = np.sum(den_arr)\n",
    "\n",
    "  return weighted_sum / weighted_den"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def pol(x, a, b, c):\n",
    "  return a * np.exp((x - b) ** 2 / c ** 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def rSlidingWindowIntro(edf: pd.DataFrame, idf: pd.DataFrame, bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, step=float(idf.pixel_size), method='N/r', cal_arr=False, t_window_width=2,\n",
    "                        r_width_factor=2, t_width_factor=8, full_width_t_hist = False, num_of_groups=5):\n",
    "  r_r_c = edf['rotated_r_c']\n",
    "  time_step = float(t_window_width) / t_width_factor\n",
    "  all_avgs = np.array(r_r_c.groupby(level=0).transform('mean').to_list()).ravel()\n",
    "  all_dists = np.abs(r_r_c - all_avgs)\n",
    "  all_sigms = np.array(r_r_c.groupby(level=0).transform('std').to_list()).ravel()\n",
    "\n",
    "  edf['mean_rotated_r_c'] = all_avgs\n",
    "  edf['dist_from_mean_rotated_r_c'] = all_dists\n",
    "  edf['rotated_r_c_sigm'] = all_sigms\n",
    "\n",
    "  # Compute beta_step and r_step using NumPy functions\n",
    "  beta_step = np.ptp(edf['beta'].values) # –Ω–µ —Ñ–∞–∫—Ç —á—Ç–æ –Ω—É–∂–Ω–æ values\n",
    "  r_step = np.ptp(edf['true_r_from_beta'].values)\n",
    "\n",
    "  # Compute beta_intervals using NumPy linspace function\n",
    "  num_of_groups = num_of_groups\n",
    "  beta_intervals = np.linspace(edf['beta'].min(), edf['beta'].max(), num=num_of_groups)\n",
    "\n",
    "  # Compute beta_group_to_bdf and true_r_group using NumPy operations\n",
    "  beta_group = np.floor((num_of_groups * edf['beta'] + max(edf['beta']) - (num_of_groups + 1) * min(edf['beta'])) / beta_step).values\n",
    "  true_r_group = np.floor((num_of_groups * edf['true_r_from_beta'] + max(edf['true_r_from_beta']) - (num_of_groups + 1) * min(edf['true_r_from_beta'])) / r_step).values\n",
    "\n",
    "  edf['beta_group'] = beta_group\n",
    "  edf['true_r_group'] = true_r_group\n",
    "\n",
    "  edf_to_bdf(edf.beta_group, bdf)\n",
    "  edf_to_bdf(edf.true_r_group, bdf)\n",
    "\n",
    "  edf_to_bdf(edf.theta_p, bdf)\n",
    "  bdf['cos_theta_p'] = np.cos(bdf['theta_p'])\n",
    "  # edf_to_bdf(edf.signal_counts, bdf)\n",
    "  edf_to_bdf(edf.beta, bdf)\n",
    "  edf_to_bdf(edf.true_r_from_beta, bdf)\n",
    "\n",
    "  # edf['slice_group'] = np.floor(r_r_c / step) * step\n",
    "  edf['slice_group'] = r_r_c # test\n",
    "  # edf['time_slice_group'] = np.floor(edf.t_c / time_step) * time_step\n",
    "  edf['time_slice_group'] = edf.t_c # test2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def calculateSignalCounts(edf: pd.DataFrame, bdf: pd.DataFrame):\n",
    "  signal_counts = edf['signal'].groupby(level=0).sum()\n",
    "  bdf['signal_counts'] = signal_counts.values\n",
    "  edf['signal_counts'] = edf.signal.groupby(level=0).transform('sum').values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def rSlidingWindowLoop1(edf: pd.DataFrame, idf: pd.DataFrame, bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, step=float(idf.pixel_size), method='N/r', cal_arr=False, t_window_width=2,\n",
    "                        r_width_factor=2, t_width_factor=8, full_width_t_hist = True, weighed = True):\n",
    "  step = step / r_width_factor\n",
    "  time_step = float(t_window_width) / t_width_factor\n",
    "\n",
    "  r_slices = np.arange(0, 800, step=step)\n",
    "  t_slices = np.arange(0, 15, step=time_step)\n",
    "\n",
    "  n_sigmas = np.ptp(avg_sigmas)\n",
    "  t_sigmas = np.ptp(avg_t_sigmas)\n",
    "  # all_counts_to_edf = np.zeros((n_sigmas, len(edf)))\n",
    "  all_counts_to_edf = np.zeros((n_sigmas, len(edf)))\n",
    "  all_calculated_r = np.zeros((n_sigmas, len(edf)))\n",
    "  all_calculated_r_from_2d = np.zeros((t_sigmas, n_sigmas, len(edf)))\n",
    "  cur_ind = 0\n",
    "  for i, (entry, subentry) in enumerate(edf[['slice_group', 'time_slice_group', 'rotated_r_c', 't_c']].groupby(level=0)):\n",
    "    counts = np.zeros(r_slices.shape)\n",
    "    square_counts = np.zeros(shape=(r_slices.shape[0], t_slices.shape[0]))\n",
    "\n",
    "    mask = np.logical_and(subentry.slice_group >= 16, subentry.slice_group <= 80)\n",
    "    slice_groups = subentry.slice_group[mask]\n",
    "    time_slice_groups = subentry.time_slice_group[mask]\n",
    "\n",
    "    counts, _ = np.histogram(slice_groups, bins=r_slices)\n",
    "    square_counts, _, __ = np.histogram2d(slice_groups, time_slice_groups, bins=(r_slices, t_slices))\n",
    "\n",
    "    if method == 'N/r':\n",
    "      counts = np.divide(np.add(counts[:-1], counts[1:]), r_slices[1:-1])\n",
    "      square_counts[:-1, :] = np.divide(np.add(square_counts[:-1, :], square_counts[1:, :]), r_slices[1:-1, np.newaxis])\n",
    "    if full_width_t_hist:\n",
    "      square_counts_but_last = sum([square_counts[:, it : -t_width_factor + 1 + it] for it in range(t_width_factor - 1)])\n",
    "      square_counts = np.add(square_counts_but_last, square_counts[:, t_width_factor - 1:])\n",
    "\n",
    "    max_index = np.argmax(counts)\n",
    "\n",
    "    max_index_2d = np.unravel_index(np.argmax(square_counts), square_counts.shape)\n",
    "\n",
    "    for j in range(n_sigmas):\n",
    "      all_counts_to_edf[j][cur_ind:subentry.shape[0] + cur_ind] = counts[np.floor_divide(subentry.slice_group, step).astype(int)] # fixed\n",
    "      # avg_r_from_slices = local_weighed_sum(r_slices, counts, max_index, j + avg_sigmas[0], method)\n",
    "      # all_calculated_r[j, cur_ind:subentry.shape[0] + cur_ind] = np.repeat(avg_r_from_slices, subentry.shape[0])\n",
    "      for t in range(t_sigmas):\n",
    "        if weighed:\n",
    "          avg_r_from_2d_slices = local_weighed_sum_2d(r_slices, t_slices, square_counts, max_index_2d, j + avg_sigmas[0], t + avg_t_sigmas[0])\n",
    "        else:\n",
    "          avg_r_from_2d_slices = local_sum_2d(subentry, r_slices, t_slices, square_counts, max_index_2d, j + avg_sigmas[0], t + avg_t_sigmas[0], t_window_width=t_window_width, timestep=time_step)\n",
    "\n",
    "        # if np.isnan(avg_r_from_2d_slices):\n",
    "        #   print(max_index_2d)\n",
    "        #   print(square_counts[max_index_2d[0] - 1:max_index_2d[0] + 2, max_index_2d[1] - 1: max_index_2d[1] + 2])\n",
    "        #   raise ValueError\n",
    "        all_calculated_r_from_2d[t, j, cur_ind:subentry.shape[0] + cur_ind] = np.repeat(avg_r_from_2d_slices, subentry.shape[0])\n",
    "\n",
    "    cur_ind += subentry.shape[0]\n",
    "  for j in range(n_sigmas):\n",
    "    edf[f'slice_counts_{j + avg_sigmas[0]}_sigms'] = all_counts_to_edf[j]\n",
    "    # edf[f'unfixed_calculated_r_{j + avg_sigmas[0]}_sigms'] = all_calculated_r[j, :]\n",
    "    for t in range(t_sigmas):\n",
    "      edf[f'unfixed_calculated_r_2d_{j + avg_sigmas[0]}_rsigms_{t + avg_t_sigmas[0]}_tsigms'] = all_calculated_r_from_2d[t, j, :]\n",
    "      edf_to_bdf(edf[f'unfixed_calculated_r_2d_{j + avg_sigmas[0]}_rsigms_{t + avg_t_sigmas[0]}_tsigms'], bdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def rSlidingWindowLoop2(edf: pd.DataFrame, idf: pd.DataFrame, bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, step=float(idf.pixel_size), method='N/r', cal_arr=False, t_window_width=2,\n",
    "                        r_width_factor=2, t_width_factor=8, full_width_t_hist = False, param_fit=False):\n",
    "\n",
    "  # cal_arr = np.array([np.array([np.array(y) for y in x]) for x in cal_arr])\n",
    "\n",
    "  edf_to_bdf(edf.theta_p, bdf)\n",
    "  bdf['cos_theta_p'] = np.cos(bdf['theta_p'])\n",
    "  edf['cos_theta_p'] = np.cos(edf['theta_p'])\n",
    "  theta_interval = np.ptp(bdf.cos_theta_p) / 10\n",
    "  theta_min = min(bdf.cos_theta_p)\n",
    "  theta_max = max(bdf.cos_theta_p)\n",
    "  edf_to_bdf(edf.beta, bdf)\n",
    "  edf_to_bdf(edf.true_r_from_beta, bdf)\n",
    "\n",
    "  # for n_sigms in range(*avg_sigmas):\n",
    "  #   meas_betas = []\n",
    "  #   for entry, subentry in edf[f'unfixed_calculated_r_{n_sigms}_sigms'].groupby(level=0):\n",
    "  #     try:\n",
    "  #       meas_beta = pol(subentry.iloc[0], *(cal_arr[n_sigms - 1][(np.floor((np.cos(edf.theta_p[entry].iloc[0]) - theta_min) / (theta_interval))).astype(int)]))\n",
    "  #     except IndexError:\n",
    "  #       meas_beta = pol(subentry.iloc[0], *(cal_arr[n_sigms - 1][9]))\n",
    "  #       print((np.cos(edf.theta_p[entry].iloc[0]) - theta_min) / (theta_interval))\n",
    "  #     for subsub in subentry:\n",
    "  #       meas_betas.append(meas_beta)\n",
    "  #   edf[f'beta_from_calc_r_{n_sigms}_sigms'] = meas_betas\n",
    "  #\n",
    "  #   edf[f'delta_beta_{n_sigms}_sigms'] = edf[f'beta_from_calc_r_{n_sigms}_sigms'] - edf['beta']\n",
    "  #   edf[f'eps_beta_{n_sigms}_sigms'] = edf[f'delta_beta_{n_sigms}_sigms'] / edf['beta'] * 100\n",
    "  #\n",
    "  #   edf_to_bdf(edf[f'unfixed_calculated_r_{n_sigms}_sigms'], bdf)\n",
    "  #   edf_to_bdf(edf[f'beta_from_calc_r_{n_sigms}_sigms'], bdf)\n",
    "  #   edf_to_bdf(edf[f'delta_beta_{n_sigms}_sigms'], bdf)\n",
    "  #   edf_to_bdf(edf[f'eps_beta_{n_sigms}_sigms'], bdf)\n",
    "\n",
    "\n",
    "  for n_sigms in range(*avg_sigmas):\n",
    "    for t_sigms in range(*avg_t_sigmas):\n",
    "      meas_betas = np.zeros(edf.shape[0])\n",
    "      cur_ind = 0\n",
    "      # meas_betas = []\n",
    "      for entry, subentry in edf[f'unfixed_calculated_r_2d_{n_sigms}_rsigms_{t_sigms}_tsigms'].groupby(level=0):\n",
    "        if param_fit:\n",
    "          cos_theta_p = edf.cos_theta_p[entry].iloc[0]\n",
    "          meas_beta = pol(subentry.iloc[0], pol2(cos_theta_p, *cal_arr[n_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][0]),\n",
    "                          pol2(cos_theta_p, *cal_arr[n_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][1]),\n",
    "                          pol2(cos_theta_p, *cal_arr[n_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][2]))\n",
    "        else:\n",
    "          if edf.cos_theta_p[entry].iloc[0] != theta_max:\n",
    "            meas_beta = pol(subentry.iloc[0], *(cal_arr[n_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][(np.floor(((edf.cos_theta_p[entry].iloc[0]) - theta_min) / theta_interval)).astype(int)]))\n",
    "          else:\n",
    "            meas_beta = pol(subentry.iloc[0], *(cal_arr[n_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][9]))\n",
    "        meas_betas[cur_ind: subentry.shape[0] + cur_ind] = np.repeat(meas_beta, subentry.shape[0])\n",
    "        cur_ind += subentry.shape[0]\n",
    "        # for subsub in subentry:\n",
    "        #   meas_betas.append(meas_beta)  # FIXME\n",
    "      edf[f'beta_from_calc_r_{n_sigms}_rsigms_{t_sigms}_tsigms'] = meas_betas\n",
    "      edf[f'delta_beta_{n_sigms}_rsigms_{t_sigms}_tsigms'] = edf[f'beta_from_calc_r_{n_sigms}_rsigms_{t_sigms}_tsigms'] - edf['beta']\n",
    "      edf[f'eps_beta_{n_sigms}_rsigms_{t_sigms}_tsigms'] = edf[f'delta_beta_{n_sigms}_rsigms_{t_sigms}_tsigms'] / edf['beta'] * 100\n",
    "\n",
    "\n",
    "      edf_to_bdf(edf[f'beta_from_calc_r_{n_sigms}_rsigms_{t_sigms}_tsigms'], bdf)\n",
    "      edf_to_bdf(edf[f'delta_beta_{n_sigms}_rsigms_{t_sigms}_tsigms'], bdf)\n",
    "      edf_to_bdf(edf[f'eps_beta_{n_sigms}_rsigms_{t_sigms}_tsigms'], bdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def rSlidingWindow(edf: pd.DataFrame, idf: pd.DataFrame, bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, step=float(idf.pixel_size), method='N/r', cal_arr=False, t_window_width=2,\n",
    "                        r_width_factor=2, t_width_factor=8, full_width_t_hist = True, num_of_groups=5, weighed=True, deg_lim=False, param_fit=False):\n",
    "  rSlidingWindowIntro(edf, idf, bdf, avg_sigmas, avg_t_sigmas, step=step, method=method, cal_arr=cal_arr, t_window_width=t_window_width,\n",
    "                      r_width_factor=r_width_factor, t_width_factor=t_width_factor, num_of_groups=num_of_groups)\n",
    "  calculateSignalCounts(edf, bdf)\n",
    "  rSlidingWindowLoop1(edf, idf, bdf, avg_sigmas, avg_t_sigmas, step=step, method=method, cal_arr=cal_arr, t_window_width=t_window_width,\n",
    "                      r_width_factor=r_width_factor, t_width_factor=t_width_factor, full_width_t_hist=full_width_t_hist, weighed=weighed)\n",
    "  if cal_arr is False:\n",
    "    cal_arr = np.array(calibration(edf, bdf, avg_sigmas=avg_sigmas, avg_t_sigmas=avg_t_sigmas, step=step, t_window_width=t_window_width,\n",
    "                                   r_width_factor=r_width_factor, t_width_factor=t_width_factor, weighed=weighed, deg_lim=deg_lim, param_fit=param_fit)) # add r and t calibr - done\n",
    "  rSlidingWindowLoop2(edf, idf, bdf, avg_sigmas, avg_t_sigmas, step=step, method=method, cal_arr=cal_arr, t_window_width=t_window_width,\n",
    "                      r_width_factor=r_width_factor, t_width_factor=t_width_factor, param_fit=param_fit)\n",
    "  return cal_arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def rms90(arr):\n",
    "    # Calculate the mean and standard deviation of the array\n",
    "    arr = arr.dropna()\n",
    "    arr_mean = np.mean(arr)\n",
    "    arr_std = np.std(arr)\n",
    "\n",
    "    # Define the upper and lower limits for the 90% range\n",
    "    lower_limit = np.percentile(arr, 5)\n",
    "    upper_limit = np.percentile(arr, 95)\n",
    "    # print(lower_limit, upper_limit)\n",
    "    # print(arr)\n",
    "    # Select the values within the 90% range\n",
    "    arr_filtered = arr[(arr >= lower_limit) & (arr <= upper_limit)]\n",
    "    # print(arr_filtered)\n",
    "    assert arr_filtered.shape\n",
    "    # Calculate the root mean square of the filtered values\n",
    "    rms = np.std(arr_filtered)\n",
    "\n",
    "    return rms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def betaGroupsRMS90(bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, n = 5):\n",
    "  beta_sigms = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), n), 0.)\n",
    "  beta_epss = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), n), 0.)\n",
    "  beta_sigms_sigms = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), n), 0.)\n",
    "\n",
    "  for group in range(1, n + 1):\n",
    "    data = bdf[bdf['beta_group'] == group]\n",
    "    for i in range(np.ptp(avg_sigmas)):\n",
    "      for j in range(np.ptp(avg_t_sigmas)):\n",
    "        population_fourth_moment = np.mean(bdf[f'delta_beta_{i + avg_sigmas[0]}_rsigms_{j + avg_t_sigmas[0]}_tsigms'] ** 4)\n",
    "        sample_fourth_moment = np.mean(data[f'delta_beta_{i + avg_sigmas[0]}_rsigms_{j + avg_t_sigmas[0]}_tsigms'] ** 4)\n",
    "        # print(np.std(data[f'delta_beta_{i + avg_sigmas[0]}_rsigms_{j + avg_t_sigmas[0]}_tsigms']))\n",
    "        beta_sigms[i, j, group - 1] = rms90(data[f'delta_beta_{i + avg_sigmas[0]}_rsigms_{j + avg_t_sigmas[0]}_tsigms'])\n",
    "        # assert not np.isnan(beta_sigms[i, j, group - 1])\n",
    "        beta_epss[i, j, group - 1] = rms90(data[f'eps_beta_{i + avg_sigmas[0]}_rsigms_{j + avg_t_sigmas[0]}_tsigms'])\n",
    "        beta_sigms_sigms[i, j, group - 1] = np.sqrt(2 * np.abs(sample_fourth_moment - population_fourth_moment) / (data.shape[0]))\n",
    "\n",
    "  return beta_sigms, beta_epss, beta_sigms_sigms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# labels = ['0', '1e3', '1e4', '1e5', '1e6']\n",
    "# labels = ['DCR = ' + i + ' $Hz/mm^2$' for i in labels]\n",
    "# num_of_groups = 10\n",
    "# y = np.arange(1, num_of_groups + 1)\n",
    "# x = (y * (max(edf['beta']) - min(edf['beta'])) - max(edf['beta']) + (num_of_groups + 1) * min(edf['beta'])) / num_of_groups\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(len(labels)):\n",
    "#   plt.plot(x, [0.0005] * 10, label=labels[i])\n",
    "# plt.ylim((0, 0.002))\n",
    "# # plt.xlim((0.954, 0.999))\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "def plot_final_graph(beta_sigms, beta_sigms_yerr, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, to_save=True, deg_lim=False, num_of_groups=10):\n",
    "  labels = ['0', '1e3', '1e4', '1e5', '1e6']\n",
    "  labels = ['DCR = ' + i + ' $Hz/mm^2$' for i in labels]\n",
    "  colors = ['c', 'y', 'g', 'r', 'm']\n",
    "  weight = 'weighed' if weighed else 'unweighed'\n",
    "  y = np.arange(1, num_of_groups + 1)\n",
    "  x = (y * (max(edf['beta']) - min(edf['beta'])) - max(edf['beta']) + (num_of_groups + 1) * min(edf['beta'])) / num_of_groups\n",
    "\n",
    "  fig, axs = plt.subplots(np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), figsize=(10 * np.ptp(avg_t_sigmas), 10 * np.ptp(avg_sigmas)))\n",
    "  title = f'Method: N(r) / r; {weight} Avg\\nR Width = {r_width}mm, T Width = {t_width}ns\\nR step factor = {r_factor}, T step factor = {t_factor}'\n",
    "  if deg_lim:\n",
    "    title += '\\n' + r'$\\theta_p < 10\\deg$'\n",
    "  # fig.suptitle(title)\n",
    "\n",
    "  if np.ptp(avg_sigmas) > 1:\n",
    "    for i in range(np.ptp(avg_sigmas)):\n",
    "      for j in range(np.ptp(avg_t_sigmas)):\n",
    "        for k in range(beta_sigms.shape[0]):\n",
    "          axs[i, j].plot(x, beta_sigms[k, i, j], label=labels[k], c=colors[k])\n",
    "          axs[i, j].errorbar(x, beta_sigms[k, i, j], xerr=[np.diff(x)[0]/4 for _ in x], linestyle='', c=colors[k])\n",
    "          axs[i, j].errorbar(x, beta_sigms[k, i, j], yerr=beta_sigms_yerr[k, i, j], linestyle='', c=colors[k])\n",
    "        axs[i, j].legend(loc='upper right')\n",
    "        axs[i, j].set_xlabel('Beta Group')\n",
    "        axs[i, j].set_ylabel(r'RMS90($\\Delta\\beta$)')\n",
    "        if deg_lim:\n",
    "          axs[i, j].set_ylim((0, 0.004))\n",
    "        axs[i, j].set_title(f'Velocity resoultion for\\nr window width = {avg_sigmas[0] + i}$\\sigma$\\nt window width = {avg_t_sigmas[0] + j}$\\sigma$')\n",
    "        axs[i, j].grid()\n",
    "  elif np.ptp(avg_t_sigmas) > 1:\n",
    "    for j in range(np.ptp(avg_t_sigmas)):\n",
    "      for k in range(beta_sigms.shape[0]):\n",
    "        axs[j].plot(x, beta_sigms[k, 0, j], label=labels[k], c=colors[k])\n",
    "        axs[j].errorbar(x, beta_sigms[k, 0, j], xerr=[np.diff(x)[0]/4 for _ in x], linestyle='', c=colors[k])\n",
    "        axs[j].errorbar(x, beta_sigms[k, 0, j], yerr=beta_sigms_yerr[k, 0, j], linestyle='', c=colors[k])\n",
    "      axs[j].legend(loc='upper right')\n",
    "      axs[j].set_xlabel('Beta Group')\n",
    "      axs[j].set_ylabel(r'RMS90($\\Delta\\beta)$')\n",
    "      if deg_lim:\n",
    "        axs[j].set_ylim((0, 0.004))\n",
    "      axs[j].set_title(f'Velocity resoultion for\\nr window width = {avg_sigmas[0]}$\\sigma$\\nt window width = {avg_t_sigmas[0] + j}$\\sigma$')\n",
    "      axs[j].grid()\n",
    "  else:\n",
    "    for k in range(beta_sigms.shape[0]):\n",
    "      axs.plot(x, beta_sigms[k, 0, 0], label=labels[k], c=colors[k])\n",
    "      axs.errorbar(x, beta_sigms[k, 0, 0], xerr=[np.diff(x)[0]/4 for _ in x], linestyle='', c=colors[k])\n",
    "      axs.errorbar(x, beta_sigms[k, 0, 0], yerr=beta_sigms_yerr[k, 0, 0], linestyle='', c=colors[k])\n",
    "    axs.legend(loc='upper right')\n",
    "    axs.set_xlabel('Beta Group')\n",
    "    axs.set_ylabel(r'RMS90($\\Delta\\beta$)')\n",
    "    if deg_lim:\n",
    "      axs.set_ylim((0, 0.002))\n",
    "    axs.set_title(f'Velocity resoultion for\\nr window width = {avg_sigmas[0]}$\\sigma$\\nt window width = {avg_t_sigmas[0]}$\\sigma$')\n",
    "    axs.grid()\n",
    "\n",
    "  if to_save:\n",
    "    filename = f'{weight}_avg_rw={r_width}_tw={t_width}_rs={r_factor}_ts={t_factor}_rsigms={avg_sigmas[0]}-{avg_sigmas[-1]-1}_tsigms={avg_t_sigmas[0]}-{avg_t_sigmas[-1]-1}'\n",
    "    if deg_lim:\n",
    "      filename += '_10deg'\n",
    "    filename += '.png'\n",
    "    fig.savefig(os.path.join('results', f'{filename}'))\n",
    "    plt.close(fig)\n",
    "  else:\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def plot_groupped_distributions(bdf, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, background, to_save=True, deg_lim=False, num_of_groups=10):\n",
    "  labels = ['0', '1e3', '1e4', '1e5', '1e6']\n",
    "  labels = ['DCR = ' + i + ' cps' for i in labels]\n",
    "  colors = ['c', 'y', 'g', 'r', 'm']\n",
    "  weight = 'weighed' if weighed else 'unweighed'\n",
    "  left_lim = min(bdf[f'delta_beta_{avg_sigmas[0]}_rsigms_{avg_t_sigmas[0]}_tsigms'])\n",
    "  right_lim = max(bdf[f'delta_beta_{avg_sigmas[0]}_rsigms_{avg_t_sigmas[0]}_tsigms'])\n",
    "  y = np.arange(1, num_of_groups + 1)\n",
    "  x = (y * (max(edf['beta']) - min(edf['beta'])) - max(edf['beta']) + (num_of_groups + 1) * min(edf['beta'])) / num_of_groups\n",
    "  x_interval_over_2 = (x[1] - x[0]) / 2\n",
    "  fig, axs = plt.subplots(num_of_groups, 1, figsize=(16, 9 * num_of_groups), sharex=True)\n",
    "  title = f'Method: N(r) / r; {weight} Avg\\nR Width = {r_width}mm, T Width = {t_width}ns\\nR step factor = {r_factor}, T step factor = {t_factor}, DCR={background}'\n",
    "  if deg_lim:\n",
    "    title += '\\n' + r'$\\theta_p < 10\\deg$'\n",
    "  # fig.suptitle(title)\n",
    "  fig.tight_layout()\n",
    "  if np.ptp(avg_sigmas) > 1:\n",
    "    pass\n",
    "  elif np.ptp(avg_t_sigmas) > 1:\n",
    "    pass\n",
    "  else:\n",
    "    for group in range(1, num_of_groups + 1):\n",
    "      data = bdf[bdf['beta_group'] == group]\n",
    "      # data = data.dropna()\n",
    "      # print(data.shape)\n",
    "      # bin_heights, bin_borders = np.histogram(data[f'delta_beta_{avg_sigmas[0]}_rsigms_{avg_t_sigmas[0]}_tsigms'], bins='auto', normed=True)\n",
    "      # bin_width = np.diff(bin_borders)\n",
    "      axs[group - 1].hist(data[f'delta_beta_{avg_sigmas[0]}_rsigms_{avg_t_sigmas[0]}_tsigms'], bins='auto')\n",
    "      # axs[group - 1].set_xlabel(r'$\\Delta\\beta$')\n",
    "      axs[group - 1].set_ylabel(r'Events')\n",
    "      axs[group - 1].set_title(r'$\\beta$ in ' + f'[{round(x[group - 1] - x_interval_over_2, 3)}, {round(x[group -1 ] + x_interval_over_2, 3)}]')\n",
    "      axs[group - 1].set_xlim((-0.05, 0.08))\n",
    "\n",
    "  if to_save:\n",
    "    filename = f'Hist_{weight}_avg_rw={r_width}_tw={t_width}_rs={r_factor}_ts={t_factor}_rsigms={avg_sigmas[0]}-{avg_sigmas[-1]-1}_tsigms={avg_t_sigmas[0]}-{avg_t_sigmas[-1]-1}_background={background}'\n",
    "    if deg_lim:\n",
    "      filename += '_10deg'\n",
    "    filename += '.png'\n",
    "    fig.savefig(os.path.join('results', f'{filename}'))\n",
    "    plt.close(fig)\n",
    "  else:\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# print([[[]]* 5] * 5)\n",
    "# print(cal_arr.shape) # r_sigms -> t_sigms -> thetq_groups -> 3 params\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def pol2old(x, b, c, d):\n",
    "  return b * x ** 2 + c * x + d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def pol2(x, p0, p1, p2):\n",
    "  return p0 + p1 * x + p2 * x ** 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def d3pol2(X, p0, p1, p2, q0, q1, q2, k0, k1, k2):\n",
    "  r, theta = X\n",
    "  # return pol(r, pol2(theta, p0, p1, p2), pol2(theta, q0, q1, q2), pol2(theta, k0, k1, k2))\n",
    "  return pol(r, p0 + p1 * theta + p2 * theta ** 2, q0 + q1 * theta + q2 * theta ** 2, k0 + k1 * theta + k2 * theta ** 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def calibration(edf: pd.DataFrame, bdf: pd.DataFrame, avg_sigmas: tuple, avg_t_sigmas: tuple, step=float(idf.pixel_size), method='N/r', t_window_width=2,\n",
    "                        r_width_factor=2, t_width_factor=8, full_width_t_hist = False, weighed=True, deg_lim=False, param_fit=False):\n",
    "  def gaussian(x, mean, sigma):\n",
    "    return norm.pdf(x, loc=mean, scale=sigma)\n",
    "  # to_return_unbinned = [[], [], [], []]\n",
    "  bdf['cos_theta_p'] = np.cos(bdf['theta_p'])\n",
    "  theta_p_max = max(bdf.cos_theta_p)\n",
    "  theta_p_min = min(bdf.cos_theta_p)\n",
    "  num_of_theta_intervals = 11\n",
    "  theta_intervals = np.linspace(theta_p_min, theta_p_max, num=num_of_theta_intervals)\n",
    "  theta_dif = (theta_intervals[1:] + theta_intervals[:-1]) / 2\n",
    "  to_return_unbinned = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), num_of_theta_intervals - 1, 3), 0.)\n",
    "\n",
    "  errs_tmp = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), num_of_theta_intervals - 1, 3), 0.)\n",
    "  fit_params = np.full((np.ptp(avg_sigmas), np.ptp(avg_t_sigmas), 3, 3), 0.)\n",
    "\n",
    "  weight = 'weighed' if weighed else 'unweighed'\n",
    "  beta_min = min(bdf.beta)\n",
    "  num_of_beta_intervals = 10 # was 20\n",
    "  beta_delim = (max(bdf.beta) - min(bdf.beta)) / num_of_beta_intervals\n",
    "  beta_intervals = np.linspace(min(bdf.beta), max(bdf.beta), num=num_of_beta_intervals + 1)\n",
    "  dir_to_save = f'{weight}_rw={step}_tw={t_window_width}_rs={r_width_factor}_ts={t_width_factor}'\n",
    "  if not os.path.exists(os.path.join('calibrations', dir_to_save)):\n",
    "    os.mkdir(os.path.join('calibrations', dir_to_save))\n",
    "  for r_sigms in range(*avg_sigmas):\n",
    "    fig, axs = plt.subplots(num_of_theta_intervals - 1, np.ptp(avg_t_sigmas), figsize=(16 * np.ptp(avg_t_sigmas), 90))\n",
    "    for t_sigms in range(*avg_t_sigmas):\n",
    "      chosen_column = f'unfixed_calculated_r_2d_{r_sigms}_rsigms_{t_sigms}_tsigms'\n",
    "\n",
    "      meas_r_min = min(bdf[chosen_column])\n",
    "      meas_r_max = max(bdf[chosen_column])\n",
    "      num_of_meas_r_intervals = num_of_beta_intervals\n",
    "      meas_r_delim = (meas_r_max - meas_r_min) / num_of_meas_r_intervals\n",
    "      meas_r_intervals = np.linspace(meas_r_min, meas_r_max, num=num_of_meas_r_intervals + 1)\n",
    "\n",
    "\n",
    "      # fig2, axs2 = plt.subplots(10* num_of_theta_intervals - 10, 10, figsize=(16, 90))\n",
    "\n",
    "      for theta_interval_index in range(num_of_theta_intervals - 1):\n",
    "        xerrs = []\n",
    "        yerrs = []\n",
    "        gauss_beta = []\n",
    "        gauss_r = []\n",
    "        t_bdf = bdf.copy()\n",
    "        t_bdf = t_bdf[np.isfinite(t_bdf[chosen_column])]\n",
    "        t_bdf = t_bdf[t_bdf.signal_counts >= 15]\n",
    "        t_bdf = t_bdf[t_bdf.cos_theta_p <= theta_intervals[theta_interval_index + 1]]\n",
    "        t_bdf = t_bdf[t_bdf.cos_theta_p >= theta_intervals[theta_interval_index]]\n",
    "        if t_sigms - avg_t_sigmas[0] != 0:\n",
    "          for_colorbar = axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].hist2d(t_bdf[chosen_column], t_bdf.beta, bins=70, range=((0, 80), (beta_min,1)))\n",
    "          fig.colorbar(for_colorbar[3], ax=axs[theta_interval_index, t_sigms - avg_t_sigmas[0]])\n",
    "        else:\n",
    "          for_colorbar = axs[theta_interval_index].hist2d(t_bdf[chosen_column], t_bdf.beta, bins=70, range=((0, 80), (beta_min,1)))\n",
    "          fig.colorbar(for_colorbar[3], ax=axs[theta_interval_index])\n",
    "        t_bdf = t_bdf[t_bdf[chosen_column] <= 65]\n",
    "        t_bdf = t_bdf[t_bdf[chosen_column] >= 25]\n",
    "\n",
    "        pol_param, cov = curve_fit(pol, t_bdf[chosen_column], t_bdf.beta, maxfev=50000, p0=(1, 80, 30))\n",
    "        to_return_unbinned[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][theta_interval_index] = pol_param\n",
    "        pol_param_errs = np.sqrt(np.diag(cov))\n",
    "        errs_tmp[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][theta_interval_index] = pol_param_errs\n",
    "        rs = np.linspace(10, 80, num=50)\n",
    "        chi2 = np.sum((t_bdf.beta - pol(t_bdf[chosen_column], *pol_param)) ** 2)\n",
    "\n",
    "        if t_sigms - avg_t_sigmas[0] != 0:\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].plot(rs, pol(rs, *pol_param), label=r'$\\chi^2$ = '+ str(chi2), c='r')\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].set_xlim((0, 90))\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].set_ylim((0.955, 1))\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].set_ylim((beta_min, 1))\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].set_xlabel(r'$R_{reco}$, mm')\n",
    "          axs[theta_interval_index, t_sigms - avg_t_sigmas[0]].set_ylabel(r'$\\beta_{true}$')\n",
    "        else:\n",
    "          axs[theta_interval_index].plot(rs, pol(rs, *pol_param), label=r'$\\chi^2$ = '+ str(chi2), c='r')\n",
    "          axs[theta_interval_index].set_xlim((0, 90))\n",
    "          axs[theta_interval_index].set_ylim((0.955, 1))\n",
    "          axs[theta_interval_index].set_ylim((beta_min, 1))\n",
    "          axs[theta_interval_index].set_xlabel(r'$R_{reco}$, mm')\n",
    "          axs[theta_interval_index].set_ylabel(r'$\\beta_{true}$')\n",
    "      if param_fit:\n",
    "        t_bdf = bdf.copy()\n",
    "        t_bdf = t_bdf[np.isfinite(t_bdf[chosen_column])]\n",
    "        t_bdf = t_bdf[t_bdf.signal_counts >= 5]\n",
    "        X = (np.array(t_bdf[chosen_column]), np.array(t_bdf.cos_theta_p))\n",
    "        fit, errs = curve_fit(d3pol2, X, t_bdf.beta, p0=(1.219, -0.5588, 0.2946, 864.4, -1922, 1055, -2535, 6572, -3751))\n",
    "        errs = np.sqrt(np.diag(errs))\n",
    "        for param in range(3):\n",
    "          fit_params[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][param] = fit[param * 3: param * 3 + 3]\n",
    "        print(fit)\n",
    "        print(errs)\n",
    "        chi2 = np.sum((t_bdf.beta - d3pol2(X, *fit)) ** 2)\n",
    "        print(chi2)\n",
    "      # if param_fit:\n",
    "      #   for param in range(3):\n",
    "      #     fit, _ = curve_fit(pol2, theta_dif, to_return_unbinned[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][:, param], sigma=errs_tmp[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][:, param])\n",
    "      #     fit_params[r_sigms - avg_sigmas[0]][t_sigms - avg_t_sigmas[0]][param] = fit\n",
    "    filename = f'rsigm={r_sigms}_t_sigms={avg_t_sigmas[0]}-{avg_t_sigmas[-1] - 1}'\n",
    "    if deg_lim:\n",
    "      filename += '_10deg'\n",
    "    if dir_to_save != '':\n",
    "      fig.savefig(os.path.join('calibrations', dir_to_save, f'{filename}'))\n",
    "      plt.close(fig)\n",
    "\n",
    "\n",
    "  if param_fit:\n",
    "    return fit_params\n",
    "  return to_return_unbinned\n",
    "# cal_arr = np.array(calibration(edf, bdf, avg_sigmas=(1, 5), avg_t_sigmas=(1, 5))) # add r and t calibr - done"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '—ã' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [88], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43m—ã\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name '—ã' is not defined"
     ]
    }
   ],
   "source": [
    "—ã"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "  print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# With DCR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f4VM3-a7N3wA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1652899028826,
     "user_tz": -180,
     "elapsed": 22573,
     "user": {
      "displayName": "–ü–ª–∞—Ç–æ–Ω –î–º–∏—Ç—Ä–∏–µ–≤–∏—á –†–æ–≥–æ–∂–∏–Ω",
      "userId": "06374754299160062301"
     }
    },
    "outputId": "9c993c1f-f0b0-40cf-c4f8-0190fe507ae2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "event = 1444\n",
    "#momentum = edf.at[(event, 0), 'momentum']\n",
    "#theta_p = edf.at[(event, 0), 'theta_p']*180/np.pi\n",
    "avg_sigmas=(4, 5)\n",
    "avg_t_sigmas=(4, 5)\n",
    "num_of_groups = 10\n",
    "r_width = float(idf.pixel_size)\n",
    "t_width = 0.25\n",
    "t_step = 0.25\n",
    "r_factor = 2 # not to change\n",
    "t_factor = int(t_width / t_step)\n",
    "weighed = False\n",
    "deg_lim = False\n",
    "param_fit = False\n",
    "for t_width in [0.25]: # [0.25, 0.5, 0.75, 1]\n",
    "  for t_step in [0.25]: # [0.25, 0.5]\n",
    "    for r_width in [2 * float(idf.pixel_size)]: # [float(idf.pixel_size), 2 * float(idf.pixel_size)]\n",
    "      for weighed in [True]: # [False, True]\n",
    "        print(f'Generating: {t_width}_{t_step}_{r_width}_{weighed}\\n')\n",
    "        cal_arr_for_dcr = False\n",
    "        beta_sigms = []\n",
    "        beta_sigms_yerr = []\n",
    "        beta_sigms_deglim = []\n",
    "        beta_sigms_yerr_deglim = []\n",
    "        for dcr in ['0']  : # ['0', '1e3', '1e4', '1e5', '1e6']\n",
    "          timer_start = perf_counter()\n",
    "          gen = genChunkFromRoot(filepath, 10000, noisefreqpersqmm=float(dcr), shiftSignalTimes=True)\n",
    "          c_bdf_d = pd.DataFrame()\n",
    "          for i in range(1):\n",
    "            edf_d = next(gen)\n",
    "            # edf_d = next(genChunkFromRoot(filepath, 10000, noisefreqpersqmm=float(dcr), shiftSignalTimes=True))\n",
    "\n",
    "            bdf_d = pd.DataFrame()\n",
    "            # signalLength(edf_d)\n",
    "            recoAngles(edf_d, idf)\n",
    "            edf_d = applySpaceCut(edf_d)\n",
    "            planeRecalculation(edf_d, idf)\n",
    "            planeRotation(edf_d)\n",
    "            edf_d = applySecondSpaceCut(edf_d)\n",
    "            primaryDirectionRecalculation(edf_d)\n",
    "\n",
    "            recoAngles(edf_d, idf, rotation_mode=True)\n",
    "            cal_arr_for_dcr = rSlidingWindow(edf_d, idf, bdf_d, avg_sigmas=avg_sigmas, avg_t_sigmas=avg_t_sigmas, cal_arr=cal_arr_for_dcr, num_of_groups=num_of_groups,\n",
    "                                             step=r_width, t_window_width=t_width, r_width_factor=r_factor, t_width_factor=t_factor, weighed=weighed, deg_lim=deg_lim, param_fit=param_fit)\n",
    "\n",
    "            if deg_lim:\n",
    "              edf_d = edf_d[edf_d.theta_p <= 10. * np.pi / 180]\n",
    "              edf_d = edf_d[edf_d.signal_counts >= 5]\n",
    "              bdf_d = bdf_d[bdf_d.theta_p <= 10. * np.pi / 180]\n",
    "              bdf_d = bdf_d[bdf_d.signal_counts >= 5]\n",
    "            if i == 0:\n",
    "              c_bdf_d = bdf_d\n",
    "            else:\n",
    "              c_bdf_d = pd.concat([c_bdf_d, bdf_d], ignore_index=True)\n",
    "          plot_groupped_distributions(c_bdf_d, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, background=dcr, deg_lim=False, num_of_groups=num_of_groups, to_save=True)\n",
    "          bg = betaGroupsRMS90(c_bdf_d, avg_sigmas=avg_sigmas, avg_t_sigmas=avg_t_sigmas, n=num_of_groups)\n",
    "          beta_sigms.append(bg[0])\n",
    "          beta_sigms_yerr.append(bg[2])\n",
    "\n",
    "          c_bdf_d = c_bdf_d[c_bdf_d.theta_p <= 10. * np.pi / 180]\n",
    "          c_bdf_d = c_bdf_d[c_bdf_d.signal_counts >= 5]\n",
    "\n",
    "          plot_groupped_distributions(c_bdf_d, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, background=dcr, deg_lim=True, num_of_groups=num_of_groups, to_save=True)\n",
    "          bg_deglim = betaGroupsRMS90(c_bdf_d, avg_sigmas=avg_sigmas, avg_t_sigmas=avg_t_sigmas, n=num_of_groups)\n",
    "          beta_sigms_deglim.append(bg_deglim[0])\n",
    "          beta_sigms_yerr_deglim.append(bg_deglim[2])\n",
    "          print(perf_counter() - timer_start)\n",
    "\n",
    "          # plothits(edf_d, 1, event, dir_to_save=f'event_{event}_{dcr}_noise')\n",
    "\n",
    "          #figxy.savefig(os.path.join(picsdir, f'labeled_ring_pi_p{momentum:.0f}mev_theta{theta_p:.0f}deg_dcr{dcr:.3g}.png'))\n",
    "          #figtime.savefig(os.path.join(picsdir, f'labeled_time_pi_p{momentum:.0f}mev_theta{theta_p:.0f}deg_dcr{dcr:.3g}.png'))\n",
    "        beta_sigms = np.array(beta_sigms)\n",
    "        beta_sigms_yerr = np.array(beta_sigms_yerr)\n",
    "        beta_sigms_deglim = np.array(beta_sigms_deglim)\n",
    "        beta_sigms_yerr_deglim = np.array(beta_sigms_yerr_deglim)\n",
    "        plot_final_graph(beta_sigms, beta_sigms_yerr, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, deg_lim=False, num_of_groups=num_of_groups)\n",
    "\n",
    "        plot_final_graph(beta_sigms_deglim, beta_sigms_yerr_deglim, avg_sigmas, avg_t_sigmas, r_width, t_width, r_factor, t_factor, weighed, deg_lim=True, num_of_groups=num_of_groups)"
   ],
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating: 0.25_0.25_6.32_True\n",
      "\n",
      "    Generate noise with DCR per mm^2 0.0, mean number of hits per event: 0.00.\n",
      "29.183363300000565\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cal_arr_for_dcr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}