{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-07T19:16:52.149789Z",
     "start_time": "2025-01-07T19:16:50.324133Z"
    }
   },
   "source": [
    "from cProfile import label\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from farich_functions import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def enforce_float32(df):\n",
    "    return df.astype({col: np.float32 for col in df.select_dtypes(include=['float64']).columns})\n",
    "\n",
    "\n",
    "idf = pd.DataFrame()\n",
    "idf['W'] = [35.]\n",
    "# idf['W'] = [40.]\n",
    "\n",
    "idf['zdis'] = [800.]\n",
    "idf['distance'] = [205.]  # 200\n",
    "idf['n_mean'] = [1.04511]\n",
    "# \n",
    "# idf['n_mean'] = [1.0502]\n",
    "\n",
    "idf['pixel_size'] = [3.16]\n",
    "mu_mass = 105.65\n",
    "pi_mass = 139.57\n",
    "ka_mass = 493.68"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:14.220550Z",
     "start_time": "2025-01-07T19:16:52.167181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "edf, bdf, gdf = create_edf('fullsim_optical_2000_pi_bin_1_FARICH_35mm_no_no_trackers.root', sample_num=None,\n",
    "                           uncertain_angle=False, is_mu=False, num_of_files=11)"
   ],
   "id": "97b7428bd582fa12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21988, 5)\n",
      "(21988, 3)\n",
      "(21864, 5)\n",
      "(21864, 3)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:15.120012Z",
     "start_time": "2025-01-07T19:17:15.108639Z"
    }
   },
   "cell_type": "code",
   "source": "edf",
   "id": "5827a9d47119ea3d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      x_c     y_c       t_c        x_i         y_i     z_c  \\\n",
       "entry subentry                                                               \n",
       "0     0         89.440131  115.36  0.668623  71.239201  102.379707  1000.0   \n",
       "      1         96.160131  112.00  0.617086  71.239201  102.379707  1000.0   \n",
       "      2         79.360131  125.44  0.639925  71.239201  102.379707  1000.0   \n",
       "      3         42.400131  105.28  0.590146  71.239201  102.379707  1000.0   \n",
       "      4         45.760131  101.92  0.573616  71.239201  102.379707  1000.0   \n",
       "...                   ...     ...       ...        ...         ...     ...   \n",
       "21863 44        32.320131  622.72  0.594467  75.151100  664.462287  1000.0   \n",
       "      45        62.560131  605.92  0.570020  75.151100  664.462287  1000.0   \n",
       "      46        12.160131  659.68  0.684080  75.151100  664.462287  1000.0   \n",
       "      47        25.600131  629.44  0.608963  75.151100  664.462287  1000.0   \n",
       "      48        18.880131  736.96  0.842494  75.151100  664.462287  1000.0   \n",
       "\n",
       "                  mass       true_p      beta  x_p  y_p  z_p      nx_p  \\\n",
       "entry subentry                                                           \n",
       "0     0         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      1         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      2         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      3         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      4         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "...                ...          ...       ...  ...  ...  ...       ...   \n",
       "21863 44        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      45        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      46        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      47        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      48        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "\n",
       "                    ny_p      nz_p  \n",
       "entry subentry                      \n",
       "0     0         0.101593  0.992311  \n",
       "      1         0.101593  0.992311  \n",
       "      2         0.101593  0.992311  \n",
       "      3         0.101593  0.992311  \n",
       "      4         0.101593  0.992311  \n",
       "...                  ...       ...  \n",
       "21863 44        0.552347  0.831270  \n",
       "      45        0.552347  0.831270  \n",
       "      46        0.552347  0.831270  \n",
       "      47        0.552347  0.831270  \n",
       "      48        0.552347  0.831270  \n",
       "\n",
       "[660903 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>x_c</th>\n",
       "      <th>y_c</th>\n",
       "      <th>t_c</th>\n",
       "      <th>x_i</th>\n",
       "      <th>y_i</th>\n",
       "      <th>z_c</th>\n",
       "      <th>mass</th>\n",
       "      <th>true_p</th>\n",
       "      <th>beta</th>\n",
       "      <th>x_p</th>\n",
       "      <th>y_p</th>\n",
       "      <th>z_p</th>\n",
       "      <th>nx_p</th>\n",
       "      <th>ny_p</th>\n",
       "      <th>nz_p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <th>subentry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>89.440131</td>\n",
       "      <td>115.36</td>\n",
       "      <td>0.668623</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.160131</td>\n",
       "      <td>112.00</td>\n",
       "      <td>0.617086</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.360131</td>\n",
       "      <td>125.44</td>\n",
       "      <td>0.639925</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.400131</td>\n",
       "      <td>105.28</td>\n",
       "      <td>0.590146</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.760131</td>\n",
       "      <td>101.92</td>\n",
       "      <td>0.573616</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">21863</th>\n",
       "      <th>44</th>\n",
       "      <td>32.320131</td>\n",
       "      <td>622.72</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>62.560131</td>\n",
       "      <td>605.92</td>\n",
       "      <td>0.570020</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>12.160131</td>\n",
       "      <td>659.68</td>\n",
       "      <td>0.684080</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>25.600131</td>\n",
       "      <td>629.44</td>\n",
       "      <td>0.608963</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>18.880131</td>\n",
       "      <td>736.96</td>\n",
       "      <td>0.842494</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660903 rows Ã— 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:15.891397Z",
     "start_time": "2025-01-07T19:17:15.536789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.hist(edf.x_c - edf.x_i, bins='auto')\n",
    "plt.xlim((-200, 200))\n",
    "plt.show()"
   ],
   "id": "3e4e9608bebafb64",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:15.977513Z",
     "start_time": "2025-01-07T19:17:15.975249Z"
    }
   },
   "cell_type": "code",
   "source": "300 / SIPM_CELL_SIZE",
   "id": "658d05134ff5db8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.28571428571429"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:17.059839Z",
     "start_time": "2025-01-07T19:17:16.283481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.hist(edf.y_c - edf.y_i, bins='auto')\n",
    "plt.xlim((-200, 200))\n",
    "plt.show()"
   ],
   "id": "2e1adc35814ce9b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkYAAAGfCAYAAAC6BB0WAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtmklEQVR4nO3de3RTZb7G8aelJJRLU25NqRaoolwUREBrva3l0EPRnhlRZka0R9FhULHFwaJYjgKKl9aiiKCCeo7gWaMirDWgUkV7ioBCKNixyrWjDghe0jpiE0Aol77nD3f3IVCghfSS9PtZK2u1e/+y875puvPk3fvdiTDGGAEAAECRTd0AAACA5oJgBAAAYCEYAQAAWAhGAAAAFoIRAACAhWAEAABgIRgBAABYCEYAAAAWghEAAICFYAQAAGCJqu8dVq9erRkzZqikpEQ//PCDlixZohEjRtjrjTGaNm2aXnnlFVVWVuqKK67Q3Llzdd5559k1u3fv1vjx4/Xuu+8qMjJSI0eO1HPPPaf27dvbNV988YUyMzO1YcMGde3aVePHj9ekSZMC2rJ48WJNmTJFO3bs0HnnnaennnpK1113XZ37Ul1dre+//14dOnRQREREfZ8KAADQBIwx2rNnjxISEhQZGeQxHlNP7733nnnooYfM3/72NyPJLFmyJGB9Xl6ecblcZunSpebzzz83v/vd70xSUpLZv3+/XTN8+HBz0UUXmXXr1pmPP/7Y9OrVy9x88832ep/PZ9xut8nIyDCbNm0yb775pomOjjYvvfSSXbNmzRrTqlUrk5+fb7Zs2WIefvhh07p1a7Nx48Y692XXrl1GEjdu3Lhx48YtBG+7du2qb4w5pQhjTv9LZCMiIgJGjIwxSkhI0MSJE3X//fdLknw+n9xutxYsWKBRo0Zp69at6tevnzZs2KAhQ4ZIkpYvX67rrrtO3377rRISEjR37lw99NBD8nq9cjgckqScnBwtXbpU27ZtkyTddNNN2rdvn5YtW2a357LLLtPAgQM1b968OrXf5/MpNjZWu3btUkxMzOk+DQAAoBH5/X4lJiaqsrJSLpcrqNuu96G0k9m+fbu8Xq9SU1PtZS6XS8nJyfJ4PBo1apQ8Ho9iY2PtUCRJqampioyMVHFxsW644QZ5PB5dffXVdiiSpLS0ND311FP6+eef1bFjR3k8HmVnZwc8flpampYuXXrC9lVVVamqqsr+fc+ePZKkmJgYghEAACGmIU6DCeqBOa/XK0lyu90By91ut73O6/UqLi4uYH1UVJQ6deoUUFPbNo5+jBPV1KyvTW5urlwul31LTEysbxcBAEAYa1Gz0iZPniyfz2ffdu3a1dRNAgAAzUhQg1F8fLwkqby8PGB5eXm5vS4+Pl4VFRUB6w8fPqzdu3cH1NS2jaMf40Q1Netr43Q67cNmHD4DAADHCmowSkpKUnx8vIqKiuxlfr9fxcXFSklJkSSlpKSosrJSJSUlds2KFStUXV2t5ORku2b16tU6dOiQXVNYWKjevXurY8eOds3Rj1NTU/M4AAAA9VXvYLR3716VlpaqtLRU0q8nXJeWlmrnzp2KiIjQhAkT9Pjjj+udd97Rxo0bddtttykhIcGeuda3b18NHz5cY8eO1fr167VmzRplZWVp1KhRSkhIkCTdcsstcjgcGjNmjDZv3qy33npLzz33XMDJ1n/5y1+0fPlyPfPMM9q2bZseeeQRffrpp8rKyjrzZwUAALRM9Z3f/9FHH9V6LYHRo0cbY4yprq42U6ZMMW632zidTjN06FBTVlYWsI2ffvrJ3HzzzaZ9+/YmJibG3HHHHWbPnj0BNZ9//rm58sorjdPpNGeddZbJy8s7ri2LFi0y559/vnE4HOaCCy4wBQUF9eqLz+czkozP56vfkwAAAJpMQ75/n9F1jEKd3++Xy+WSz+fjfCMAAEJEQ75/t6hZaQAAACdDMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsBCMAAAALAQjAJKknjkF6plT0NTNAIAmRTACcEKEpcbF8w00PYIRAACAhWAEAABgIRgBAABYopq6AQCAujn6/KMdeelN2BIgfDFiBLRQnOgLAMcjGAEAAFgIRgDQRBi1A5ofghEAAICFYAQAzRQjSkDjY1YaADRzhCOg8TBiBKDOGMFoPvhbAA2DYAS0ELyRAsCpEYwAAAAsBCMAAAALJ18DQDPDIU+g6TBiBAAAYGHECGjhGJ0AgP/HiBEAAICFESOghWGEqGnUPO878tJDYrtAS0UwAhCA4ASgJeNQGgAAgIURIwCndKJRJA7jAAg3jBgBAABYCEYAAAAWghEAAICFYAQAYaBnTgEzCoEgIBgBCCreoAGEMmalAUATI0gCzQcjRgAAABaCEQAAgIVgBAAAYCEYAQAAWAhGAAAAFmalAag3ZlEBCFeMGAEAAFgIRgAAABaCEQAAgIVzjIAwx/lALUvN33tHXnoTtwQITYwYAQAAWBgxAnDGGJUCEC4YMQKABtAzp4DACIQgRowAoBERloDmjREjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALwQgAAMBCMAIAALBwHSMgDDWna+Xw3V0AQgkjRgAAABaCEQAAgIVgBAAAYAl6MDpy5IimTJmipKQkRUdH69xzz9Vjjz0mY4xdY4zR1KlT1a1bN0VHRys1NVVffvllwHZ2796tjIwMxcTEKDY2VmPGjNHevXsDar744gtdddVVatOmjRITE5Wfnx/s7gAAgBYk6MHoqaee0ty5c/X8889r69ateuqpp5Sfn685c+bYNfn5+Zo9e7bmzZun4uJitWvXTmlpaTpw4IBdk5GRoc2bN6uwsFDLli3T6tWrdeedd9rr/X6/hg0bph49eqikpEQzZszQI488opdffjnYXQIAAC1E0GelrV27Vtdff73S03+dgdKzZ0+9+eabWr9+vaRfR4tmzZqlhx9+WNdff70k6X/+53/kdru1dOlSjRo1Slu3btXy5cu1YcMGDRkyRJI0Z84cXXfddXr66aeVkJCg119/XQcPHtSrr74qh8OhCy64QKWlpZo5c2ZAgAKAptScZggCOLWgjxhdfvnlKioq0j/+8Q9J0ueff65PPvlE1157rSRp+/bt8nq9Sk1Nte/jcrmUnJwsj8cjSfJ4PIqNjbVDkSSlpqYqMjJSxcXFds3VV18th8Nh16SlpamsrEw///xzrW2rqqqS3+8PuAEAANQI+ohRTk6O/H6/+vTpo1atWunIkSN64oknlJGRIUnyer2SJLfbHXA/t9ttr/N6vYqLiwtsaFSUOnXqFFCTlJR03DZq1nXs2PG4tuXm5urRRx8NQi8BIBDXawLCQ9BHjBYtWqTXX39db7zxhv7+97/rtdde09NPP63XXnst2A9Vb5MnT5bP57Nvu3btauomAQCAZiToI0YPPPCAcnJyNGrUKElS//799c033yg3N1ejR49WfHy8JKm8vFzdunWz71deXq6BAwdKkuLj41VRURGw3cOHD2v37t32/ePj41VeXh5QU/N7Tc2xnE6nnE7nmXcSAACEpaCPGP3yyy+KjAzcbKtWrVRdXS1JSkpKUnx8vIqKiuz1fr9fxcXFSklJkSSlpKSosrJSJSUlds2KFStUXV2t5ORku2b16tU6dOiQXVNYWKjevXvXehgNAADgVIIejH7729/qiSeeUEFBgXbs2KElS5Zo5syZuuGGGyRJERERmjBhgh5//HG988472rhxo2677TYlJCRoxIgRkqS+fftq+PDhGjt2rNavX681a9YoKytLo0aNUkJCgiTplltukcPh0JgxY7R582a99dZbeu6555SdnR3sLgEAgBYi6IfS5syZoylTpuiee+5RRUWFEhISdNddd2nq1Kl2zaRJk7Rv3z7deeedqqys1JVXXqnly5erTZs2ds3rr7+urKwsDR06VJGRkRo5cqRmz55tr3e5XPrwww+VmZmpwYMHq0uXLpo6dSpT9QEAwGkLejDq0KGDZs2apVmzZp2wJiIiQtOnT9f06dNPWNOpUye98cYbJ32sAQMG6OOPPz7dpgIAAATgu9IAIAz1zCng4pLAaSAYAQAAWAhGAAAAFoIRgEbFIR4AzRnBCAAAwBL0WWkAEO6OHvHiu9GA8EIwAtAgOFwGIBQRjAAgiAiEQGjjHCMAAAALwQgAAMBCMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsHAdIwA4A1y3CAgvjBgBwCnwxbdAy0EwAgAAsBCMAAAALJxjBKBRcCgKQChgxAgAAMBCMAIAALAQjAAAACwEIwAAAAsnXwNhJJROcK5p64689CZuCQD8P0aMAAAALAQjAAAAC4fSADSpow//NZfDahzmA1ouRowAAAAsBCMAAAALwQhAs9EQ32LfENsEEL4IRgAAABaCEQAAgIVgBKDZ4fAXgKZCMALQohC6AJwM1zEC0OLV9bpFBCog/DFiBAAAYCEYAWi2OOwFoLERjAAAACycYwQAJ8BoFdDyMGIEIKxw+A3AmSAYAWj2CDsAGgvBCAAAwEIwAhAyGDkC0NAIRgAAABZmpQEIWUePHp3qqtUAUBeMGAEAAFgIRgAQxjgvC6gfghEAAICFc4wAwMLICgCCEYCQQ4AB0FA4lAYAAGBhxAhAWGJUCcDpIBgBCAv1DUIEJwC14VAaAACAhREjIAww+gEAwcGIEQAAgIVgBAAAYOFQGoAWgcONAOqCESMAAAALwQgAAMBCMAIAALAQjAAAACwNEoy+++47/cd//Ic6d+6s6Oho9e/fX59++qm93hijqVOnqlu3boqOjlZqaqq+/PLLgG3s3r1bGRkZiomJUWxsrMaMGaO9e/cG1HzxxRe66qqr1KZNGyUmJio/P78hugMAAFqIoAejn3/+WVdccYVat26t999/X1u2bNEzzzyjjh072jX5+fmaPXu25s2bp+LiYrVr105paWk6cOCAXZORkaHNmzersLBQy5Yt0+rVq3XnnXfa6/1+v4YNG6YePXqopKREM2bM0COPPKKXX3452F0CAAAtRIQxxgRzgzk5OVqzZo0+/vjjWtcbY5SQkKCJEyfq/vvvlyT5fD653W4tWLBAo0aN0tatW9WvXz9t2LBBQ4YMkSQtX75c1113nb799lslJCRo7ty5euihh+T1euVwOOzHXrp0qbZt21brY1dVVamqqsr+3e/3KzExUT6fTzExMcF8GoBGxVR0nMqOvPSmbgIQNH6/Xy6Xq0Hev4M+YvTOO+9oyJAh+sMf/qC4uDhdfPHFeuWVV+z127dvl9frVWpqqr3M5XIpOTlZHo9HkuTxeBQbG2uHIklKTU1VZGSkiouL7Zqrr77aDkWSlJaWprKyMv3888+1ti03N1cul8u+JSYmBrXvAAAgtAU9GP3zn//U3Llzdd555+mDDz7QuHHjdO+99+q1116TJHm9XkmS2+0OuJ/b7bbXeb1excXFBayPiopSp06dAmpq28bRj3GsyZMny+fz2bddu3adYW8BAEA4CfqVr6urqzVkyBA9+eSTkqSLL75YmzZt0rx58zR69OhgP1y9OJ1OOZ3OJm0DAABovoI+YtStWzf169cvYFnfvn21c+dOSVJ8fLwkqby8PKCmvLzcXhcfH6+KioqA9YcPH9bu3bsDamrbxtGPAQAAUB9BD0ZXXHGFysrKApb94x//UI8ePSRJSUlJio+PV1FRkb3e7/eruLhYKSkpkqSUlBRVVlaqpKTErlmxYoWqq6uVnJxs16xevVqHDh2yawoLC9W7d++AGXAAAAB1FfRgdN9992ndunV68skn9dVXX+mNN97Qyy+/rMzMTElSRESEJkyYoMcff1zvvPOONm7cqNtuu00JCQkaMWKEpF9HmIYPH66xY8dq/fr1WrNmjbKysjRq1CglJCRIkm655RY5HA6NGTNGmzdv1ltvvaXnnntO2dnZwe4SAABoIYJ+jtEll1yiJUuWaPLkyZo+fbqSkpI0a9YsZWRk2DWTJk3Svn37dOedd6qyslJXXnmlli9frjZt2tg1r7/+urKysjR06FBFRkZq5MiRmj17tr3e5XLpww8/VGZmpgYPHqwuXbpo6tSpAdc6AgAAqI+gX8colDTkdRCAxsR1jFAfXNMIoS6krmMEAAAQqghGAAAAFoIRAACAhWAEAABgIRgBAABYCEYAAAAWghEAAICFYAQAAGAhGAEAAFgIRgAAABaCEQAAgIVgBAAAYCEYAQAAWAhGAAAAFoIRAACAhWAEAABgiWrqBgA4fT1zCpq6CQAQVhgxAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAAALwQgAAMBCMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsBCMAKCF6ZlToJ45BU3dDKBZIhgBAABYCEYAAAAWghEAAICFYAQAAGCJauoGAKg/TpwFgIbBiBEAAICFYAQAAGAhGAEAAFgIRgAAABaCEQAAgIVgBAAAYCEYAQAAWAhGAAAAFoIRAACAhWAEAABgIRgBAABYCEYA0EL1zCnge/eAYxCMAAAALAQjAAAAC8EIAADAQjACAACwEIwAAAAsBCMAAABLVFM3AEDdMbUaABoWI0YAAAAWghEAAICFYAQAAGAhGAEAAFgIRgAAABaCEQAAgIVgBAAAYGnwYJSXl6eIiAhNmDDBXnbgwAFlZmaqc+fOat++vUaOHKny8vKA++3cuVPp6elq27at4uLi9MADD+jw4cMBNStXrtSgQYPkdDrVq1cvLViwoKG7AwAAwliDBqMNGzbopZde0oABAwKW33fffXr33Xe1ePFirVq1St9//71uvPFGe/2RI0eUnp6ugwcPau3atXrttde0YMECTZ061a7Zvn270tPTdc0116i0tFQTJkzQn//8Z33wwQcN2SUACDs9cwq4eChgabBgtHfvXmVkZOiVV15Rx44d7eU+n0///d//rZkzZ+o3v/mNBg8erPnz52vt2rVat26dJOnDDz/Uli1b9Ne//lUDBw7Utddeq8cee0wvvPCCDh48KEmaN2+ekpKS9Mwzz6hv377KysrS73//ez377LMN1SUAABDmGiwYZWZmKj09XampqQHLS0pKdOjQoYDlffr0Uffu3eXxeCRJHo9H/fv3l9vttmvS0tLk9/u1efNmu+bYbaelpdnbqE1VVZX8fn/ADQAAoEaDfFfawoUL9fe//10bNmw4bp3X65XD4VBsbGzAcrfbLa/Xa9ccHYpq1tesO1mN3+/X/v37FR0dfdxj5+bm6tFHHz3tfgEAgPAW9GC0a9cu/eUvf1FhYaHatGkT7M2fkcmTJys7O9v+3e/3KzExsQlbBNQN538AQOMI+qG0kpISVVRUaNCgQYqKilJUVJRWrVql2bNnKyoqSm63WwcPHlRlZWXA/crLyxUfHy9Jio+PP26WWs3vp6qJiYmpdbRIkpxOp2JiYgJuAAAANYIejIYOHaqNGzeqtLTUvg0ZMkQZGRn2z61bt1ZRUZF9n7KyMu3cuVMpKSmSpJSUFG3cuFEVFRV2TWFhoWJiYtSvXz+75uht1NTUbAMAAKC+gn4orUOHDrrwwgsDlrVr106dO3e2l48ZM0bZ2dnq1KmTYmJiNH78eKWkpOiyyy6TJA0bNkz9+vXTrbfeqvz8fHm9Xj388MPKzMyU0+mUJN199916/vnnNWnSJP3pT3/SihUrtGjRIhUUcMgBAACcngY5+fpUnn32WUVGRmrkyJGqqqpSWlqaXnzxRXt9q1attGzZMo0bN04pKSlq166dRo8erenTp9s1SUlJKigo0H333afnnntOZ599tv7rv/5LaWlpTdElAAAQBiKMMaapG9FU/H6/XC6XfD4f5xuhWePkazSGHXnpTd0EoE4a8v2b70oDAACwEIwAAJL4ahBAIhgBAADYCEYAAAAWghEAAICFYAQAAGAhGAEAAFgIRgAAABaCEQAAgIVgBAAAYCEYAQAAWAhGAAAAlqimbgCA2vHVDADQ+BgxAgAAsBCMAAAALAQjAAAAC8EIAADAQjACAATomVPAyf9osQhGAAAAFoIRAACAhesYAc0MhzAAoOkwYgQAAGAhGAEAAFgIRgAAABaCEQCgVkzbR0tEMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsBCMAAAALHwlCNBMMC0aAJoeI0YAAAAWghEAAICFYAQAAGDhHCMAwEkdff7bjrz0JmwJ0PAYMQIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsDArDWhiXPEaAJoPRowAAAAsBCMAAAALwQgAAMBCMAIAALAQjAAAACwEIwAAAAvBCABQZz1zCrjEBMIawQgAAMBCMAIAALAQjAAAACwEIwBAvXGuEcIVwQgAAMDCl8gCTYRP2wDQ/DBiBAAAYCEYAQAAWAhGAAAAFoIRAACAhWAEAABgIRgBAE4b1zNCuCEYAQAAWIIejHJzc3XJJZeoQ4cOiouL04gRI1RWVhZQc+DAAWVmZqpz585q3769Ro4cqfLy8oCanTt3Kj09XW3btlVcXJweeOABHT58OKBm5cqVGjRokJxOp3r16qUFCxYEuzsAAKAFCXowWrVqlTIzM7Vu3ToVFhbq0KFDGjZsmPbt22fX3HfffXr33Xe1ePFirVq1St9//71uvPFGe/2RI0eUnp6ugwcPau3atXrttde0YMECTZ061a7Zvn270tPTdc0116i0tFQTJkzQn//8Z33wwQfB7hIAAGghIowxpiEf4Mcff1RcXJxWrVqlq6++Wj6fT127dtUbb7yh3//+95Kkbdu2qW/fvvJ4PLrsssv0/vvv69///d/1/fffy+12S5LmzZunBx98UD/++KMcDocefPBBFRQUaNOmTfZjjRo1SpWVlVq+fHmd2ub3++VyueTz+RQTExP8zgO14HwMhKMdeelN3QS0IA35/t3g5xj5fD5JUqdOnSRJJSUlOnTokFJTU+2aPn36qHv37vJ4PJIkj8ej/v3726FIktLS0uT3+7V582a75uht1NTUbKM2VVVV8vv9ATcAAIAaDRqMqqurNWHCBF1xxRW68MILJUler1cOh0OxsbEBtW63W16v1645OhTVrK9Zd7Iav9+v/fv319qe3NxcuVwu+5aYmHjGfQQAAOGjQYNRZmamNm3apIULFzbkw9TZ5MmT5fP57NuuXbuaukkAAKAZiWqoDWdlZWnZsmVavXq1zj77bHt5fHy8Dh48qMrKyoBRo/LycsXHx9s169evD9hezay1o2uOnclWXl6umJgYRUdH19omp9Mpp9N5xn0DAADhKegjRsYYZWVlacmSJVqxYoWSkpIC1g8ePFitW7dWUVGRvaysrEw7d+5USkqKJCklJUUbN25URUWFXVNYWKiYmBj169fPrjl6GzU1NdsAAACor6CPGGVmZuqNN97Q22+/rQ4dOtjnBLlcLkVHR8vlcmnMmDHKzs5Wp06dFBMTo/HjxyslJUWXXXaZJGnYsGHq16+fbr31VuXn58vr9erhhx9WZmamPeJz99136/nnn9ekSZP0pz/9SStWrNCiRYtUUMCMHzRPzEYDgOYv6NP1IyIial0+f/583X777ZJ+vcDjxIkT9eabb6qqqkppaWl68cUX7cNkkvTNN99o3LhxWrlypdq1a6fRo0crLy9PUVH/n+VWrlyp++67T1u2bNHZZ5+tKVOm2I9RF0zXR2MiGKElYNo+GkNDvn83+HWMmjOCERoTwQgtAcEIjSGkr2MEAAAQKghGAICg6ZlTwOgoQlqDTdcHwOEzAAg1jBgBAABYCEYAAAAWghEAAICFYAQAAGAhGAEAAFiYlQY0AGajAUBoYsQIABB0XM8IoYoRIyCIeCMAgNDGiBEAAICFESMAQIM5ehSVL5hFKGDECAAAwEIwAgAAsBCMAAAALAQjAECjYAo/QgEnXwNBwM4eAMIDI0YAgEbFyBGaM4IRAACAhWAEnAY+8QLBw/8TmhPOMQLOADtzAAgvBCMAQJPggwWaIw6lAQCaldoOrXG4DY2FYAQAAGDhUBpwCnwJJgC0HAQj4Bg1Qai2EMRQPtA8nOz/FDgTBCMAQLPABw80B5xjBAAAYCEYAQBCHrPWECwcSgNOgJ0sALQ8BCO0OMeetMlJnEDzxIcTNAWCEWBhJwwA4BwjAAAAC8EIAADAwqE0AEDY4Yr1OF0EI4Q1rmINhJcz+b9logXqgmAEAAhZfMBBsBGM0CKw8wRaBv7XcaY4+RoAAMDCiBHCEp8aAQCng2CEkEYAAgAEE8EIABDWTvQB6kRfD3T0MrQ8BCOEDEaHAAANjZOv0Wz1zCkgDAEAGhUjRmh2CEMAGlJ99jFcFLLliTDGmKZuRFPx+/1yuVzy+XyKiYlp6ua0eAQiAM0Vwah5acj3b0aM0KhqO7mRQAQgVDCCFP4IRmgyBCIAoYL9VcvByddoUJxADSCcsY8LP4wYIShOdj2Q2n4HgHDF4bbQRjBCUBGAALQEfPgLXwQj1Bs7AAA4tWP3lYwghQaCEeqMQAQAZ45Dbc0b1zHiOkanRCACgMZBWKobrmOERnGqE6gBAA2L0aSmx4hRmI8YnSjsHP1PRwACgObp2IBEcPoVI0aot1OFHcIQAADHIxiFsNrCzYk+RRCEACD01OdD7omODDDKVD8EoxBSlxc3AQgAwt+Z7OsJSidHMGrGTvTCJ/wAAI4VzLDUksMTwaiBnOpFxgwwAEBDCub7SksKSsxKC8JZ7Seb6UXwAQCEi9re05pilKkhZ6WFfDB64YUXNGPGDHm9Xl100UWaM2eOLr300jrdt65PLCEHAIDgONkgQl0RjE7grbfe0m233aZ58+YpOTlZs2bN0uLFi1VWVqa4uLhT3v/oJ3bAkx83QosBAMCZqq76Rbtm/ZFgdKzk5GRdcsklev755yVJ1dXVSkxM1Pjx45WTk3NcfVVVlaqqquzffT6funfvrrPGLVCks22jtRsAAJy+6qpf9N3c21VZWSmXyxXUbYfsydcHDx5USUmJJk+ebC+LjIxUamqqPB5PrffJzc3Vo48+etzy7+be3lDNBAAADeSnn34iGNX417/+pSNHjsjtdgcsd7vd2rZtW633mTx5srKzs+3fKysr1aNHD+3cuTPoT2xz5vf7lZiYqF27doXtV6HUhn7T75aAftPvlqDmiE+nTp2Cvu2QDUanw+l0yul0Hrfc5XK1qBdUjZiYGPrdgtDvloV+tywttd+RkZHB32bQt9hIunTpolatWqm8vDxgeXl5ueLj45uoVQAAIJSFbDByOBwaPHiwioqK7GXV1dUqKipSSkpKE7YMAACEqpA+lJadna3Ro0dryJAhuvTSSzVr1izt27dPd9xxR53u73Q6NW3atFoPr4Uz+k2/WwL6Tb9bAvod/H6H9HR9SXr++eftCzwOHDhQs2fPVnJyclM3CwAAhKCQD0YAAADBErLnGAEAAAQbwQgAAMBCMAIAALAQjAAAACxhH4x27NihMWPGKCkpSdHR0Tr33HM1bdo0HTx4MKDuiy++0FVXXaU2bdooMTFR+fn5x21r8eLF6tOnj9q0aaP+/fvrvffea6xunJYnnnhCl19+udq2bavY2NhaayIiIo67LVy4MKBm5cqVGjRokJxOp3r16qUFCxY0fOPPQF36vXPnTqWnp6tt27aKi4vTAw88oMOHDwfUhFq/a9OzZ8/j/r55eXkBNXV57YeaF154QT179lSbNm2UnJys9evXN3WTguqRRx457u/ap08fe/2BAweUmZmpzp07q3379ho5cuRxF8MNBatXr9Zvf/tbJSQkKCIiQkuXLg1Yb4zR1KlT1a1bN0VHRys1NVVffvllQM3u3buVkZGhmJgYxcbGasyYMdq7d28j9qL+TtXv22+//bi///DhwwNqQq3fubm5uuSSS9ShQwfFxcVpxIgRKisrC6ipy+u6Lvv2UzJh7v333ze33367+eCDD8zXX39t3n77bRMXF2cmTpxo1/h8PuN2u01GRobZtGmTefPNN010dLR56aWX7Jo1a9aYVq1amfz8fLNlyxbz8MMPm9atW5uNGzc2RbfqZOrUqWbmzJkmOzvbuFyuWmskmfnz55sffvjBvu3fv99e/89//tO0bdvWZGdnmy1btpg5c+aYVq1ameXLlzdSL+rvVP0+fPiwufDCC01qaqr57LPPzHvvvWe6dOliJk+ebNeEYr9r06NHDzN9+vSAv+/evXvt9XV57YeahQsXGofDYV599VWzefNmM3bsWBMbG2vKy8ubumlBM23aNHPBBRcE/F1//PFHe/3dd99tEhMTTVFRkfn000/NZZddZi6//PImbPHpee+998xDDz1k/va3vxlJZsmSJQHr8/LyjMvlMkuXLjWff/65+d3vfmeSkpIC9mHDhw83F110kVm3bp35+OOPTa9evczNN9/cyD2pn1P1e/To0Wb48OEBf//du3cH1IRav9PS0sz8+fPNpk2bTGlpqbnuuutM9+7dA/ZXp3pd12XfXhdhH4xqk5+fb5KSkuzfX3zxRdOxY0dTVVVlL3vwwQdN79697d//+Mc/mvT09IDtJCcnm7vuuqvhG3yG5s+ff9JgdOw/3dEmTZpkLrjggoBlN910k0lLSwtiCxvGifr93nvvmcjISOP1eu1lc+fONTExMfZrIJT7fbQePXqYZ5999oTr6/LaDzWXXnqpyczMtH8/cuSISUhIMLm5uU3YquCaNm2aueiii2pdV1lZaVq3bm0WL15sL9u6dauRZDweTyO1MPiO3VdVV1eb+Ph4M2PGDHtZZWWlcTqd5s033zTGGLNlyxYjyWzYsMGuef/9901ERIT57rvvGq3tZ+JEwej6668/4X3Cod8VFRVGklm1apUxpm6v67rs2+si7A+l1cbn8wV8I6/H49HVV18th8NhL0tLS1NZWZl+/vlnuyY1NTVgO2lpafJ4PI3T6AaUmZmpLl266NJLL9Wrr74qc9SlrcKx3x6PR/3795fb7baXpaWlye/3a/PmzXZNuPQ7Ly9PnTt31sUXX6wZM2YEDCvX5bUfSg4ePKiSkpKAv11kZKRSU1ND8m93Ml9++aUSEhJ0zjnnKCMjQzt37pQklZSU6NChQwHPQZ8+fdS9e/eweg62b98ur9cb0E+Xy6Xk5GS7nx6PR7GxsRoyZIhdk5qaqsjISBUXFzd6m4Np5cqViouLU+/evTVu3Dj99NNP9rpw6LfP55Mk+726Lq/ruuzb6yKkvxLkdHz11VeaM2eOnn76aXuZ1+tVUlJSQF3NE+v1etWxY0d5vd6AJ7umxuv1NnyjG9D06dP1m9/8Rm3bttWHH36oe+65R3v37tW9994rSSfst9/v1/79+xUdHd0UzT4jJ+pTzbqT1YRav++9914NGjRInTp10tq1azV58mT98MMPmjlzpqS6vfZDyb/+9S8dOXKk1r/dtm3bmqhVwZecnKwFCxaod+/e+uGHH/Too4/qqquu0qZNm+T1euVwOI47vy4c9ldHq+nLyfbLXq9XcXFxAeujoqLUqVOnkH4uhg8frhtvvFFJSUn6+uuv9Z//+Z+69tpr5fF41KpVq5Dvd3V1tSZMmKArrrhCF154oSTV6XVdl317XYRsMMrJydFTTz110pqtW7cGnJD43Xffafjw4frDH/6gsWPHNnQTG8Tp9PtkpkyZYv988cUXa9++fZoxY4YdjJqLYPc7lNXnucjOzraXDRgwQA6HQ3fddZdyc3Nb3HcrhZNrr73W/nnAgAFKTk5Wjx49tGjRopAJ7Th9o0aNsn/u37+/BgwYoHPPPVcrV67U0KFDm7BlwZGZmalNmzbpk08+aZLHD9lgNHHiRN1+++0nrTnnnHPsn7///ntdc801uvzyy/Xyyy8H1MXHxx93ZnvN7/Hx8SetqVnfWOrb7/pKTk7WY489pqqqKjmdzhP2OyYmplF3wMHsd3x8/HGzlOr6927sftfmTJ6L5ORkHT58WDt27FDv3r3r9NoPJV26dFGrVq2axf9qY4qNjdX555+vr776Sv/2b/+mgwcPqrKyMuDTdbg9BzV9KS8vV7du3ezl5eXlGjhwoF1TUVERcL/Dhw9r9+7dYfVcnHPOOerSpYu++uorDR06NKT7nZWVpWXLlmn16tU6++yz7eXx8fGnfF3XZd9eFyEbjLp27aquXbvWqfa7777TNddco8GDB2v+/PmKjAw8tSolJUUPPfSQDh06pNatW0uSCgsL1bt3b/tQQkpKioqKijRhwgT7foWFhUpJSQlOh+qoPv0+HaWlperYsaM9mpCSknLcZQlCvd8pKSl64oknVFFRYQ83FxYWKiYmRv369bNrmkO/a3Mmz0VpaakiIyPtftfltR9KHA6HBg8erKKiIo0YMULSr8PyRUVFysrKatrGNaC9e/fq66+/1q233qrBgwerdevWKioq0siRIyVJZWVl2rlzZ7N4/QZLUlKS4uPjVVRUZAchv9+v4uJijRs3TtKvr+/KykqVlJRo8ODBkqQVK1aouro6rL5s/Ntvv9VPP/1kB8RQ7LcxRuPHj9eSJUu0cuXK4w7x1+V1XZd9e10bE9a+/fZb06tXLzN06FDz7bffBkxvrFFZWWncbre59dZbzaZNm8zChQtN27Ztj5uuHxUVZZ5++mmzdetWM23atGY/Xf+bb74xn332mXn00UdN+/btzWeffWY+++wzs2fPHmOMMe+884555ZVXzMaNG82XX35pXnzxRdO2bVszdepUexs109YfeOABs3XrVvPCCy80+2nrp+p3zZTOYcOGmdLSUrN8+XLTtWvXWqfrh1K/j7V27Vrz7LPPmtLSUvP111+bv/71r6Zr167mtttus2vq8toPNQsXLjROp9MsWLDAbNmyxdx5550mNjY2YKZKqJs4caJZuXKl2b59u1mzZo1JTU01Xbp0MRUVFcaYX6c1d+/e3axYscJ8+umnJiUlxaSkpDRxq+tvz5499v+vJDNz5kzz2WefmW+++cYY8+t0/djYWPP222+bL774wlx//fW1Tte/+OKLTXFxsfnkk0/Meeed16ynrRtz8n7v2bPH3H///cbj8Zjt27eb//3f/zWDBg0y5513njlw4IC9jVDr97hx44zL5TIrV64MeJ/+5Zdf7JpTva7rsm+vi7APRvPnzzeSar0d7fPPPzdXXnmlcTqd5qyzzjJ5eXnHbWvRokXm/PPPNw6Hw1xwwQWmoKCgsbpxWkaPHl1rvz/66CNjzK/TNwcOHGjat29v2rVrZy666CIzb948c+TIkYDtfPTRR2bgwIHG4XCYc845x8yfP7/xO1MPp+q3Mcbs2LHDXHvttSY6Otp06dLFTJw40Rw6dChgO6HW72OVlJSY5ORk43K5TJs2bUzfvn3Nk08+GbDzNKZur/1QM2fOHNO9e3fjcDjMpZdeatatW9fUTQqqm266yXTr1s04HA5z1llnmZtuusl89dVX9vr9+/ebe+65x3Ts2NG0bdvW3HDDDQEfBkPFRx99VOv/8ujRo40xv07ZnzJlinG73cbpdJqhQ4easrKygG389NNP5uabbzbt27c3MTEx5o477rA/JDVXJ+v3L7/8YoYNG2a6du1qWrdubXr06GHGjh17XPAPtX6f6H366P1uXV7Xddm3n0qE1SAAAIAWr0VexwgAAKA2BCMAAAALwQgAAMBCMAIAALAQjAAAACwEIwAAAAvBCAAAwEIwAgAAsBCMAAAALAQjAAAAC8EIAADA8n8E9rGSubXxoAAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:17.097911Z",
     "start_time": "2025-01-07T19:17:17.095089Z"
    }
   },
   "cell_type": "code",
   "source": "440 / SIPM_CELL_SIZE",
   "id": "7fefab9a215bd93a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.95238095238096"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:17.894319Z",
     "start_time": "2025-01-07T19:17:17.266502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.hist(edf.t_c, bins='auto')\n",
    "plt.show()"
   ],
   "id": "d1b31964544ef6c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:17.916289Z",
     "start_time": "2025-01-07T19:17:17.906715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "edf['x_s'] = np.array((edf.x_c - edf.x_i) / SIPM_CELL_SIZE, dtype=int)\n",
    "edf['y_s'] = np.array((edf.y_c - edf.y_i) / SIPM_CELL_SIZE, dtype=int)"
   ],
   "id": "36f9fe5499e78c44",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:18.898796Z",
     "start_time": "2025-01-07T19:17:18.888501Z"
    }
   },
   "cell_type": "code",
   "source": "edf",
   "id": "921b3c27c6c96c01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      x_c     y_c       t_c        x_i         y_i     z_c  \\\n",
       "entry subentry                                                               \n",
       "0     0         89.440131  115.36  0.668623  71.239201  102.379707  1000.0   \n",
       "      1         96.160131  112.00  0.617086  71.239201  102.379707  1000.0   \n",
       "      2         79.360131  125.44  0.639925  71.239201  102.379707  1000.0   \n",
       "      3         42.400131  105.28  0.590146  71.239201  102.379707  1000.0   \n",
       "      4         45.760131  101.92  0.573616  71.239201  102.379707  1000.0   \n",
       "...                   ...     ...       ...        ...         ...     ...   \n",
       "21863 44        32.320131  622.72  0.594467  75.151100  664.462287  1000.0   \n",
       "      45        62.560131  605.92  0.570020  75.151100  664.462287  1000.0   \n",
       "      46        12.160131  659.68  0.684080  75.151100  664.462287  1000.0   \n",
       "      47        25.600131  629.44  0.608963  75.151100  664.462287  1000.0   \n",
       "      48        18.880131  736.96  0.842494  75.151100  664.462287  1000.0   \n",
       "\n",
       "                  mass       true_p      beta  x_p  y_p  z_p      nx_p  \\\n",
       "entry subentry                                                           \n",
       "0     0         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      1         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      2         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      3         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      4         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "...                ...          ...       ...  ...  ...  ...       ...   \n",
       "21863 44        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      45        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      46        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      47        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      48        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "\n",
       "                    ny_p      nz_p  x_s  y_s  \n",
       "entry subentry                                \n",
       "0     0         0.101593  0.992311    5    3  \n",
       "      1         0.101593  0.992311    7    2  \n",
       "      2         0.101593  0.992311    2    6  \n",
       "      3         0.101593  0.992311   -8    0  \n",
       "      4         0.101593  0.992311   -7    0  \n",
       "...                  ...       ...  ...  ...  \n",
       "21863 44        0.552347  0.831270  -12  -12  \n",
       "      45        0.552347  0.831270   -3  -17  \n",
       "      46        0.552347  0.831270  -18   -1  \n",
       "      47        0.552347  0.831270  -14  -10  \n",
       "      48        0.552347  0.831270  -16   21  \n",
       "\n",
       "[660903 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>x_c</th>\n",
       "      <th>y_c</th>\n",
       "      <th>t_c</th>\n",
       "      <th>x_i</th>\n",
       "      <th>y_i</th>\n",
       "      <th>z_c</th>\n",
       "      <th>mass</th>\n",
       "      <th>true_p</th>\n",
       "      <th>beta</th>\n",
       "      <th>x_p</th>\n",
       "      <th>y_p</th>\n",
       "      <th>z_p</th>\n",
       "      <th>nx_p</th>\n",
       "      <th>ny_p</th>\n",
       "      <th>nz_p</th>\n",
       "      <th>x_s</th>\n",
       "      <th>y_s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <th>subentry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>89.440131</td>\n",
       "      <td>115.36</td>\n",
       "      <td>0.668623</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.160131</td>\n",
       "      <td>112.00</td>\n",
       "      <td>0.617086</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.360131</td>\n",
       "      <td>125.44</td>\n",
       "      <td>0.639925</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.400131</td>\n",
       "      <td>105.28</td>\n",
       "      <td>0.590146</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.760131</td>\n",
       "      <td>101.92</td>\n",
       "      <td>0.573616</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">21863</th>\n",
       "      <th>44</th>\n",
       "      <td>32.320131</td>\n",
       "      <td>622.72</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "      <td>-12</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>62.560131</td>\n",
       "      <td>605.92</td>\n",
       "      <td>0.570020</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "      <td>-3</td>\n",
       "      <td>-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>12.160131</td>\n",
       "      <td>659.68</td>\n",
       "      <td>0.684080</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "      <td>-18</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>25.600131</td>\n",
       "      <td>629.44</td>\n",
       "      <td>0.608963</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "      <td>-14</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>18.880131</td>\n",
       "      <td>736.96</td>\n",
       "      <td>0.842494</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "      <td>-16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660903 rows Ã— 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:19.487665Z",
     "start_time": "2025-01-07T19:17:19.457175Z"
    }
   },
   "cell_type": "code",
   "source": "edf_c = edf[(np.abs(edf.x_s) < 65) & (np.abs(edf.y_s) < 65)]",
   "id": "f91962a57f0b45a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:20.775303Z",
     "start_time": "2025-01-07T19:17:20.766130Z"
    }
   },
   "cell_type": "code",
   "source": "edf_c",
   "id": "c9213e5ad3914bab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      x_c     y_c       t_c        x_i         y_i     z_c  \\\n",
       "entry subentry                                                               \n",
       "0     0         89.440131  115.36  0.668623  71.239201  102.379707  1000.0   \n",
       "      1         96.160131  112.00  0.617086  71.239201  102.379707  1000.0   \n",
       "      2         79.360131  125.44  0.639925  71.239201  102.379707  1000.0   \n",
       "      3         42.400131  105.28  0.590146  71.239201  102.379707  1000.0   \n",
       "      4         45.760131  101.92  0.573616  71.239201  102.379707  1000.0   \n",
       "...                   ...     ...       ...        ...         ...     ...   \n",
       "21863 44        32.320131  622.72  0.594467  75.151100  664.462287  1000.0   \n",
       "      45        62.560131  605.92  0.570020  75.151100  664.462287  1000.0   \n",
       "      46        12.160131  659.68  0.684080  75.151100  664.462287  1000.0   \n",
       "      47        25.600131  629.44  0.608963  75.151100  664.462287  1000.0   \n",
       "      48        18.880131  736.96  0.842494  75.151100  664.462287  1000.0   \n",
       "\n",
       "                  mass       true_p      beta  x_p  y_p  z_p      nx_p  \\\n",
       "entry subentry                                                           \n",
       "0     0         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      1         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      2         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      3         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "      4         139.57   522.711615  0.966152  0.0  0.0  0.0  0.070691   \n",
       "...                ...          ...       ...  ...  ...  ...       ...   \n",
       "21863 44        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      45        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      46        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      47        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "      48        139.57  1615.806533  0.996290  0.0  0.0  0.0  0.062471   \n",
       "\n",
       "                    ny_p      nz_p  x_s  y_s  \n",
       "entry subentry                                \n",
       "0     0         0.101593  0.992311    5    3  \n",
       "      1         0.101593  0.992311    7    2  \n",
       "      2         0.101593  0.992311    2    6  \n",
       "      3         0.101593  0.992311   -8    0  \n",
       "      4         0.101593  0.992311   -7    0  \n",
       "...                  ...       ...  ...  ...  \n",
       "21863 44        0.552347  0.831270  -12  -12  \n",
       "      45        0.552347  0.831270   -3  -17  \n",
       "      46        0.552347  0.831270  -18   -1  \n",
       "      47        0.552347  0.831270  -14  -10  \n",
       "      48        0.552347  0.831270  -16   21  \n",
       "\n",
       "[656074 rows x 17 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>x_c</th>\n",
       "      <th>y_c</th>\n",
       "      <th>t_c</th>\n",
       "      <th>x_i</th>\n",
       "      <th>y_i</th>\n",
       "      <th>z_c</th>\n",
       "      <th>mass</th>\n",
       "      <th>true_p</th>\n",
       "      <th>beta</th>\n",
       "      <th>x_p</th>\n",
       "      <th>y_p</th>\n",
       "      <th>z_p</th>\n",
       "      <th>nx_p</th>\n",
       "      <th>ny_p</th>\n",
       "      <th>nz_p</th>\n",
       "      <th>x_s</th>\n",
       "      <th>y_s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <th>subentry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>89.440131</td>\n",
       "      <td>115.36</td>\n",
       "      <td>0.668623</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.160131</td>\n",
       "      <td>112.00</td>\n",
       "      <td>0.617086</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.360131</td>\n",
       "      <td>125.44</td>\n",
       "      <td>0.639925</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.400131</td>\n",
       "      <td>105.28</td>\n",
       "      <td>0.590146</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.760131</td>\n",
       "      <td>101.92</td>\n",
       "      <td>0.573616</td>\n",
       "      <td>71.239201</td>\n",
       "      <td>102.379707</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>522.711615</td>\n",
       "      <td>0.966152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070691</td>\n",
       "      <td>0.101593</td>\n",
       "      <td>0.992311</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">21863</th>\n",
       "      <th>44</th>\n",
       "      <td>32.320131</td>\n",
       "      <td>622.72</td>\n",
       "      <td>0.594467</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "      <td>-12</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>62.560131</td>\n",
       "      <td>605.92</td>\n",
       "      <td>0.570020</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "      <td>-3</td>\n",
       "      <td>-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>12.160131</td>\n",
       "      <td>659.68</td>\n",
       "      <td>0.684080</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "      <td>-18</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>25.600131</td>\n",
       "      <td>629.44</td>\n",
       "      <td>0.608963</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "      <td>-14</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>18.880131</td>\n",
       "      <td>736.96</td>\n",
       "      <td>0.842494</td>\n",
       "      <td>75.151100</td>\n",
       "      <td>664.462287</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>139.57</td>\n",
       "      <td>1615.806533</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>0.831270</td>\n",
       "      <td>-16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>656074 rows Ã— 17 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:21.472836Z",
     "start_time": "2025-01-07T19:17:21.237429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.hist(edf_c.x_s, bins='auto')\n",
    "plt.show()"
   ],
   "id": "bc443c88ca333980",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:21.961849Z",
     "start_time": "2025-01-07T19:17:21.836541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.hist(edf_c.y_s, bins='auto')\n",
    "plt.show()"
   ],
   "id": "bcdeeecddfe2382b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:54.992502Z",
     "start_time": "2025-01-07T19:17:54.013911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ],
   "id": "aee57334e098e33b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:29:28.152827Z",
     "start_time": "2025-01-07T18:29:28.147403Z"
    }
   },
   "cell_type": "code",
   "source": "edf_c.loc[1, ['x_s', 'y_s']]",
   "id": "16eedbaa9bf936c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          x_s  y_s\n",
       "subentry          \n",
       "0          -3   -5\n",
       "1          -4    2\n",
       "2          -1   -8\n",
       "3          -7    0\n",
       "4           9   -1\n",
       "5          -6   -8\n",
       "6          10   -2\n",
       "7           4    7\n",
       "8          -6    7"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_s</th>\n",
       "      <th>y_s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subentry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:31:25.040172Z",
     "start_time": "2025-01-07T18:31:25.036699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BinaryImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_size=130):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame with columns 'x_s' and 'y_s' representing pixel coordinates.\n",
    "            image_size (int): Size of the binary image (assumes square images).\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.image_ids = dataframe.index.get_level_values(0).unique()  # Assuming each image has a unique first-level index\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        \n",
    "        # Get all pixel coordinates for the current image\n",
    "        pixels = self.dataframe.loc[image_id, ['x_s', 'y_s']].to_numpy()\n",
    "        # print(image_id)\n",
    "        # print(pixels)\n",
    "        if isinstance(pixels, pd.Series):\n",
    "            pixels = pixels.to_frame().T  # Convert to DataFrame and transpose if a single row\n",
    "        # print(pixels)\n",
    "        \n",
    "        # Map coordinates from [-65, +65] to [0, 129]\n",
    "        pixels_mapped = pixels + 65\n",
    "        \n",
    "        # Create a blank binary image\n",
    "        image = np.zeros((self.image_size, self.image_size), dtype=np.float32)\n",
    "        # print(pixels_mapped)\n",
    "        # Set activated pixels to 1\n",
    "        for x, y in pixels_mapped:\n",
    "            image[x, y] = 1.0\n",
    "        \n",
    "        return image"
   ],
   "id": "4edf0e8881e72685",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:31:25.194728Z",
     "start_time": "2025-01-07T18:31:25.181229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = BinaryImageDataset(dataframe=edf_c)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ],
   "id": "4b1665b70cd820c8",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:31:25.348746Z",
     "start_time": "2025-01-07T18:31:25.345351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 130 * 130),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img.view(-1, 1, 130, 130)  # Reshape to image size"
   ],
   "id": "c4dce71d131d6612",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:31:25.651400Z",
     "start_time": "2025-01-07T18:31:25.648430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(130 * 130, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # Output probability of being real\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)  # Flatten image\n",
    "        return self.model(img_flat)\n"
   ],
   "id": "7a7cf9e4b7881423",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:31:26.100040Z",
     "start_time": "2025-01-07T18:31:25.799516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "latent_dim = 100\n",
    "generator = Generator(latent_dim)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "# Optimizers\n",
    "lr = 0.0002\n",
    "beta1, beta2 = 0.5, 0.999\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n"
   ],
   "id": "4fd2f6158d13e347",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:44:28.975190Z",
     "start_time": "2025-01-07T18:31:26.105296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10000\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for real_imgs in dataloader:\n",
    "        real_imgs = real_imgs.to(device)\n",
    "\n",
    "        # Create real and fake labels\n",
    "        real_labels = torch.ones((real_imgs.size(0), 1), device=device)\n",
    "        fake_labels = torch.zeros((real_imgs.size(0), 1), device=device)\n",
    "\n",
    "        # ------------------\n",
    "        # Train Discriminator\n",
    "        # ------------------\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real_labels)\n",
    "\n",
    "        # Fake loss\n",
    "        z = torch.randn(real_imgs.size(0), latent_dim, device=device)\n",
    "        fake_imgs = generator(z)\n",
    "        fake_loss = adversarial_loss(discriminator(fake_imgs.detach()), fake_labels)\n",
    "\n",
    "        # Total loss and backprop\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # ------------------\n",
    "        # Train Generator\n",
    "        # ------------------\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generator loss\n",
    "        g_loss = adversarial_loss(discriminator(fake_imgs), real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]  D Loss: {d_loss.item():.4f}  G Loss: {g_loss.item():.4f}\")\n"
   ],
   "id": "9ee215a7f93d2be3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000]  D Loss: 0.0204  G Loss: 73.2634\n",
      "Epoch [2/10000]  D Loss: 0.0021  G Loss: 71.3813\n",
      "Epoch [3/10000]  D Loss: 0.0008  G Loss: 70.3585\n",
      "Epoch [4/10000]  D Loss: 0.0023  G Loss: 69.4763\n",
      "Epoch [5/10000]  D Loss: 0.0003  G Loss: 68.5102\n",
      "Epoch [6/10000]  D Loss: 0.0000  G Loss: 67.9319\n",
      "Epoch [7/10000]  D Loss: 0.0002  G Loss: 67.2595\n",
      "Epoch [8/10000]  D Loss: 0.0000  G Loss: 66.7424\n",
      "Epoch [9/10000]  D Loss: 0.0001  G Loss: 66.0954\n",
      "Epoch [10/10000]  D Loss: 0.0001  G Loss: 65.7477\n",
      "Epoch [11/10000]  D Loss: 0.0000  G Loss: 65.2573\n",
      "Epoch [12/10000]  D Loss: 0.0000  G Loss: 64.8807\n",
      "Epoch [13/10000]  D Loss: 0.0000  G Loss: 64.5413\n",
      "Epoch [14/10000]  D Loss: 0.0000  G Loss: 63.7488\n",
      "Epoch [15/10000]  D Loss: 0.0000  G Loss: 63.4491\n",
      "Epoch [16/10000]  D Loss: 0.0000  G Loss: 63.2279\n",
      "Epoch [17/10000]  D Loss: 0.0000  G Loss: 62.3913\n",
      "Epoch [18/10000]  D Loss: 0.0000  G Loss: 61.7305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[81], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m64\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m----> 5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mreal_imgs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreal_imgs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mreal_imgs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Create real and fake labels\u001B[39;49;00m\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[76], line 19\u001B[0m, in \u001B[0;36mBinaryImageDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     16\u001B[0m image_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_ids[idx]\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Get all pixel coordinates for the current image\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m pixels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mimage_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mx_s\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43my_s\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# print(image_id)\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# print(pixels)\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pixels, pd\u001B[38;5;241m.\u001B[39mSeries):\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1182\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_scalar_access(key):\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_value(\u001B[38;5;241m*\u001B[39mkey, takeable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_takeable)\n\u001B[1;32m-> 1184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_tuple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1185\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1186\u001B[0m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m     axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1368\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_tuple\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1366\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m suppress(IndexingError):\n\u001B[0;32m   1367\u001B[0m     tup \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_ellipsis(tup)\n\u001B[1;32m-> 1368\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_lowerdim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtup\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1370\u001B[0m \u001B[38;5;66;03m# no multi-index, so validate all of the indexers\u001B[39;00m\n\u001B[0;32m   1371\u001B[0m tup \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_tuple_indexer(tup)\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1041\u001B[0m, in \u001B[0;36m_LocationIndexer._getitem_lowerdim\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;66;03m# we may have a nested tuples indexer here\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_nested_tuple_indexer(tup):\n\u001B[1;32m-> 1041\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_nested_tuple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtup\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;66;03m# we maybe be using a tuple to represent multiple dimensions here\u001B[39;00m\n\u001B[0;32m   1044\u001B[0m ax0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1153\u001B[0m, in \u001B[0;36m_LocationIndexer._getitem_nested_tuple\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1150\u001B[0m     axis \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1151\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m-> 1153\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1154\u001B[0m axis \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1156\u001B[0m \u001B[38;5;66;03m# if we have a scalar, we are done\u001B[39;00m\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1420\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1417\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1418\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index with multidimensional key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_iterable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1422\u001B[0m \u001B[38;5;66;03m# nested tuple slicing\u001B[39;00m\n\u001B[0;32m   1423\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_tuple(key, labels):\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1361\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_iterable\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1359\u001B[0m \u001B[38;5;66;03m# A collection of keys\u001B[39;00m\n\u001B[0;32m   1360\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_listlike_indexer(key, axis)\n\u001B[1;32m-> 1361\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reindex_with_indexers\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1362\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_dups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m   1363\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:5686\u001B[0m, in \u001B[0;36mNDFrame._reindex_with_indexers\u001B[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001B[0m\n\u001B[0;32m   5683\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m ensure_platform_int(indexer)\n\u001B[0;32m   5685\u001B[0m \u001B[38;5;66;03m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001B[39;00m\n\u001B[1;32m-> 5686\u001B[0m new_data \u001B[38;5;241m=\u001B[39m \u001B[43mnew_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreindex_indexer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5687\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5688\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5689\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbaxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5690\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5691\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_dups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_dups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5692\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5693\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5694\u001B[0m \u001B[38;5;66;03m# If we've made a copy once, no need to make another one\u001B[39;00m\n\u001B[0;32m   5695\u001B[0m copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:680\u001B[0m, in \u001B[0;36mBaseBlockManager.reindex_indexer\u001B[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001B[0m\n\u001B[0;32m    677\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequested axis not found in manager\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    679\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 680\u001B[0m     new_blocks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_slice_take_blocks_ax0\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    681\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    682\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    683\u001B[0m \u001B[43m        \u001B[49m\u001B[43monly_slice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43monly_slice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    684\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_na_proxy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_na_proxy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    685\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    686\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    687\u001B[0m     new_blocks \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    688\u001B[0m         blk\u001B[38;5;241m.\u001B[39mtake_nd(\n\u001B[0;32m    689\u001B[0m             indexer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    695\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks\n\u001B[0;32m    696\u001B[0m     ]\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:843\u001B[0m, in \u001B[0;36mBaseBlockManager._slice_take_blocks_ax0\u001B[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001B[0m\n\u001B[0;32m    841\u001B[0m                     blocks\u001B[38;5;241m.\u001B[39mappend(nb)\n\u001B[0;32m    842\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 843\u001B[0m                 nb \u001B[38;5;241m=\u001B[39m \u001B[43mblk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtake_nd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtaker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_mgr_locs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmgr_locs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    844\u001B[0m                 blocks\u001B[38;5;241m.\u001B[39mappend(nb)\n\u001B[0;32m    846\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m blocks\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001B[0m, in \u001B[0;36mBlock.take_nd\u001B[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001B[0m\n\u001B[0;32m   1304\u001B[0m     allow_fill \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001B[39;00m\n\u001B[1;32m-> 1307\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43malgos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtake_nd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1308\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_fill\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_fill\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfill_value\u001B[49m\n\u001B[0;32m   1309\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1311\u001B[0m \u001B[38;5;66;03m# Called from three places in managers, all of which satisfy\u001B[39;00m\n\u001B[0;32m   1312\u001B[0m \u001B[38;5;66;03m#  these assertions\u001B[39;00m\n\u001B[0;32m   1313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ExtensionBlock):\n\u001B[0;32m   1314\u001B[0m     \u001B[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001B[39;00m\n\u001B[0;32m   1315\u001B[0m     \u001B[38;5;66;03m#  algos.take_nd call above.\u001B[39;00m\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001B[0m, in \u001B[0;36mtake_nd\u001B[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001B[0m\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mtake(indexer, fill_value\u001B[38;5;241m=\u001B[39mfill_value, allow_fill\u001B[38;5;241m=\u001B[39mallow_fill)\n\u001B[0;32m    116\u001B[0m arr \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(arr)\n\u001B[1;32m--> 117\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_take_nd_ndarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_fill\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001B[0m, in \u001B[0;36m_take_nd_ndarray\u001B[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001B[0m\n\u001B[0;32m    157\u001B[0m     out \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty(out_shape, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    159\u001B[0m func \u001B[38;5;241m=\u001B[39m _get_take_nd_function(\n\u001B[0;32m    160\u001B[0m     arr\u001B[38;5;241m.\u001B[39mndim, arr\u001B[38;5;241m.\u001B[39mdtype, out\u001B[38;5;241m.\u001B[39mdtype, axis\u001B[38;5;241m=\u001B[39maxis, mask_info\u001B[38;5;241m=\u001B[39mmask_info\n\u001B[0;32m    161\u001B[0m )\n\u001B[1;32m--> 162\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m flip_order:\n\u001B[0;32m    165\u001B[0m     out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mT\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "36124e7313669aad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:59.173976Z",
     "start_time": "2025-01-07T19:17:59.170729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SparseImageDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_ids = dataframe.index.get_level_values(0).unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        pixels = self.dataframe.loc[image_id, ['x_s', 'y_s']].to_numpy()\n",
    "        return torch.tensor(pixels, dtype=torch.float32)"
   ],
   "id": "84b569d386581ed1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:17:59.746144Z",
     "start_time": "2025-01-07T19:17:59.743649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sparse_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to pad variable-length coordinate sets.\n",
    "\n",
    "    Args:\n",
    "        batch (list of Tensors): Each tensor is of shape (num_pixels, 2).\n",
    "    \n",
    "    Returns:\n",
    "        padded_coords (Tensor): Padded coordinate sets of shape (batch_size, max_num_pixels, 2).\n",
    "        lengths (Tensor): Original lengths of each coordinate set.\n",
    "    \"\"\"\n",
    "    lengths = torch.tensor([coords.size(0) for coords in batch])  # Original lengths\n",
    "    max_length = lengths.max().item()  # Maximum length in the batch\n",
    "    \n",
    "    # Create padded tensor of shape (batch_size, max_length, 2)\n",
    "    padded_coords = torch.zeros((len(batch), max_length, 2), dtype=torch.float32)\n",
    "    \n",
    "    for i, coords in enumerate(batch):\n",
    "        padded_coords[i, :lengths[i]] = coords  # Copy coordinates and pad the rest with zeros\n",
    "    \n",
    "    return padded_coords, lengths"
   ],
   "id": "16d6f0ba9f1f42b4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:21:02.963480Z",
     "start_time": "2025-01-07T19:21:02.949620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming 'df' is your dataframe with multi-index and columns ['x_s', 'y_s']\n",
    "dataset = SparseImageDataset(edf_c)\n",
    "\n",
    "# Create DataLoader with custom collate function\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=sparse_collate_fn)\n",
    "\n"
   ],
   "id": "fac755e9153775ad",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:21:03.463631Z",
     "start_time": "2025-01-07T19:21:03.460774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SparseGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_pixels):\n",
    "        super(SparseGenerator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_pixels = num_pixels  # Number of activated pixels to generate\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_pixels * 2)  # Output (x, y) pairs\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        coords = self.fc(z)\n",
    "        coords = coords.view(-1, self.num_pixels, 2)  # Reshape to (batch, num_pixels, 2)\n",
    "        coords = torch.tanh(coords) * 65  # Scale to range [-65, +65]\n",
    "        return coords\n",
    "\n"
   ],
   "id": "b4d170b44d7e98ab",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T19:21:03.827501Z",
     "start_time": "2025-01-07T19:21:03.822856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SparseDiscriminator(nn.Module):\n",
    "    def __init__(self, hidden_dim=256):\n",
    "        super(SparseDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, coords, lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            coords (Tensor): Padded coordinate sets of shape (batch_size, max_num_pixels, 2).\n",
    "            lengths (Tensor): Lengths of each coordinate set.\n",
    "        \"\"\"\n",
    "        batch_size, max_length, _ = coords.size()\n",
    "        flat_coords = coords.view(-1, 2)  # Flatten to (batch_size * max_length, 2)\n",
    "        \n",
    "        # Process all coordinates through the model\n",
    "        validity = self.model(flat_coords).view(batch_size, max_length)\n",
    "        \n",
    "        # Create a mask to ignore padded values\n",
    "        mask = torch.arange(max_length).unsqueeze(0).repeat(batch_size, 1).cuda()\n",
    "        mask = (mask < lengths.unsqueeze(1)).float()  # 1 where valid, 0 where padded\n",
    "        \n",
    "        # Apply mask and average validity over valid pixels\n",
    "        masked_validity = validity * mask\n",
    "        validity_per_image = masked_validity.sum(dim=1) / lengths.float()\n",
    "        \n",
    "        return validity_per_image"
   ],
   "id": "b685c1678a44a4ea",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T20:30:43.676554800Z",
     "start_time": "2025-01-07T19:21:52.193366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 10000\n",
    "latent_dim = 100\n",
    "num_pixels = 150  # Adjust based on your data\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "\n",
    "# Initialize models\n",
    "generator = SparseGenerator(latent_dim, num_pixels).cuda()\n",
    "discriminator = SparseDiscriminator(latent_dim).cuda()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_coords, lengths) in enumerate(dataloader):\n",
    "        real_coords, lengths = real_coords.cuda(), lengths.cuda()\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Real data\n",
    "        real_validity = discriminator(real_coords, lengths)\n",
    "        real_labels = torch.ones((real_coords.size(0), 1)).cuda().squeeze()\n",
    "        d_real_loss = adversarial_loss(real_validity, real_labels)\n",
    "        \n",
    "        # Fake data\n",
    "        z = torch.randn(real_coords.size(0), latent_dim).cuda()\n",
    "        fake_coords = generator(z)\n",
    "        fake_lengths = torch.full((real_coords.size(0),), num_pixels).cuda()  # All fake sets have num_pixels\n",
    "        \n",
    "        fake_validity = discriminator(fake_coords, fake_lengths)\n",
    "        fake_labels = torch.zeros((real_coords.size(0), 1)).cuda().squeeze()\n",
    "        d_fake_loss = adversarial_loss(fake_validity, fake_labels)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward(retain_graph=True)  # Retain the graph for the generator backward pass\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        fake_validity = discriminator(fake_coords, fake_lengths)\n",
    "        g_loss = adversarial_loss(fake_validity, real_labels)\n",
    "        g_loss.backward()  # Now the graph is retained, so we can backpropagate for the generator\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}] Batch {i}, D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")"
   ],
   "id": "9c357f0f42f041a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000] Batch 0, D Loss: 1.832671880722046, G Loss: 1.0402464866638184\n",
      "Epoch [0/10000] Batch 100, D Loss: 1.3399641513824463, G Loss: 0.871056079864502\n",
      "Epoch [0/10000] Batch 200, D Loss: 1.470534324645996, G Loss: 0.6957976222038269\n",
      "Epoch [0/10000] Batch 300, D Loss: 1.6944940090179443, G Loss: 0.45542630553245544\n",
      "Epoch [1/10000] Batch 0, D Loss: 1.500002384185791, G Loss: 0.6354241967201233\n",
      "Epoch [1/10000] Batch 100, D Loss: 1.3783658742904663, G Loss: 0.6553231477737427\n",
      "Epoch [1/10000] Batch 200, D Loss: 1.4435793161392212, G Loss: 0.6689199805259705\n",
      "Epoch [1/10000] Batch 300, D Loss: 1.44451904296875, G Loss: 0.6522355079650879\n",
      "Epoch [2/10000] Batch 0, D Loss: 1.4014755487442017, G Loss: 0.6912693977355957\n",
      "Epoch [2/10000] Batch 100, D Loss: 1.3862881660461426, G Loss: 0.6960849761962891\n",
      "Epoch [2/10000] Batch 200, D Loss: 1.4087927341461182, G Loss: 0.7236218452453613\n",
      "Epoch [2/10000] Batch 300, D Loss: 1.4310028553009033, G Loss: 0.6465438604354858\n",
      "Epoch [3/10000] Batch 0, D Loss: 1.4484760761260986, G Loss: 0.6295483112335205\n",
      "Epoch [3/10000] Batch 100, D Loss: 1.5421268939971924, G Loss: 0.5448243021965027\n",
      "Epoch [3/10000] Batch 200, D Loss: 1.4469010829925537, G Loss: 0.7937884330749512\n",
      "Epoch [3/10000] Batch 300, D Loss: 1.3645973205566406, G Loss: 0.7197250127792358\n",
      "Epoch [4/10000] Batch 0, D Loss: 1.3448700904846191, G Loss: 0.7160360813140869\n",
      "Epoch [4/10000] Batch 100, D Loss: 1.3797223567962646, G Loss: 0.6842184066772461\n",
      "Epoch [4/10000] Batch 200, D Loss: 1.4131217002868652, G Loss: 0.713355541229248\n",
      "Epoch [4/10000] Batch 300, D Loss: 1.3993239402770996, G Loss: 0.7137404680252075\n",
      "Epoch [5/10000] Batch 0, D Loss: 1.395857810974121, G Loss: 0.6941651105880737\n",
      "Epoch [5/10000] Batch 100, D Loss: 1.398054838180542, G Loss: 0.6935235857963562\n",
      "Epoch [5/10000] Batch 200, D Loss: 1.3997375965118408, G Loss: 0.6899089217185974\n",
      "Epoch [5/10000] Batch 300, D Loss: 1.394437551498413, G Loss: 0.6949779391288757\n",
      "Epoch [6/10000] Batch 0, D Loss: 1.3929234743118286, G Loss: 0.7050085067749023\n",
      "Epoch [6/10000] Batch 100, D Loss: 1.389519453048706, G Loss: 0.6986992359161377\n",
      "Epoch [6/10000] Batch 200, D Loss: 1.384730577468872, G Loss: 0.7062773108482361\n",
      "Epoch [6/10000] Batch 300, D Loss: 1.389719009399414, G Loss: 0.6938501596450806\n",
      "Epoch [7/10000] Batch 0, D Loss: 1.3848097324371338, G Loss: 0.7087658643722534\n",
      "Epoch [7/10000] Batch 100, D Loss: 1.3895546197891235, G Loss: 0.6922124624252319\n",
      "Epoch [7/10000] Batch 200, D Loss: 1.3898911476135254, G Loss: 0.7064977884292603\n",
      "Epoch [7/10000] Batch 300, D Loss: 1.3955159187316895, G Loss: 0.6979291439056396\n",
      "Epoch [8/10000] Batch 0, D Loss: 1.3932446241378784, G Loss: 0.695722222328186\n",
      "Epoch [8/10000] Batch 100, D Loss: 1.387563943862915, G Loss: 0.6875097155570984\n",
      "Epoch [8/10000] Batch 200, D Loss: 1.4001986980438232, G Loss: 0.7024418115615845\n",
      "Epoch [8/10000] Batch 300, D Loss: 1.4128168821334839, G Loss: 0.7198317050933838\n",
      "Epoch [9/10000] Batch 0, D Loss: 1.432146668434143, G Loss: 0.6624903678894043\n",
      "Epoch [9/10000] Batch 100, D Loss: 1.427754521369934, G Loss: 0.6879689693450928\n",
      "Epoch [9/10000] Batch 200, D Loss: 1.4085843563079834, G Loss: 0.6718286871910095\n",
      "Epoch [9/10000] Batch 300, D Loss: 1.4169061183929443, G Loss: 0.600843071937561\n",
      "Epoch [10/10000] Batch 0, D Loss: 1.4707353115081787, G Loss: 0.8147917985916138\n",
      "Epoch [10/10000] Batch 100, D Loss: 1.3237323760986328, G Loss: 0.7263673543930054\n",
      "Epoch [10/10000] Batch 200, D Loss: 1.4540719985961914, G Loss: 0.6343262195587158\n",
      "Epoch [10/10000] Batch 300, D Loss: 1.353746771812439, G Loss: 0.7381884455680847\n",
      "Epoch [11/10000] Batch 0, D Loss: 1.3457696437835693, G Loss: 0.7688150405883789\n",
      "Epoch [11/10000] Batch 100, D Loss: 1.3933744430541992, G Loss: 0.6664950847625732\n",
      "Epoch [11/10000] Batch 200, D Loss: 1.3917121887207031, G Loss: 0.7213472127914429\n",
      "Epoch [11/10000] Batch 300, D Loss: 1.3799468278884888, G Loss: 0.698803186416626\n",
      "Epoch [12/10000] Batch 0, D Loss: 1.374997854232788, G Loss: 0.7026528716087341\n",
      "Epoch [12/10000] Batch 100, D Loss: 1.396738052368164, G Loss: 0.6913504004478455\n",
      "Epoch [12/10000] Batch 200, D Loss: 1.3854273557662964, G Loss: 0.6720467209815979\n",
      "Epoch [12/10000] Batch 300, D Loss: 1.3887497186660767, G Loss: 0.6904773116111755\n",
      "Epoch [13/10000] Batch 0, D Loss: 1.3892552852630615, G Loss: 0.7016758918762207\n",
      "Epoch [13/10000] Batch 100, D Loss: 1.388333797454834, G Loss: 0.7015395164489746\n",
      "Epoch [13/10000] Batch 200, D Loss: 1.3862574100494385, G Loss: 0.698127031326294\n",
      "Epoch [13/10000] Batch 300, D Loss: 1.3902504444122314, G Loss: 0.7022645473480225\n",
      "Epoch [14/10000] Batch 0, D Loss: 1.3892810344696045, G Loss: 0.6976885199546814\n",
      "Epoch [14/10000] Batch 100, D Loss: 1.3873138427734375, G Loss: 0.6829184293746948\n",
      "Epoch [14/10000] Batch 200, D Loss: 1.3866395950317383, G Loss: 0.6862752437591553\n",
      "Epoch [14/10000] Batch 300, D Loss: 1.3868216276168823, G Loss: 0.6816556453704834\n",
      "Epoch [15/10000] Batch 0, D Loss: 1.3885040283203125, G Loss: 0.6910173892974854\n",
      "Epoch [15/10000] Batch 100, D Loss: 1.400543451309204, G Loss: 0.684600293636322\n",
      "Epoch [15/10000] Batch 200, D Loss: 1.3851628303527832, G Loss: 0.6986343860626221\n",
      "Epoch [15/10000] Batch 300, D Loss: 1.401158094406128, G Loss: 0.6897373199462891\n",
      "Epoch [16/10000] Batch 0, D Loss: 1.394050121307373, G Loss: 0.6863904595375061\n",
      "Epoch [16/10000] Batch 100, D Loss: 1.3933688402175903, G Loss: 0.68048495054245\n",
      "Epoch [16/10000] Batch 200, D Loss: 1.3786535263061523, G Loss: 0.7178245186805725\n",
      "Epoch [16/10000] Batch 300, D Loss: 1.3868703842163086, G Loss: 0.7096638679504395\n",
      "Epoch [17/10000] Batch 0, D Loss: 1.3916505575180054, G Loss: 0.690299928188324\n",
      "Epoch [17/10000] Batch 100, D Loss: 1.3739917278289795, G Loss: 0.7063554525375366\n",
      "Epoch [17/10000] Batch 200, D Loss: 1.4235255718231201, G Loss: 0.638336181640625\n",
      "Epoch [17/10000] Batch 300, D Loss: 1.423656702041626, G Loss: 0.6959627866744995\n",
      "Epoch [18/10000] Batch 0, D Loss: 1.3855295181274414, G Loss: 0.7031109929084778\n",
      "Epoch [18/10000] Batch 100, D Loss: 1.4200372695922852, G Loss: 0.7224971055984497\n",
      "Epoch [18/10000] Batch 200, D Loss: 1.4130542278289795, G Loss: 0.6634352207183838\n",
      "Epoch [18/10000] Batch 300, D Loss: 1.3811333179473877, G Loss: 0.710330605506897\n",
      "Epoch [19/10000] Batch 0, D Loss: 1.4199883937835693, G Loss: 0.6529990434646606\n",
      "Epoch [19/10000] Batch 100, D Loss: 1.3794994354248047, G Loss: 0.7281335592269897\n",
      "Epoch [19/10000] Batch 200, D Loss: 1.4164161682128906, G Loss: 0.6501064896583557\n",
      "Epoch [19/10000] Batch 300, D Loss: 1.3821518421173096, G Loss: 0.6672319173812866\n",
      "Epoch [20/10000] Batch 0, D Loss: 1.2983149290084839, G Loss: 0.9170539975166321\n",
      "Epoch [20/10000] Batch 100, D Loss: 1.5456035137176514, G Loss: 0.6401842832565308\n",
      "Epoch [20/10000] Batch 200, D Loss: 1.3292720317840576, G Loss: 1.1225440502166748\n",
      "Epoch [20/10000] Batch 300, D Loss: 1.6604915857315063, G Loss: 0.7301080226898193\n",
      "Epoch [21/10000] Batch 0, D Loss: 1.6026928424835205, G Loss: 0.8457356691360474\n",
      "Epoch [21/10000] Batch 100, D Loss: 1.458065152168274, G Loss: 0.8086908459663391\n",
      "Epoch [21/10000] Batch 200, D Loss: 1.5722150802612305, G Loss: 0.6560635566711426\n",
      "Epoch [21/10000] Batch 300, D Loss: 1.539363145828247, G Loss: 0.7868489027023315\n",
      "Epoch [22/10000] Batch 0, D Loss: 1.4735158681869507, G Loss: 0.9349356889724731\n",
      "Epoch [22/10000] Batch 100, D Loss: 1.3381552696228027, G Loss: 0.8221724629402161\n",
      "Epoch [22/10000] Batch 200, D Loss: 1.512908697128296, G Loss: 0.6702646613121033\n",
      "Epoch [22/10000] Batch 300, D Loss: 1.422240138053894, G Loss: 0.8324278593063354\n",
      "Epoch [23/10000] Batch 0, D Loss: 1.30454421043396, G Loss: 0.9088824391365051\n",
      "Epoch [23/10000] Batch 100, D Loss: 1.3746618032455444, G Loss: 0.8284856081008911\n",
      "Epoch [23/10000] Batch 200, D Loss: 1.5329163074493408, G Loss: 0.7216624021530151\n",
      "Epoch [23/10000] Batch 300, D Loss: 1.4214445352554321, G Loss: 0.9253257513046265\n",
      "Epoch [24/10000] Batch 0, D Loss: 1.317283034324646, G Loss: 0.8154928684234619\n",
      "Epoch [24/10000] Batch 100, D Loss: 1.3749163150787354, G Loss: 0.7741714715957642\n",
      "Epoch [24/10000] Batch 200, D Loss: 1.6314616203308105, G Loss: 0.6158186197280884\n",
      "Epoch [24/10000] Batch 300, D Loss: 1.4199516773223877, G Loss: 0.7869671583175659\n",
      "Epoch [25/10000] Batch 0, D Loss: 1.4331485033035278, G Loss: 0.7533328533172607\n",
      "Epoch [25/10000] Batch 100, D Loss: 1.3654905557632446, G Loss: 0.7693222761154175\n",
      "Epoch [25/10000] Batch 200, D Loss: 1.260622262954712, G Loss: 0.8677195906639099\n",
      "Epoch [25/10000] Batch 300, D Loss: 1.2713736295700073, G Loss: 0.8919988870620728\n",
      "Epoch [26/10000] Batch 0, D Loss: 1.342790961265564, G Loss: 0.9473648071289062\n",
      "Epoch [26/10000] Batch 100, D Loss: 1.5208508968353271, G Loss: 0.7110658288002014\n",
      "Epoch [26/10000] Batch 200, D Loss: 1.298384189605713, G Loss: 0.8423476219177246\n",
      "Epoch [26/10000] Batch 300, D Loss: 1.398148775100708, G Loss: 0.8603988885879517\n",
      "Epoch [27/10000] Batch 0, D Loss: 1.3245717287063599, G Loss: 0.928449273109436\n",
      "Epoch [27/10000] Batch 100, D Loss: 1.3319635391235352, G Loss: 0.8109387159347534\n",
      "Epoch [27/10000] Batch 200, D Loss: 1.4315452575683594, G Loss: 0.6868616938591003\n",
      "Epoch [27/10000] Batch 300, D Loss: 1.4219799041748047, G Loss: 0.7482165098190308\n",
      "Epoch [28/10000] Batch 0, D Loss: 1.4929986000061035, G Loss: 0.7132501602172852\n",
      "Epoch [28/10000] Batch 100, D Loss: 1.5008294582366943, G Loss: 0.6905434727668762\n",
      "Epoch [28/10000] Batch 200, D Loss: 1.5570778846740723, G Loss: 0.6902889013290405\n",
      "Epoch [28/10000] Batch 300, D Loss: 1.3921797275543213, G Loss: 0.8226400017738342\n",
      "Epoch [29/10000] Batch 0, D Loss: 1.494781494140625, G Loss: 0.7729588747024536\n",
      "Epoch [29/10000] Batch 100, D Loss: 1.453918218612671, G Loss: 0.8142653703689575\n",
      "Epoch [29/10000] Batch 200, D Loss: 1.5343613624572754, G Loss: 0.7758424878120422\n",
      "Epoch [29/10000] Batch 300, D Loss: 1.4846842288970947, G Loss: 0.7903990149497986\n",
      "Epoch [30/10000] Batch 0, D Loss: 1.5231831073760986, G Loss: 0.6843833923339844\n",
      "Epoch [30/10000] Batch 100, D Loss: 1.3991613388061523, G Loss: 0.8313343524932861\n",
      "Epoch [30/10000] Batch 200, D Loss: 1.4505484104156494, G Loss: 0.8406509160995483\n",
      "Epoch [30/10000] Batch 300, D Loss: 1.4798280000686646, G Loss: 0.8160488605499268\n",
      "Epoch [31/10000] Batch 0, D Loss: 1.367990493774414, G Loss: 0.8056153059005737\n",
      "Epoch [31/10000] Batch 100, D Loss: 1.5095441341400146, G Loss: 0.6893562078475952\n",
      "Epoch [31/10000] Batch 200, D Loss: 1.5240916013717651, G Loss: 0.7361474633216858\n",
      "Epoch [31/10000] Batch 300, D Loss: 1.4295381307601929, G Loss: 0.8033949136734009\n",
      "Epoch [32/10000] Batch 0, D Loss: 1.4458481073379517, G Loss: 0.7697169780731201\n",
      "Epoch [32/10000] Batch 100, D Loss: 1.4932360649108887, G Loss: 0.7655748724937439\n",
      "Epoch [32/10000] Batch 200, D Loss: 1.460846185684204, G Loss: 0.7820839881896973\n",
      "Epoch [32/10000] Batch 300, D Loss: 1.3985735177993774, G Loss: 0.7763803601264954\n",
      "Epoch [33/10000] Batch 0, D Loss: 1.368522047996521, G Loss: 0.7516681551933289\n",
      "Epoch [33/10000] Batch 100, D Loss: 1.4831770658493042, G Loss: 0.727043628692627\n",
      "Epoch [33/10000] Batch 200, D Loss: 1.4698750972747803, G Loss: 0.8406037092208862\n",
      "Epoch [33/10000] Batch 300, D Loss: 1.4398770332336426, G Loss: 0.728484034538269\n",
      "Epoch [34/10000] Batch 0, D Loss: 1.4408855438232422, G Loss: 0.8123809099197388\n",
      "Epoch [34/10000] Batch 100, D Loss: 1.4078054428100586, G Loss: 0.827052652835846\n",
      "Epoch [34/10000] Batch 200, D Loss: 1.5030388832092285, G Loss: 0.6717773675918579\n",
      "Epoch [34/10000] Batch 300, D Loss: 1.5218756198883057, G Loss: 0.7441888451576233\n",
      "Epoch [35/10000] Batch 0, D Loss: 1.3771377801895142, G Loss: 0.7865240573883057\n",
      "Epoch [35/10000] Batch 100, D Loss: 1.498152494430542, G Loss: 0.76887446641922\n",
      "Epoch [35/10000] Batch 200, D Loss: 1.46091890335083, G Loss: 0.8252232074737549\n",
      "Epoch [35/10000] Batch 300, D Loss: 1.3882942199707031, G Loss: 0.7946807742118835\n",
      "Epoch [36/10000] Batch 0, D Loss: 1.3735542297363281, G Loss: 0.8044431209564209\n",
      "Epoch [36/10000] Batch 100, D Loss: 1.448395013809204, G Loss: 0.7616990804672241\n",
      "Epoch [36/10000] Batch 200, D Loss: 1.5550386905670166, G Loss: 0.7650949358940125\n",
      "Epoch [36/10000] Batch 300, D Loss: 1.413681149482727, G Loss: 0.6803063154220581\n",
      "Epoch [37/10000] Batch 0, D Loss: 1.4381670951843262, G Loss: 0.7468816041946411\n",
      "Epoch [37/10000] Batch 100, D Loss: 1.4678239822387695, G Loss: 0.8412240147590637\n",
      "Epoch [37/10000] Batch 200, D Loss: 1.4993445873260498, G Loss: 0.6959138512611389\n",
      "Epoch [37/10000] Batch 300, D Loss: 1.439192295074463, G Loss: 0.7523738145828247\n",
      "Epoch [38/10000] Batch 0, D Loss: 1.536746621131897, G Loss: 0.73231440782547\n",
      "Epoch [38/10000] Batch 100, D Loss: 1.4199786186218262, G Loss: 0.8576434254646301\n",
      "Epoch [38/10000] Batch 200, D Loss: 1.3796844482421875, G Loss: 0.7456969022750854\n",
      "Epoch [38/10000] Batch 300, D Loss: 1.4577112197875977, G Loss: 0.7138863205909729\n",
      "Epoch [39/10000] Batch 0, D Loss: 1.4660788774490356, G Loss: 0.7972928285598755\n",
      "Epoch [39/10000] Batch 100, D Loss: 1.4196550846099854, G Loss: 0.734922468662262\n",
      "Epoch [39/10000] Batch 200, D Loss: 1.42547607421875, G Loss: 0.7447232007980347\n",
      "Epoch [39/10000] Batch 300, D Loss: 1.3213720321655273, G Loss: 0.814283013343811\n",
      "Epoch [40/10000] Batch 0, D Loss: 1.464022159576416, G Loss: 0.7306013107299805\n",
      "Epoch [40/10000] Batch 100, D Loss: 1.4360750913619995, G Loss: 0.7565492391586304\n",
      "Epoch [40/10000] Batch 200, D Loss: 1.4002705812454224, G Loss: 0.7900640964508057\n",
      "Epoch [40/10000] Batch 300, D Loss: 1.5206470489501953, G Loss: 0.7108621597290039\n",
      "Epoch [41/10000] Batch 0, D Loss: 1.448529839515686, G Loss: 0.7825394868850708\n",
      "Epoch [41/10000] Batch 100, D Loss: 1.3544716835021973, G Loss: 0.8111741542816162\n",
      "Epoch [41/10000] Batch 200, D Loss: 1.484776496887207, G Loss: 0.7560180425643921\n",
      "Epoch [41/10000] Batch 300, D Loss: 1.4156928062438965, G Loss: 0.8611060380935669\n",
      "Epoch [42/10000] Batch 0, D Loss: 1.4219837188720703, G Loss: 0.8174532651901245\n",
      "Epoch [42/10000] Batch 100, D Loss: 1.4491417407989502, G Loss: 0.7083571553230286\n",
      "Epoch [42/10000] Batch 200, D Loss: 1.4355590343475342, G Loss: 0.8170166015625\n",
      "Epoch [42/10000] Batch 300, D Loss: 1.4531549215316772, G Loss: 0.7357653379440308\n",
      "Epoch [43/10000] Batch 0, D Loss: 1.4024577140808105, G Loss: 0.7084461450576782\n",
      "Epoch [43/10000] Batch 100, D Loss: 1.4750351905822754, G Loss: 0.7983004450798035\n",
      "Epoch [43/10000] Batch 200, D Loss: 1.435140609741211, G Loss: 0.7968816757202148\n",
      "Epoch [43/10000] Batch 300, D Loss: 1.440385103225708, G Loss: 0.7121334671974182\n",
      "Epoch [44/10000] Batch 0, D Loss: 1.4170153141021729, G Loss: 0.7558023929595947\n",
      "Epoch [44/10000] Batch 100, D Loss: 1.4321374893188477, G Loss: 0.8092032670974731\n",
      "Epoch [44/10000] Batch 200, D Loss: 1.525876760482788, G Loss: 0.7096995711326599\n",
      "Epoch [44/10000] Batch 300, D Loss: 1.3494718074798584, G Loss: 0.7563554048538208\n",
      "Epoch [45/10000] Batch 0, D Loss: 1.5059974193572998, G Loss: 0.6805005669593811\n",
      "Epoch [45/10000] Batch 100, D Loss: 1.3661754131317139, G Loss: 0.7768682241439819\n",
      "Epoch [45/10000] Batch 200, D Loss: 1.4143837690353394, G Loss: 0.7911587357521057\n",
      "Epoch [45/10000] Batch 300, D Loss: 1.367978572845459, G Loss: 0.808180570602417\n",
      "Epoch [46/10000] Batch 0, D Loss: 1.3672592639923096, G Loss: 0.7833932638168335\n",
      "Epoch [46/10000] Batch 100, D Loss: 1.3287986516952515, G Loss: 0.762596607208252\n",
      "Epoch [46/10000] Batch 200, D Loss: 1.4524980783462524, G Loss: 0.9029264450073242\n",
      "Epoch [46/10000] Batch 300, D Loss: 1.4832909107208252, G Loss: 0.6933132410049438\n",
      "Epoch [47/10000] Batch 0, D Loss: 1.329387903213501, G Loss: 0.7946541905403137\n",
      "Epoch [47/10000] Batch 100, D Loss: 1.523559331893921, G Loss: 0.8112531900405884\n",
      "Epoch [47/10000] Batch 200, D Loss: 1.4433231353759766, G Loss: 0.8368858695030212\n",
      "Epoch [47/10000] Batch 300, D Loss: 1.3949453830718994, G Loss: 0.7178307771682739\n",
      "Epoch [48/10000] Batch 0, D Loss: 1.4766050577163696, G Loss: 0.6848181486129761\n",
      "Epoch [48/10000] Batch 100, D Loss: 1.4992921352386475, G Loss: 0.7560371160507202\n",
      "Epoch [48/10000] Batch 200, D Loss: 1.4768171310424805, G Loss: 0.7386730909347534\n",
      "Epoch [48/10000] Batch 300, D Loss: 1.338761568069458, G Loss: 0.7793281078338623\n",
      "Epoch [49/10000] Batch 0, D Loss: 1.4546294212341309, G Loss: 0.7080997228622437\n",
      "Epoch [49/10000] Batch 100, D Loss: 1.3948798179626465, G Loss: 0.7516941428184509\n",
      "Epoch [49/10000] Batch 200, D Loss: 1.4075086116790771, G Loss: 0.7392669916152954\n",
      "Epoch [49/10000] Batch 300, D Loss: 1.4175795316696167, G Loss: 0.8106701374053955\n",
      "Epoch [50/10000] Batch 0, D Loss: 1.3827506303787231, G Loss: 0.7710248231887817\n",
      "Epoch [50/10000] Batch 100, D Loss: 1.4147167205810547, G Loss: 0.7285172343254089\n",
      "Epoch [50/10000] Batch 200, D Loss: 1.5853114128112793, G Loss: 0.7311569452285767\n",
      "Epoch [50/10000] Batch 300, D Loss: 1.424915075302124, G Loss: 0.7623269557952881\n",
      "Epoch [51/10000] Batch 0, D Loss: 1.5356495380401611, G Loss: 0.6554566621780396\n",
      "Epoch [51/10000] Batch 100, D Loss: 1.4082920551300049, G Loss: 0.7401846647262573\n",
      "Epoch [51/10000] Batch 200, D Loss: 1.4407932758331299, G Loss: 0.788512110710144\n",
      "Epoch [51/10000] Batch 300, D Loss: 1.327911138534546, G Loss: 0.7113187313079834\n",
      "Epoch [52/10000] Batch 0, D Loss: 1.3837387561798096, G Loss: 0.686575710773468\n",
      "Epoch [52/10000] Batch 100, D Loss: 1.4163148403167725, G Loss: 0.836840808391571\n",
      "Epoch [52/10000] Batch 200, D Loss: 1.3891994953155518, G Loss: 0.7334216833114624\n",
      "Epoch [52/10000] Batch 300, D Loss: 1.5158627033233643, G Loss: 0.6251128911972046\n",
      "Epoch [53/10000] Batch 0, D Loss: 1.4223235845565796, G Loss: 0.7459642887115479\n",
      "Epoch [53/10000] Batch 100, D Loss: 1.3886785507202148, G Loss: 0.8283998370170593\n",
      "Epoch [53/10000] Batch 200, D Loss: 1.3685282468795776, G Loss: 0.7120791673660278\n",
      "Epoch [53/10000] Batch 300, D Loss: 1.4530107975006104, G Loss: 0.6601577997207642\n",
      "Epoch [54/10000] Batch 0, D Loss: 1.4749914407730103, G Loss: 0.7247220277786255\n",
      "Epoch [54/10000] Batch 100, D Loss: 1.399308681488037, G Loss: 0.7448381185531616\n",
      "Epoch [54/10000] Batch 200, D Loss: 1.386763334274292, G Loss: 0.8576070666313171\n",
      "Epoch [54/10000] Batch 300, D Loss: 1.3232967853546143, G Loss: 0.7495673298835754\n",
      "Epoch [55/10000] Batch 0, D Loss: 1.33955979347229, G Loss: 0.7419401407241821\n",
      "Epoch [55/10000] Batch 100, D Loss: 1.381622552871704, G Loss: 0.7743569612503052\n",
      "Epoch [55/10000] Batch 200, D Loss: 1.5174224376678467, G Loss: 0.7187578678131104\n",
      "Epoch [55/10000] Batch 300, D Loss: 1.4114984273910522, G Loss: 0.7767057418823242\n",
      "Epoch [56/10000] Batch 0, D Loss: 1.4869663715362549, G Loss: 0.7295290231704712\n",
      "Epoch [56/10000] Batch 100, D Loss: 1.3426520824432373, G Loss: 0.7540007829666138\n",
      "Epoch [56/10000] Batch 200, D Loss: 1.3684080839157104, G Loss: 0.8901412487030029\n",
      "Epoch [56/10000] Batch 300, D Loss: 1.3845118284225464, G Loss: 0.7382794618606567\n",
      "Epoch [57/10000] Batch 0, D Loss: 1.3768028020858765, G Loss: 0.7095882892608643\n",
      "Epoch [57/10000] Batch 100, D Loss: 1.3991646766662598, G Loss: 0.7454144954681396\n",
      "Epoch [57/10000] Batch 200, D Loss: 1.4424009323120117, G Loss: 0.7994723320007324\n",
      "Epoch [57/10000] Batch 300, D Loss: 1.4672003984451294, G Loss: 0.6714634895324707\n",
      "Epoch [58/10000] Batch 0, D Loss: 1.4617208242416382, G Loss: 0.6952438950538635\n",
      "Epoch [58/10000] Batch 100, D Loss: 1.4074959754943848, G Loss: 0.7865579128265381\n",
      "Epoch [58/10000] Batch 200, D Loss: 1.488924503326416, G Loss: 0.7272432446479797\n",
      "Epoch [58/10000] Batch 300, D Loss: 1.4495503902435303, G Loss: 0.7947824001312256\n",
      "Epoch [59/10000] Batch 0, D Loss: 1.480900526046753, G Loss: 0.7580921649932861\n",
      "Epoch [59/10000] Batch 100, D Loss: 1.388366937637329, G Loss: 0.7605113983154297\n",
      "Epoch [59/10000] Batch 200, D Loss: 1.3963847160339355, G Loss: 0.8295947313308716\n",
      "Epoch [59/10000] Batch 300, D Loss: 1.4887402057647705, G Loss: 0.7553519606590271\n",
      "Epoch [60/10000] Batch 0, D Loss: 1.3525248765945435, G Loss: 0.7873668670654297\n",
      "Epoch [60/10000] Batch 100, D Loss: 1.4505820274353027, G Loss: 0.7662144899368286\n",
      "Epoch [60/10000] Batch 200, D Loss: 1.4061245918273926, G Loss: 0.7333285212516785\n",
      "Epoch [60/10000] Batch 300, D Loss: 1.3538990020751953, G Loss: 0.8963342905044556\n",
      "Epoch [61/10000] Batch 0, D Loss: 1.4252541065216064, G Loss: 0.8756008148193359\n",
      "Epoch [61/10000] Batch 100, D Loss: 1.4738762378692627, G Loss: 0.6785382032394409\n",
      "Epoch [61/10000] Batch 200, D Loss: 1.436781644821167, G Loss: 0.7056550979614258\n",
      "Epoch [61/10000] Batch 300, D Loss: 1.5012011528015137, G Loss: 0.7176699042320251\n",
      "Epoch [62/10000] Batch 0, D Loss: 1.321843147277832, G Loss: 0.7970601320266724\n",
      "Epoch [62/10000] Batch 100, D Loss: 1.403114914894104, G Loss: 0.6932424902915955\n",
      "Epoch [62/10000] Batch 200, D Loss: 1.4619642496109009, G Loss: 0.70462965965271\n",
      "Epoch [62/10000] Batch 300, D Loss: 1.3308385610580444, G Loss: 0.8785340785980225\n",
      "Epoch [63/10000] Batch 0, D Loss: 1.4481257200241089, G Loss: 0.7188454866409302\n",
      "Epoch [63/10000] Batch 100, D Loss: 1.342817783355713, G Loss: 0.8044933080673218\n",
      "Epoch [63/10000] Batch 200, D Loss: 1.4428318738937378, G Loss: 0.7161669731140137\n",
      "Epoch [63/10000] Batch 300, D Loss: 1.4054831266403198, G Loss: 0.770431399345398\n",
      "Epoch [64/10000] Batch 0, D Loss: 1.56095552444458, G Loss: 0.6866345405578613\n",
      "Epoch [64/10000] Batch 100, D Loss: 1.3780362606048584, G Loss: 0.7969373464584351\n",
      "Epoch [64/10000] Batch 200, D Loss: 1.422609567642212, G Loss: 0.7144297361373901\n",
      "Epoch [64/10000] Batch 300, D Loss: 1.4993572235107422, G Loss: 0.950764536857605\n",
      "Epoch [65/10000] Batch 0, D Loss: 1.4524199962615967, G Loss: 0.7484244108200073\n",
      "Epoch [65/10000] Batch 100, D Loss: 1.4037089347839355, G Loss: 0.6468531489372253\n",
      "Epoch [65/10000] Batch 200, D Loss: 1.3627830743789673, G Loss: 0.8857666254043579\n",
      "Epoch [65/10000] Batch 300, D Loss: 1.4296518564224243, G Loss: 0.7527350783348083\n",
      "Epoch [66/10000] Batch 0, D Loss: 1.3518627882003784, G Loss: 0.7245612144470215\n",
      "Epoch [66/10000] Batch 100, D Loss: 1.3176219463348389, G Loss: 0.8719194531440735\n",
      "Epoch [66/10000] Batch 200, D Loss: 1.5293643474578857, G Loss: 0.7907915115356445\n",
      "Epoch [66/10000] Batch 300, D Loss: 1.406159520149231, G Loss: 0.6552257537841797\n",
      "Epoch [67/10000] Batch 0, D Loss: 1.299718976020813, G Loss: 0.862928569316864\n",
      "Epoch [67/10000] Batch 100, D Loss: 1.5068798065185547, G Loss: 0.635949969291687\n",
      "Epoch [67/10000] Batch 200, D Loss: 1.4395850896835327, G Loss: 0.7191272377967834\n",
      "Epoch [67/10000] Batch 300, D Loss: 1.4515563249588013, G Loss: 0.7276754975318909\n",
      "Epoch [68/10000] Batch 0, D Loss: 1.4447249174118042, G Loss: 0.7394180297851562\n",
      "Epoch [68/10000] Batch 100, D Loss: 1.3898520469665527, G Loss: 0.6802144050598145\n",
      "Epoch [68/10000] Batch 200, D Loss: 1.3703429698944092, G Loss: 0.8791185021400452\n",
      "Epoch [68/10000] Batch 300, D Loss: 1.51426362991333, G Loss: 0.7069301605224609\n",
      "Epoch [69/10000] Batch 0, D Loss: 1.4015616178512573, G Loss: 0.740073561668396\n",
      "Epoch [69/10000] Batch 100, D Loss: 1.4201443195343018, G Loss: 0.7730896472930908\n",
      "Epoch [69/10000] Batch 200, D Loss: 1.4329112768173218, G Loss: 0.7349609732627869\n",
      "Epoch [69/10000] Batch 300, D Loss: 1.4519648551940918, G Loss: 0.6673997044563293\n",
      "Epoch [70/10000] Batch 0, D Loss: 1.630897045135498, G Loss: 0.6677656173706055\n",
      "Epoch [70/10000] Batch 100, D Loss: 1.4299514293670654, G Loss: 0.7416150569915771\n",
      "Epoch [70/10000] Batch 200, D Loss: 1.3059951066970825, G Loss: 0.8697994351387024\n",
      "Epoch [70/10000] Batch 300, D Loss: 1.4351446628570557, G Loss: 0.7231179475784302\n",
      "Epoch [71/10000] Batch 0, D Loss: 1.402277946472168, G Loss: 0.7011151909828186\n",
      "Epoch [71/10000] Batch 100, D Loss: 1.3983526229858398, G Loss: 0.7332797050476074\n",
      "Epoch [71/10000] Batch 200, D Loss: 1.3566184043884277, G Loss: 0.8796055316925049\n",
      "Epoch [71/10000] Batch 300, D Loss: 1.4686424732208252, G Loss: 0.7341511249542236\n",
      "Epoch [72/10000] Batch 0, D Loss: 1.3955243825912476, G Loss: 0.7558481693267822\n",
      "Epoch [72/10000] Batch 100, D Loss: 1.425812005996704, G Loss: 0.6596841216087341\n",
      "Epoch [72/10000] Batch 200, D Loss: 1.5757715702056885, G Loss: 0.6051452159881592\n",
      "Epoch [72/10000] Batch 300, D Loss: 1.4570717811584473, G Loss: 0.8049722909927368\n",
      "Epoch [73/10000] Batch 0, D Loss: 1.4739378690719604, G Loss: 0.6719809770584106\n",
      "Epoch [73/10000] Batch 100, D Loss: 1.4021766185760498, G Loss: 0.6589832305908203\n",
      "Epoch [73/10000] Batch 200, D Loss: 1.4173290729522705, G Loss: 0.80096435546875\n",
      "Epoch [73/10000] Batch 300, D Loss: 1.2862120866775513, G Loss: 0.8203170299530029\n",
      "Epoch [74/10000] Batch 0, D Loss: 1.431081771850586, G Loss: 0.6180078387260437\n",
      "Epoch [74/10000] Batch 100, D Loss: 1.4032598733901978, G Loss: 0.8111940622329712\n",
      "Epoch [74/10000] Batch 200, D Loss: 1.3504647016525269, G Loss: 0.7978487610816956\n",
      "Epoch [74/10000] Batch 300, D Loss: 1.4408938884735107, G Loss: 0.6359903216362\n",
      "Epoch [75/10000] Batch 0, D Loss: 1.3271009922027588, G Loss: 0.9008435010910034\n",
      "Epoch [75/10000] Batch 100, D Loss: 1.4785313606262207, G Loss: 0.6710665225982666\n",
      "Epoch [75/10000] Batch 200, D Loss: 1.4972749948501587, G Loss: 0.6417481899261475\n",
      "Epoch [75/10000] Batch 300, D Loss: 1.433518409729004, G Loss: 0.7503794431686401\n",
      "Epoch [76/10000] Batch 0, D Loss: 1.4588350057601929, G Loss: 0.6738841533660889\n",
      "Epoch [76/10000] Batch 100, D Loss: 1.4657721519470215, G Loss: 0.7337148189544678\n",
      "Epoch [76/10000] Batch 200, D Loss: 1.4511504173278809, G Loss: 0.9277751445770264\n",
      "Epoch [76/10000] Batch 300, D Loss: 1.2949414253234863, G Loss: 0.9162299036979675\n",
      "Epoch [77/10000] Batch 0, D Loss: 1.491674542427063, G Loss: 0.6455202102661133\n",
      "Epoch [77/10000] Batch 100, D Loss: 1.3871262073516846, G Loss: 0.9325491189956665\n",
      "Epoch [77/10000] Batch 200, D Loss: 1.5130362510681152, G Loss: 0.6822413206100464\n",
      "Epoch [77/10000] Batch 300, D Loss: 1.4581272602081299, G Loss: 0.7074415683746338\n",
      "Epoch [78/10000] Batch 0, D Loss: 1.4288618564605713, G Loss: 0.8531778454780579\n",
      "Epoch [78/10000] Batch 100, D Loss: 1.4731276035308838, G Loss: 0.67634117603302\n",
      "Epoch [78/10000] Batch 200, D Loss: 1.3459938764572144, G Loss: 0.7722026109695435\n",
      "Epoch [78/10000] Batch 300, D Loss: 1.489762306213379, G Loss: 0.8463168144226074\n",
      "Epoch [79/10000] Batch 0, D Loss: 1.5277992486953735, G Loss: 0.6588447093963623\n",
      "Epoch [79/10000] Batch 100, D Loss: 1.3966370820999146, G Loss: 0.6494314670562744\n",
      "Epoch [79/10000] Batch 200, D Loss: 1.331085205078125, G Loss: 1.023491621017456\n",
      "Epoch [79/10000] Batch 300, D Loss: 1.425276517868042, G Loss: 0.6939513683319092\n",
      "Epoch [80/10000] Batch 0, D Loss: 1.3436455726623535, G Loss: 0.7475590705871582\n",
      "Epoch [80/10000] Batch 100, D Loss: 1.5243127346038818, G Loss: 0.5842565894126892\n",
      "Epoch [80/10000] Batch 200, D Loss: 1.413354516029358, G Loss: 0.8635409474372864\n",
      "Epoch [80/10000] Batch 300, D Loss: 1.5421689748764038, G Loss: 0.6491171717643738\n",
      "Epoch [81/10000] Batch 0, D Loss: 1.361133098602295, G Loss: 0.738099217414856\n",
      "Epoch [81/10000] Batch 100, D Loss: 1.507237434387207, G Loss: 0.6926443576812744\n",
      "Epoch [81/10000] Batch 200, D Loss: 1.3964948654174805, G Loss: 0.7392585277557373\n",
      "Epoch [81/10000] Batch 300, D Loss: 1.522817611694336, G Loss: 0.618241012096405\n",
      "Epoch [82/10000] Batch 0, D Loss: 1.398108959197998, G Loss: 0.8197363615036011\n",
      "Epoch [82/10000] Batch 100, D Loss: 1.4431264400482178, G Loss: 0.6707770824432373\n",
      "Epoch [82/10000] Batch 200, D Loss: 1.491919755935669, G Loss: 0.6789944171905518\n",
      "Epoch [82/10000] Batch 300, D Loss: 1.4102931022644043, G Loss: 0.7365201115608215\n",
      "Epoch [83/10000] Batch 0, D Loss: 1.3861651420593262, G Loss: 0.7485920190811157\n",
      "Epoch [83/10000] Batch 100, D Loss: 1.4073960781097412, G Loss: 0.7150301337242126\n",
      "Epoch [83/10000] Batch 200, D Loss: 1.3662893772125244, G Loss: 0.7506008148193359\n",
      "Epoch [83/10000] Batch 300, D Loss: 1.3532531261444092, G Loss: 0.8051761388778687\n",
      "Epoch [84/10000] Batch 0, D Loss: 1.353513240814209, G Loss: 0.7748240232467651\n",
      "Epoch [84/10000] Batch 100, D Loss: 1.426285743713379, G Loss: 0.7682439088821411\n",
      "Epoch [84/10000] Batch 200, D Loss: 1.419715166091919, G Loss: 0.7466631531715393\n",
      "Epoch [84/10000] Batch 300, D Loss: 1.5459585189819336, G Loss: 0.7024531364440918\n",
      "Epoch [85/10000] Batch 0, D Loss: 1.4255683422088623, G Loss: 0.7873954772949219\n",
      "Epoch [85/10000] Batch 100, D Loss: 1.4929455518722534, G Loss: 0.6183485984802246\n",
      "Epoch [85/10000] Batch 200, D Loss: 1.4427329301834106, G Loss: 0.8910198211669922\n",
      "Epoch [85/10000] Batch 300, D Loss: 1.3098982572555542, G Loss: 0.8120391964912415\n",
      "Epoch [86/10000] Batch 0, D Loss: 1.4380714893341064, G Loss: 0.7542678117752075\n",
      "Epoch [86/10000] Batch 100, D Loss: 1.4098925590515137, G Loss: 0.7176088690757751\n",
      "Epoch [86/10000] Batch 200, D Loss: 1.482758641242981, G Loss: 0.7257391214370728\n",
      "Epoch [86/10000] Batch 300, D Loss: 1.4679332971572876, G Loss: 0.6294665336608887\n",
      "Epoch [87/10000] Batch 0, D Loss: 1.4249284267425537, G Loss: 0.7897230386734009\n",
      "Epoch [87/10000] Batch 100, D Loss: 1.3394577503204346, G Loss: 0.7490713596343994\n",
      "Epoch [87/10000] Batch 200, D Loss: 1.4004203081130981, G Loss: 0.7763923406600952\n",
      "Epoch [87/10000] Batch 300, D Loss: 1.4525375366210938, G Loss: 0.6784121990203857\n",
      "Epoch [88/10000] Batch 0, D Loss: 1.405759334564209, G Loss: 0.8490818738937378\n",
      "Epoch [88/10000] Batch 100, D Loss: 1.4624099731445312, G Loss: 0.7047110795974731\n",
      "Epoch [88/10000] Batch 200, D Loss: 1.2685091495513916, G Loss: 0.8252376914024353\n",
      "Epoch [88/10000] Batch 300, D Loss: 1.5384669303894043, G Loss: 0.7448838949203491\n",
      "Epoch [89/10000] Batch 0, D Loss: 1.453914761543274, G Loss: 0.784187912940979\n",
      "Epoch [89/10000] Batch 100, D Loss: 1.2667429447174072, G Loss: 0.8415637016296387\n",
      "Epoch [89/10000] Batch 200, D Loss: 1.3782310485839844, G Loss: 0.811598539352417\n",
      "Epoch [89/10000] Batch 300, D Loss: 1.4266154766082764, G Loss: 0.7292426824569702\n",
      "Epoch [90/10000] Batch 0, D Loss: 1.3263016939163208, G Loss: 0.7795792818069458\n",
      "Epoch [90/10000] Batch 100, D Loss: 1.5791382789611816, G Loss: 0.7517125606536865\n",
      "Epoch [90/10000] Batch 200, D Loss: 1.489891529083252, G Loss: 0.7896609306335449\n",
      "Epoch [90/10000] Batch 300, D Loss: 1.2144925594329834, G Loss: 0.8785244226455688\n",
      "Epoch [91/10000] Batch 0, D Loss: 1.56501305103302, G Loss: 0.5486496686935425\n",
      "Epoch [91/10000] Batch 100, D Loss: 1.4162178039550781, G Loss: 0.842570424079895\n",
      "Epoch [91/10000] Batch 200, D Loss: 1.2984033823013306, G Loss: 0.7635055780410767\n",
      "Epoch [91/10000] Batch 300, D Loss: 1.5380933284759521, G Loss: 0.8769407272338867\n",
      "Epoch [92/10000] Batch 0, D Loss: 1.5375802516937256, G Loss: 0.7218154668807983\n",
      "Epoch [92/10000] Batch 100, D Loss: 1.329805612564087, G Loss: 0.7976318597793579\n",
      "Epoch [92/10000] Batch 200, D Loss: 1.449814796447754, G Loss: 0.7397897839546204\n",
      "Epoch [92/10000] Batch 300, D Loss: 1.3984811305999756, G Loss: 0.8110396862030029\n",
      "Epoch [93/10000] Batch 0, D Loss: 1.4769279956817627, G Loss: 0.7814829349517822\n",
      "Epoch [93/10000] Batch 100, D Loss: 1.48178231716156, G Loss: 0.6302571892738342\n",
      "Epoch [93/10000] Batch 200, D Loss: 1.4852828979492188, G Loss: 0.7981041073799133\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m adversarial_loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBCELoss()\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m---> 22\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mreal_coords\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlengths\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreal_coords\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlengths\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mreal_coords\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlengths\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Train Discriminator\u001B[39;49;00m\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mZ:\\Prog\\FARICH\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[18], line 12\u001B[0m, in \u001B[0;36mSparseImageDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     10\u001B[0m image_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_ids[idx]\n\u001B[0;32m     11\u001B[0m pixels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataframe\u001B[38;5;241m.\u001B[39mloc[image_id, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_s\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_s\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpixels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-01-07T19:15:02.925368200Z",
     "start_time": "2025-01-07T19:12:30.581597Z"
    }
   },
   "cell_type": "code",
   "source": "train_sparse_gan(edf_c)",
   "id": "75f56d2d925e4a46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "edf_c",
   "id": "4b78ce12e42a274e"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "gdf.nhits.max()",
   "id": "a1609a7d45614485",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
